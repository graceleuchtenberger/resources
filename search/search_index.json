{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to the Roberts Lab Handbook!","text":"<p>Our hope is this is a one-stop locale for relevant information. You can use navigation at the left, the search function, and a few quick pages of interest are highlighted below. If you see something needing updating, you should be able to click on the pencil on each page and go directly to the source to edit, or simply submit an issue. Do not hesitate to join the Discussion.</p> <p> </p>"},{"location":"#just-getting-started","title":"Just Getting Started?","text":"<p>Be sure have a look at the following:</p> <ul> <li> <p>Read and adhere to:</p> <ul> <li> <p>Code of Conduct</p> </li> <li> <p>Lab Environment and Expectations</p> </li> </ul> </li> <li> <p>Onboarding Documentation</p> </li> <li> <p>Complete all Lab Safety Trainings</p> </li> <li> <p>Lab Communication - Digital and scheduling tools that we use to stay connected.</p> </li> </ul>"},{"location":"#ready-to-pick-up-a-pipette","title":"Ready to Pick up a Pipette?","text":"<ul> <li> <p>Lab Safety</p> </li> <li> <p>Chemical Standard Operating Protocols (SOPs)</p> </li> <li> <p>Lab Inventory - Materials, purchasing log, freezer contents, histology samples, primer database.</p> </li> <li> <p>Lab Protocols - Protocols for benchwork in the lab (e.g. RNA isolation), for commonly used instruments and software (e.g. proteomics data analysis in Skyline), and for commonly performed hatchery practices and tissue sampling.</p> </li> <li> <p>Alarm Information - Description of active alarms in the lab, how to configure, and what phone calls mean.</p> </li> </ul>"},{"location":"#sticking-to-the-keyboard","title":"Sticking to the Keyboard?","text":"<ul> <li> <p>Computing Hardware - Computing resources we have available &amp; links to help you begin learning.</p> </li> <li> <p>Lab Software - A list of software installed on lab computers.</p> </li> <li> <p>Data Management - This page is intended to document all aspects of data management, from the day-to-day, formal NGS and proteomics plans, and general archiving options.</p> </li> <li> <p>Genomic Resources - Here we try to compile genomic resources such that they are readily available and somewhat described.</p> </li> <li> <p>Digital Media - Where and how to store media including photos, videos and audio</p> </li> </ul>"},{"location":"#even-more","title":"Even More!","text":"<ul> <li> <p>Experiment Database - Database of all Roberts Lab experiments</p> </li> <li> <p>External Communication &amp; Funding - Conferences, community outreach, and funding sources that past and present lab members recommend. Also contains tips on printing posters.</p> </li> <li> <p>Lab Notebooks - Links to notebooks of current and past Roberts Lab members, as well as archived notebooks.</p> </li> <li> <p>Pubathon - Annual \"pubathon\" roster, links to and status of manuscripts.</p> </li> <li> <p>Purchasing &amp; Reimbursement - Procedure for purchases.</p> </li> </ul>"},{"location":"Alarm-Information/","title":"Alarm Information","text":"<p>Description of active alarms in the lab, how to configure, and what phone calls mean.</p>"},{"location":"Alarm-Information/#alarm-sensaphone-model-1104","title":"Alarm: Sensaphone Model 1104","text":"<p>User Manual here</p> <p>Incoming Phone Number: 1-206-685-7806</p> <p>This allows for you to call the alarm and receive updates on connected alarms, as well as listen to what is happening inside of the room for 15 seconds.</p> <p>Current numbers programmed to be called in the event of an alarm state:</p> <ul> <li> <p>1: 206-866-5141 : Steven</p> </li> <li> <p>2: Sam (home number)</p> </li> <li> <p>3: 206-914-3735 :</p> </li> <li> <p>4: 206-685-3273 : Sam</p> </li> </ul> <p>Sensaphone Connections:</p> <ul> <li> <p>1: Temperature sensor for ambient temperature inside of room.</p> </li> <li> <p>2: Power on/off sensor for power being supplied to freezer 1</p> </li> <li> <p>3: ~~Power on/off sensor for power being supplied to freezer 2~~ (disabled 20220803 by SJW)</p> </li> <li> <p>4: Not hooked to anything.</p> </li> </ul> <p>Example alarm meaning and acknowledgement:</p> <p>The alarm indicates only lack of power being supplied to freezer 1.</p> <p>To acknowledge receipt of the alarm, press \"555\" at any time during the recorded message.</p> <p>This only acknowledges receipt, the alarm condition still exists.</p> <p>Sensaphone alarm sequence:</p> <p>When the power goes off, Alarm 2 waits 10 minutes, then issues an alarm status.</p> <p>It then waits 5 further minutes to begin calling numbers on the list. There is a 1 minute pause between phone number calls.</p> <p>Upshot: We currently do not know of a power outage until a minimum of 15 minutes after it happens.</p> <p>To add/change phone numbers (The sensaphone can hold 4 phone numbers):</p> <ul> <li> <p>Press Set</p> </li> <li> <p>Press Phone Number</p> </li> <li> <p>Press Number on number pad corresponding to number you would like to change</p> </li> <li> <p>Enter Phone number on number pad</p> </li> <li> <p>Press Enter</p> </li> <li> <p>Sensaphone should respond with \"Enter\" if number updated correctly.</p> </li> </ul> <p>VWR freezer alarm set points:</p> <ul> <li> <p>-60<sup>o</sup>C High</p> </li> <li> <p>-90<sup>o</sup>C Low.</p> </li> </ul>"},{"location":"Alarm-Information/#alarm-avtech","title":"Alarm: Avtech","text":"<p>Alarms:</p> <ul> <li> <p>1: FTR-213 Large Freezer [High Alarm: -20, Low Alarm: -50]. Not set up as of 2021-08-27</p> </li> <li> <p>2: FTR-209 Refrigerator [High Alarm: 15, Low Alarm: -5]</p> </li> <li> <p>3: FTR-213 Freezer [High Alarm: 5, Low Alarm: -50]</p> </li> <li> <p>4: FTR-213 Refrigerator [High Alarm: 15, Low Alarm: -5]</p> </li> </ul> <p>Current numbers programmed to be called in the event of an alarm state:</p> <ul> <li> <p>1: 206-866-5141 : Steven</p> </li> <li> <p>2: 206-685-3273 : Sam</p> </li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/","title":"Chemical SOPs","text":""},{"location":"Chemical-Standard-Operating-Protocols/#university-of-washington-lab-safety-manual","title":"University of Washington Lab Safety Manual","text":""},{"location":"Chemical-Standard-Operating-Protocols/#chemical-material-safety-data-sheets-msds-on-mychem-website","title":"Chemical Material Safety Data Sheets (MSDS) on MyChem website.","text":""},{"location":"Chemical-Standard-Operating-Protocols/#uw-hazardous-waste-online-collection-request","title":"UW Hazardous Waste Online Collection Request","text":""},{"location":"Chemical-Standard-Operating-Protocols/#rnazol-rt","title":"RNAzol RT","text":"<p>Purpose: RNAzol RT is used for separating RNA from cells.</p> <p>Specific Hazards: RNAzol RT is corrosive and harmful if inhaled.</p> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li> <p>Gloves</p> </li> <li> <p>Chemical fume hood</p> </li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for RNAzol waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual RNAzol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#isopropanol-2-propanol","title":"Isopropanol (2-propanol)","text":"<p>Purpose: Used in the precipitation of nucleic acids.</p> <p>Specific Hazards: Highly flammable - keep away from ignition sources.</p> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li> <p>Safety goggles</p> </li> <li> <p>Lab Coat</p> </li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for isopropanol waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual isopropanol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#diethylpyrocarbonate-depc","title":"Diethylpyrocarbonate (DEPC)","text":"<p>Purpose: Used as an RNase inhibitor during handling and storage of RNA.</p> <p>Specific Hazards:</p> <ul> <li>Skin irritant and harmful if inhaled.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> <li>Chemical fume hood</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for DEPC waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual DEPC should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#dnazol","title":"DNAzol","text":"<p>Purpose: DNAzol is used for separating DNA from cells.</p> <p>Specific Hazards:</p> <ul> <li>DNAzol is corrosive.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>Liquid Waste:<ul> <li>Transfer liquid waste to labeled container designated for DNAzol waste.</li> </ul> </li> <li>Solid Waste:<ul> <li>Tubes/tip/gloves with residual DNAzol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#ethanol","title":"Ethanol","text":"<p>Purpose: Used in the precipitation of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Highly flammable - keep away from ignition sources.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for ethanol waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual ethanol should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#phenolchloroformiaa-25241","title":"Phenol:chloroform:IAA (25:24:1)","text":"<p>Purpose: Used for purification of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Phenol:chloroform:IAA is corrosive and harmful if inhaled.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> <li>Chemical fume hood</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for phenol:chloroform:IAA waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual phenol:chloroform:IAA should be stored in chemical fume hood for no less than 24hrs and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#proteinase-k","title":"Proteinase K","text":"<p>Purpose: Enzyme used to degrade proteins during DNA isolation.</p> <p>Specific Hazards:</p> <ul> <li>None.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li>No requirements.</li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#sodium-acetate","title":"Sodium acetate","text":"<p>Purpose: Used to precipitate nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Skin irritant.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li>REQUIRED:<ul> <li>Gloves</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Dispose in sink.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual sodium acetate can be disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#ethidium-bromide-etbr","title":"Ethidium bromide (EtBr)","text":"<p>Purpose: Use for staining nucleic acids in agarose gels.</p> <p>Specific Hazards:</p> <ul> <li>Mutagen and potential carcinogen.</li> </ul> <p>Personal Protective Equipment:</p> <ul> <li> <p>REQUIRED:</p> <ul> <li>Gloves</li> </ul> </li> <li> <p>WHEN SPLASH POTENTIAL EXISTS</p> <ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <p>NOTE: Disposal instructions are only for dilute EtBr concentrations (&lt; 10ug/mL) that are used in the lab. Concentrations higher than this are hazardous waste and should be placed in a labeled, dedicated container.</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Dispose in sink.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves/gels should be double bagged, labelled \"non-hazardous\", and then disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Chemical-Standard-Operating-Protocols/#qiagen-kits","title":"Qiagen Kits","text":"<p>Purpose: Use for isolation of nucleic acids.</p> <p>Specific Hazards:</p> <ul> <li>Harmful, irritant.</li> </ul> <p>NOTE: Do not combine kit reagents with bleach (sodium hypchlorite)!</p> <p>Personal Protective Equipment:</p> <ul> <li>REQUIRED:<ul> <li>Gloves</li> </ul> </li> <li>WHEN SPLASH POTENTIAL EXISTS<ul> <li>Safety goggles</li> <li>Lab Coat</li> </ul> </li> </ul> <p>Waste Disposal:</p> <ul> <li> <p>Liquid Waste:</p> <ul> <li>Transfer liquid waste to labeled container designated for Qiagen Kit waste.</li> </ul> </li> <li> <p>Solid Waste:</p> <ul> <li>Tubes/tip/gloves with residual sodium acetate can be disposed in regular trash.</li> </ul> </li> </ul> <p>Prepared by:</p> <ul> <li>Name: Sam White</li> <li>Date: 2016-10-24</li> </ul>"},{"location":"Code-of-Conduct/","title":"Code of Conduct","text":"<p>All members of the lab, along with visitors, are expected to agree with the following code of conduct. We expect cooperation from all members to help ensure a safe environment for everybody.</p> <p>In our lab we:</p> <ul> <li> <p>Recognize our differences as strengths</p> </li> <li> <p>Promote continuing education in diversity, equity, and inclusion (DEI). See non-exhaustive list of DEI resources offered by UW and beyond</p> </li> <li> <p>Provide educational and emotional support for each other</p> </li> <li> <p>Provide resources for educational and emotional support</p> </li> <li> <p>Provide resources for personal and professional growth</p> </li> </ul> <p>Harassment includes offensive verbal comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, religion, sexual images in public spaces, deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of talks or other events, inappropriate physical contact, and unwelcome sexual attention.</p> <p>We do not tolerate harassment and/or discrimination of lab members in any form. Sexual language and imagery is generally not appropriate for any lab venue, including lab meetings, presentations, or discussions (however, do note that we work on biological matters so work-related discussions of e.g. animal reproduction are appropriate).</p> <p>We expect members to follow these guidelines at any lab-related event.</p> <p>If you have experienced harassment, notice that someone else is being harassed, or have any other concerns, please contact Steven Roberts  (SAFS Graduate Program Coordinator and PI) or Amy Fox (SAFS Graduate Program Adviser) immediately.</p>"},{"location":"Code-of-Conduct/#support-resources-at-uw","title":"Support Resources at UW","text":"<ul> <li> <p>Compliance Office (title IX, ADA, Compliance)</p> </li> <li> <p>UW title IX coordinator (federal civil rights law)</p> </li> <li> <p>UW Safe Campus</p> </li> <li> <p>UW Q Center (Advocacy, mentoring, and support for queer students)</p> </li> <li> <p>Disability Resources</p> </li> <li> <p>UW Counseling Center</p> </li> <li> <p>UW Health and Wellness </p> </li> <li> <p>UW Livewell Site (wellness training site)</p> </li> </ul> <p>Modified from Titus Brown's Code of Conduct. Original source and credit: http://2012.jsconf.us/#/about &amp; The Ada Initiative. Please help by translating or improving: http://github.com/leftlogic/confcodeofconduct.com. This work is licensed under a Creative Commons Attribution 3.0 Unported License</p>"},{"location":"Computing-Best-Practices/","title":"Best Practices","text":"<p>There are a variety of hardware and software options and combinations available to you. While there are few concrete rules, here is an attempt to guide your success.</p> <p>Resources for thinking about open and reproducible scientific computing.</p>"},{"location":"Computing-Best-Practices/#practical-aspects","title":"Practical Aspects","text":"<p>Foremost, code should be written so someone else could easily run. This means they have access and can understand.</p> <p>1) Code should be in a Github repository </p> <p>2) Organize your data and code. </p> <p>Here's an example of how repos should be organized. Note that each directory contains a <code>README.md</code>, which describes the contents of each directory (and, sometimes even describes each file in that directory).</p> <p>Create a directory called <code>gitrepos</code> and then keep all subsequent repositories within it.</p> <pre><code>gitrepos$ tree\n\n.\n\u251c\u2500\u2500 &lt;GitHub username&gt;\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Project-01\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 code\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 01-FastQ-QC.Rmd\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 02-DESeq2\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 genome-features\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 raw\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 outputs\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 01-FastQ-QC\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 figures\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 02-DESeq2\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 figures\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 RobertsLab\n    \u251c\u2500\u2500 lab-website\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n    \u251c\u2500\u2500 README.md\n    \u251c\u2500\u2500 resources\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n    \u2514\u2500\u2500 tusk\n        \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"Computing-Best-Practices/#working-with-git-and-rstudio-on-raven","title":"Working with Git and RStudio on Raven","text":"Your browser does not support the video tag.  <p>related - getting a Personal Access token - https://d.pr/i/lS8UAr</p>"},{"location":"Computing-Best-Practices/#papers","title":"Papers","text":"<ul> <li> <p>Good enough practices in scientific computing</p> </li> <li> <p>Packaging data analytical work reproducibly using R (and friends)</p> </li> </ul>"},{"location":"Computing-Best-Practices/#workshops","title":"Workshops","text":"<ul> <li>A crash-course in using a project-oriented workflow with Git + GitHub in scientific research</li> </ul>"},{"location":"Computing-Best-Practices/#courses","title":"Courses","text":"<ul> <li> <p>FISH546 - Bioinformatics for Environmental Sciences</p> </li> <li> <p>FISH274 - Introduction to Data Analysis for Aquatic Sciences</p> </li> <li> <p>Data Carpentry for Biologists</p> </li> </ul>"},{"location":"Computing-Hardware/","title":"Roberts Lab Computing","text":"<p>Using computers is an integral part of Roberts Lab activities. The majority of our projects take on some form of bioinformatics analysis and manipulation of large data sets. Although we don't perform any high level programming, you will need to become familiar with basic command line syntax.</p> <p>Below is a list of computing resources we have available, as well as some links to help you begin learning.</p>"},{"location":"Computing-Hardware/#accounts","title":"Accounts","text":"<p>You will need accounts with the following services in order to minimally function in the Roberts Lab:</p> <ul> <li> <p>GitHub: Needed for posting/responding to RobertsLab/resources Issues</p> </li> <li> <p>Slack: Needed for participation in the Roberts Lab Slack channels</p> </li> </ul>"},{"location":"Computing-Hardware/#computers","title":"Computers","text":"<p>You're free to use your own computer for any computing task that you wish. However, some of the computing work that you will perform will require lengthy run times. As such, we have computers available for you to use. Plus, Roberts Lab computers have better processors and much more RAM, which will allow you to keep your computer free for doing fun stuff, like reading Facebook (or scientific papers).</p>"},{"location":"Computing-Hardware/#local-computers","title":"Local Computers","text":"<p>Here is a table of computers we have in the lab that are available for use:</p> Name Operating System Location CPU Cores Memory Storage Primary Use External Drives genefish macOS Sierra (10.12), Windows 7 230 2.3 GHz Intel Core i7 Quad Core 16GB 1TB roadrunner Ubuntu (16.04.1) 213 16 48GB 1.9TB ostrich El Capitan (10.11.5) 213 16 48GB 1.9TB hummingbird Mavericks (10.8.2) 213 16 48GB 1.9TB 1.5TB Windows 7 Enterprise (64-bit) 228 qPCR woodpecker Windows 7 Enterprise (64-bit) 209 16 64GB 2TB Bioanalyzer;NanoDrop;NanoPore;proteomics swoose Ubuntu 16.04.1/Windows 10 Pro (64-bit) 209 24 72GB 1.5TB Sam 8TB swan Windows 7 Enterprise (64-bit) Brinnon 24 72GB 500GB titrator raven Ubuntu (18.04LTS) 213 48 256GB 1TB 2 x 1TB <p>A more detailed spreadsheet, including IP addresses is below (Google Sheet). You'll need to request access from Steven or Sam.</p> <ul> <li>Roberts Lab Computers</li> </ul>"},{"location":"Computing-Hardware/#remote-services","title":"Remote Services","text":""},{"location":"Computing-Hardware/#mox-hyak","title":"Mox (Hyak)","text":"<p>We have two nodes (a fancy name for a computer) in the University of Washington super-computing cluster, called Mox (formerly Hyak). They're well-suited for resource-intensive computing, like genome assemblies and shotgun proteomics analyses.</p> <p>Computer specs:</p> Model CPU (dual) Cores RAM (GB) Lenovo NextScale E5-2680 v4 28 512 Lenovo NextScale E5-2680 v4 28 128 <p>Due to the initial steep learning curve, we have a dedicated section on how to use Mox:</p> <ul> <li>New Mox User</li> </ul>"},{"location":"Computing-Hardware/#printers","title":"Printers","text":"<p>You can send print jobs wirelessly to the Brother HL-L2395DW395DW printer in rm 209.</p> <p>Windows computers:</p> <ol> <li> <p>Download the printer driver software to your computer.</p> </li> <li> <p>Add the printer via: Settings-&gt; Devices -&gt; Printers and Scanners. You'll need to enter the IP address of the printer which is listed on the Roberts Lab Computers spreadsheet.</p> </li> </ol> <p>For Macs:</p> <ol> <li> <p>Add the printer via: System preferences-&gt; Printers and scanners. You'll need to enter the IP address of the printer which is listed on the Roberts Lab Computers spreadsheet.</p> </li> <li> <p>You may need to change the 'Use' drop down menu:</p> <ul> <li> <p>Choose 'select software'</p> </li> <li> <p>Select 'Brother HL-L2395DW CUPS'.</p> </li> </ul> </li> <li> <p>You will need to change the Protocol to 'HP Jetdirect-Socket'.</p> </li> </ol>"},{"location":"Computing-Hardware/#software","title":"Software","text":"<p>To limit clutter on this page, we've assembled a list of software currently installed on each lab computer (including our Mox node):</p> <ul> <li>Lab Software</li> </ul> <p>If you need/want any particular software installed that isn't on the list, please submit a GitHub Issue. Please consider that we prefer to use free, open-source software.</p>"},{"location":"Computing-Hardware/#reproducibility","title":"Reproducibility","text":"<p>Reproducibility is of the utmost importance to your, and the Roberts Lab, success! This means that someone (ironically, usually yourself) should be able to look at your notebook and get the same results you did by executing the same commands with the same files you used.</p> <p>The easiest and most robust means that we've found to aid in this goal is through the use of a Jupyter Notebook. A Jupyter Notebook serves as a substitute for your Terminal (i.e. the place where you normally run your commands) and documents all commands that you run in a given session.</p> <ul> <li>Review our guide for using Jupyter Notebooks</li> </ul>"},{"location":"Computing-Hardware/#learning-other-resources","title":"Learning &amp; Other Resources","text":""},{"location":"Computing-Hardware/#data-management-reproducibility-and-collaboration","title":"Data Management, Reproducibility, and Collaboration","text":"<p>Please be sure to read the article linked below. It is a great starting point on understanding how to properly manage and manipulate data.</p> <ul> <li>Good Enough Practices in Scientific Computing (Wilson et al, 2017)</li> </ul>"},{"location":"Computing-Hardware/#learning-the-basics","title":"Learning the Basics","text":"<p>If you are new to using the command line (and/or other languages like R and Python), don't worry! We all were (and still are), so we know how you feel! The links below are lessons that take you through the basics - no prior experience needed!</p> <ul> <li> <p>Software Carpentry Introduction to The Shell (command line)</p> </li> <li> <p>Software Carpentry Introduction to Python</p> </li> <li> <p>Software Carpentry Introduction to R</p> </li> </ul>"},{"location":"DEI-Resources/","title":"DEI Resources","text":""},{"location":"DEI-Resources/#support-resources-at-uw","title":"Support Resources at UW","text":"<ul> <li> <p>Title IX office (federal gender equity law)</p> </li> <li> <p>UW Safe Campus</p> </li> <li> <p>UW Q Center (Advocacy, mentoring, and support for queer students)</p> </li> <li> <p>Disability Resources</p> </li> <li> <p>UW Counseling Center</p> </li> <li> <p>UW Health and Wellness</p> </li> </ul>"},{"location":"DEI-Resources/#groups-and-committees","title":"Groups and Committees","text":"<ul> <li> <p>GO-MAP: Supporting Graduate Students of Color at the University of Washington https://grad.uw.edu/equity-inclusion-and-diversity/go-map/</p> </li> <li> <p>SAFS DEI Committee: https://fish.uw.edu/about/diversity-equity-and-inclusion/safs-equity-inclusion-committee/</p> <ul> <li>SAFS DEI Committee GitHub for suggested action items: https://github.com/OARS-SAFS/DEI/issues</li> </ul> </li> <li> <p>SAFS DEI Slack channel: https://join.slack.com/t/safs-community/shared_invite/zt-uzytnche-1JagEpn8NxUEm6~tTi2izg (navigate to DEI page) </p> </li> <li> <p>SAFS 360: https://fish.uw.edu/about/diversity-equity-and-inclusion/safs-360/</p> </li> <li> <p>College of the Environment Community Equity Initiative: Organizational information here </p> </li> <li> <p>College of the Environment DEI Committee: https://environment.uw.edu/about/diversity-equity-inclusion/college-diversity-committee/</p> </li> <li> <p>Departmental Diversity Committees: https://grad.uw.edu/equity-inclusion-and-diversity/programs-resources/for-faculty-and-staff/departmental-diversity-committees/</p> </li> <li> <p>UW Postdoc Diversity Alliance: https://sites.uw.edu/uwpda</p> </li> <li> <p>Peaks and professors club: hike with UW faculty members to network while enjoying the outdoors.</p> <ul> <li>Facebook page: https://www.facebook.com/peaksandprofessorsuw/</li> <li>Send a request to join the mailing list: peaksandprofessorsuw@gmail.com</li> </ul> </li> <li> <p>List of organizations that are striving to bring more diversity to the outdoors. https://www.adventure-journal.com/2020/06/these-orgs-could-use-your-help-to-bring-more-diversity-to-the-outdoors/</p> <ul> <li>The College of the Environment communities are often consisting of people who enjoy and spend time in nature. Gatekeeping \u201coutdoorsy-ness\u201d is a serious issue that often excludes women, people of color, lower income individuals, and more. This can often make it difficult to participate in casual conversations at work/school or after-work/weekend activities, which can create a feeling of exclusion from the community as a whole.</li> </ul> </li> </ul>"},{"location":"DEI-Resources/#uw-centers","title":"UW Centers","text":"<ul> <li> <p>Kelly Ethnic Cultural Center. ECC frequently has talks, film showings, and more that are centered around DEI issues or celebrating different cultures. See there website for upcoming events: https://depts.washington.edu/ecc/event/</p> </li> <li> <p>Center for International Relations &amp; Cultural Leadership Exchange (CIRCLE) https://www.washington.edu/circle/</p> <ul> <li>Events calendar: https://www.washington.edu/circle/calendar/</li> </ul> </li> </ul>"},{"location":"DEI-Resources/#indigenous-resources-and-land-acknowledgement","title":"Indigenous Resources and Land Acknowledgement","text":"<ul> <li>Text your zip code or your city and state (separated by a comma) to (907) 312-5085 and a bot will respond with the names of the Native lands that correspond to that region</li> <li>Duwamish Tribe Land Acknowledgement</li> <li>\u00e2pihtawikosis\u00e2n Beyond Territorial Acknowledgements</li> <li>U.S. Department of Arts and Culture - Honor Native Land:  A Guide and Call to Acknowledgement</li> </ul>"},{"location":"DEI-Resources/#training-continuing-education","title":"Training &amp; Continuing Education","text":"<ul> <li> <p>Various DEI trainings available offered by UW:  https://hr.uw.edu/diversity/dei-related-trainings/pod-trainings/</p> <ul> <li>These do cost money, but department budget codes are available to offset that cost. If you're interested contact the SAFS administrator Jonas Louie at jinl@uw.edu for budget code and sign up information.</li> </ul> </li> <li> <p>\"Strategies to address unconscious bias\" https://diversity.ucsf.edu/resources/strategies-address-unconscious-bias</p> </li> <li> <p>\"Eight tactics to identify and reduce your implicit biases\" https://www.aafp.org/journals/fpm/blogs/inpractice/entry/implicit_bias.html</p> </li> <li> <p>Implicit bias test from Harvard: https://implicit.harvard.edu/implicit/takeatest.html</p> </li> </ul>"},{"location":"DEI-Resources/#articles-and-reading","title":"Articles and Reading","text":"<ul> <li> <p>Interrupting Bias in Academic Settings Feb 2017. From the National Center for Women &amp; Information Technology. \u201cUse this resource to help you practice ways to interrupt bias in real-life situations.\"</p> </li> <li> <p>Black Scientists Call Out Racism in Their Institutions June 2020. \u201cBlack scientists and students are sharing their experiences on Twitter of being dismissed and discriminated against in academia using the hashtag #BlackintheIvory.\u201d</p> </li> <li> <p>The science divide: Why do Latino and black students leave STEM majors at higher rates? May 2019. \u201cIf there\u2019s demonstrated, strong interest in STEM among black and Latino youth, why would you see higher departure rates for these students?\u201d the professor said. \u201cIt\u2019s not about interest or academic ability. So what causes this?\u201d</p> </li> <li> <p>Facilitating Critical Conversations With Students [PDF] December 2019. \u201c It\u2019s a conversation that explores the relationships between identity and power, that traces the structures that privilege some at the expense of others, that helps students think through the actions they can take to create a more just, more equitable, world.\u201d</p> </li> </ul>"},{"location":"DEI-Resources/#bimonthly-diversity-equity-and-inclusion-meetings","title":"Bimonthly Diversity, Equity and Inclusion Meetings","text":"<p>Biweekly DEI meetings (~1 hour) provide a space to learn, discuss, and engage in initiatives that further lab members' understanding about the institutionalized oppression present in academia. Example activities include discussing articles read prior to the meeting, tackling action items to improve DEI in the lab and/or department, and more. See log of topics.</p> <p>Code of Conduct for DEI Meetings</p> <p>We are dedicated to providing a welcoming and supportive environment for all people, regardless of background, identity, physical appearance, or manner of communication. Any form of language or behavior used to exclude, intimidate, or cause discomfort will not be tolerated. This applies to all course participants (instructor, students, guests). In order to foster a positive and professional learning environment, we will be using progressive stack discussion methods and these discussion rules:</p> <p>Discussion Rules</p> <ol> <li>We will listen with the intent to understand.</li> <li>We will monitor our own air time, aiming to share the space and time so others may participate as well.</li> <li>We will respect those who do not wish to speak.</li> <li>We will use \u201cI\u201d statements as opposed to generalizations.</li> <li>We will not ask anyone to speak on behalf of any group we perceive them to identify with, or that they self-identify with.</li> <li>We will expect discomfort.</li> <li>We will resist the urge to \u201cfix\u201d others\u2019 discomfort.</li> <li>We will elevate impact above intent, and we will apologize when necessary.</li> <li>We will expect and accept non-closure. We acknowledge that these conversations may not be resolved in a single meeting.</li> <li>We will take lessons learned, but not others\u2019 stories, out of this space. </li> <li>We will not participate in ad hominem attacks.</li> </ol>"},{"location":"Data-Management/","title":"Data Management","text":"<p>This page is intended to document all aspects of data management, from the day-to-day, formal NGS and proteomics plans, and general archiving options. Inspiration for this has been provided by Tim Essington and Gordon Holtgrieve who have developed similar documentation.</p> <p>Data must be:</p> <ol> <li> <p>Adequately described via metadata.</p> </li> <li> <p>Managed for data quality.</p> </li> <li> <p>Backed up in a secure manner.</p> </li> <li> <p>Archived in an easily reproducible format.</p> </li> </ol>"},{"location":"Data-Management/#metadata","title":"Metadata","text":"<p>All research data must be accompanied with a thorough description of that data from the beginning of the work. Metadata describes information about a dataset, such that a dataset can be understood, reused, and integrated with other datasets. Information described in a metadata record includes where the data were collected, who is responsible for the dataset, why the dataset was created, and how the data are organized.   </p>"},{"location":"Data-Management/#data-quality-standards","title":"Data Quality Standards","text":"<p>Students must take care that protocols and methods are employed to ensure that data are properly collected, handled, processed, used, and maintained, and that this process is documented in the metadata.</p>"},{"location":"Data-Management/#backup-and-storage","title":"Backup and Storage","text":"<p>Primary should be stored in several locations with canonical versions on Gannet (see below).</p> <p>Data, including intermediate analysis, needs to have a url. This most often means it will live on a Network Attached Storage Device (NAS; aka a server).</p>"},{"location":"Data-Management/#gannet","title":"Gannet","text":"<p>Gannet is a Synology RS3618xs NAS :</p> <ul> <li>RS3618xs uses 16TB HDDs (n = 12)</li> </ul> <p>Data on Gannet is backed up in the following ways:</p> <ul> <li> <p>Synology Hybrid RAID</p> <ul> <li>Mirrors data across HDDs, which reduces total storage capacity by 50%</li> <li>Allows for up to two concurrent HDD failures before data loss occurs</li> </ul> </li> <li> <p>Gannet/web folder</p> <ul> <li>One-way sync from Gannet to UW Google Drive via the Synology Cloud Sync app.</li> <li>Backup frequency: Daily</li> <li>Access: Public (read-only)</li> </ul> </li> </ul>"},{"location":"Data-Management/#daily-data-on-gannet","title":"Daily Data on Gannet","text":"<p>Using the Gannet NAS to store your data:</p> <ol> <li>Ask Steven or Sam to generate a user account for you. A folder will be created for you in: <code>gannet/web/</code> Ask Steven/Sam for the name of the folder, as well as your username and password.</li> <li>Upload data to your Gannet web folder:<ol> <li>Navigate to http://gannet.fish.washington.edu/</li> <li>Click on <code>Web Browser login</code>.<ol> <li>If it's your first time visiting this page, your browser will present you with a warning about an insecure site or bad certificate. That's OK. Click on the option to add an exception for this site.</li> </ol> </li> <li>Enter username and password. (NOTE: If it's your first time accessing your account, please change your password by clicking on the silhouette in the upper right corner, then \"Personal\" in the dropdown menu).</li> <li>Navigate to File Station &gt; web &gt; your_folder (If you don't see the File Station icon, click on the icon of four squares in the upper left corner and select File Station from the subsequent menu).</li> <li>Click-and-drag files from your computer to your <code>gannet/web</code> folder.</li> </ol> </li> </ol> <p>Files that you have uploaded to your_folder are publicly viewable: http://gannet.fish.washington.edu/your_folder</p> <p>You can use the URLs for your files for linking in your notebook.</p> <p>IMPORTANT!</p> <p>All folders need to contain a readme file.</p> <p>The readme files should be plain text (i.e. do not create/edit the file with a word processor like Microsoft Word or LibreOffice Writer) and should describe the contents of the folder. If there are directories in the same folder as your readme file, the directory names should be listed and a brief description of their contents should be provided.</p> <p>Please refrain from using any non alpha-numeric (including spaces) in file and folder names.</p>"},{"location":"Data-Management/#ngs-data-management-plan","title":"NGS Data Management Plan","text":"<p>Raw Data</p> <ol> <li> <p>As sequencing facility provides data, files are downloaded to our local NAS (owl), in the correct species subdirectory within <code>nightingales</code>.  http://owl.fish.washington.edu/nightingales/</p> </li> <li> <p>MD5 checksums are generated and compared to those supplied by the sequencing facility.</p> <ol> <li>Append the generated MD5 checksums to the <code>checksums.md5</code> file. If that file does not yet exist, create it, and add the generated checksums to the new <code>checksums.md5</code> file.</li> </ol> </li> <li> <p>The Nightingales Google Spreadsheet is updated.</p> <ol> <li>Each library (i.e. each sample with a unique sequencing barcode) is entered in its own row.</li> <li><code>SeqID</code> is the base name of the sequencing file (i.e. no file extensions like \".fq.gz\" or \".gz\")</li> <li>Each library receives a unique, incremented <code>Library_ID</code> number.</li> <li>Each library receives a <code>Library_name</code>; this may or may not be unique.</li> <li><code>SeqSubmissionDate</code> and <code>SeqReceiptDate</code> should be entered in yyyymmdd format. </li> </ol> </li> </ol> <p>Taxa Representation in Nightingales </p> <p></p> <p>Backup </p> <ul> <li> <p>The Google Docs spreadsheet Nightingales Google Spreadsheet is backed up on a regular basis by downloading tab-delimited file and pushing to LabDocs Repository, with the file name <code>Nightingales.tsv</code></p> </li> <li> <p><code>owl/nightingales</code> is automatically backed up to two locations, both managed by Synology apps:</p> </li> <li> <p>Amazon Glacier: Backup task occurs weekly on Mondays at 00:00.</p> </li> <li> <p>CloudSync to UW Google Drive: Backup occurs in real-time any time new files, or changes to existing files, are detected.</p> </li> </ul> <p>SRA Upload</p> <ul> <li>Sam will upload all high-throughput sequencing data to the NCBI Sequence Read Archive (SRA). Once submitted, the BioProject accession and a link to the NCBI BioProject will be added to the <code>SRA</code> column in the Nightingales Google Spreadsheet.</li> </ul>"},{"location":"Data-Management/#proteomics-data-management-plan","title":"Proteomics Data Management Plan","text":"<p>Raw Data</p> <ol> <li> <p>As sequencing facility provides data, files are downloaded to our local NAS (owl), in the root <code>phainopepla</code> directory.  http://owl.fish.washington.edu/phainopepla/ These data are organized by species, then by mass spectrometer run date (e.g. YYYY-MM-DD). For each run date, all <code>RAW</code> files (including blanks, sample, and QC files) should be included in the directory with their original names. Inside of the YYYY-MM-DD directory there should be a Readme file with the following information: Description of each file (eg. treatment, blank, etc), experimental design, link to more information.</p> </li> <li> <p>The Spreadsheet is then updated. Each \"mass spectrometer run date\" will be a new row in the sheet.</p> </li> </ol>"},{"location":"Data-Management/#histology-data-management-plan","title":"Histology Data Management Plan","text":"<p>1) Before histology cassettes are sent off for processing, fill out the Histology-databank with all relevant information at the sample(tissue) level. Reserve space for blocks and slides by adding block-location and slide-location information. Each sample should have a <code>unique-sample-ID</code> which is:</p> <ul> <li><code>experiment-date_organism-label_tissue</code></li> </ul> <p>2) After histology blocks are returned, photograph blocks and slides and label such that the location of each sample(tissue) can be readily understood.</p> <p>3) Image each sample(tissue). Use the following convention for saving images:</p> <ul> <li> <p>`[FULLTIMESTAMP]-[unique-sample-ID]-[magnification].jpeg</p> </li> <li> <p>e.g. <code>20180924-angasi013-10x.tif</code></p> </li> </ul> <p>All images should be stored in the proper species directory at http://owl.fish.washington.edu/hesperornis/</p>"},{"location":"Data-Management/#data-archiving","title":"Data Archiving","text":"<p>The goal for data archiving is to make your research easily understandable and reproducible in the future. It is therefore incumbent upon the researcher that, by the end of a project, care and effort is given to providing a highly organized and traceable accounting of the research that is archived in perpetuity.  At a minimum, this archive should include: raw and full processed data, complete metadata, all computer code, and any research products (manuscripts, published articles, figures, etc.). You will find that creating a usable data archive is much easier to do as you go, rather than waiting until the end of your project!</p>"},{"location":"Data-Management/#options-include","title":"Options include","text":"<ul> <li>GitHub -&gt; Zenodo.     </li> <li>Figshare</li> <li>UW ResearchWorks</li> <li>Open Science Framework</li> </ul>"},{"location":"Data-Management/#easy-file-upload-for-collaborators","title":"Easy file upload for Collaborators","text":"<p>Finally, data will be most usable if it is as flexible as possible.  So an excel spreadsheet with different information on different tabs is not very flexible.  Much better to have a text file, with the data in \u201clong form\u201d.  This means rather than have a ton of columns, have a ton of rows.</p> <p>see   Broman KW, Woo KH. (2017) Data organization in spreadsheets. PeerJ Preprints 5:e3183v1 https://doi.org/10.7287/peerj.preprints.3183v</p>"},{"location":"Digital-Media/","title":"Digital Media","text":"<p>Media including photos, videos and audio can really fall into two categories. In some instances they might fall under data. In that case treat them as such and follow Data Management guidelines. Another category might be considered candids.</p> <p>Candid media should be place in this Team Drive. If you need access please submit an issue. This has been developed in order to populate social media platforms, grant reports, and otherwise share in the adventures in science.</p>"},{"location":"Digital-Media/#videos","title":"Videos","text":""},{"location":"Digital-Media/#hatchery-and-field-work","title":"Hatchery and Field Work","text":"<p>Laura takes us through the process of screening Olympia oyster larvae.</p> <p>Tour of the Chew hatchery and Laura's research given by Beyer.</p> <p>Research Summary video highlighting our work with Geoduck clams and environmental conditioning.</p> <p>Release of sablefish with a satellite tag.</p>"},{"location":"Digital-Media/#how-to","title":"How-to","text":""},{"location":"Digital-Media/#defenses","title":"Defenses","text":""},{"location":"Digital-Media/#miscellany","title":"Miscellany","text":""},{"location":"Environment-and-Expectations/","title":"Environment and Expectations","text":""},{"location":"Environment-and-Expectations/#lab-environment","title":"Lab Environment","text":"<p>The purpose of the lab group is to grow as scientists and as people. Our intent is to maintain an open, welcoming, and communicative environment among all lab members. You are encouraged to approach any member of the lab with questions or issues related to science or otherwise. As the old idiom goes, \"there are no stupid questions\". It is okay to make mistakes, but it is not okay to hide your mistakes from others - addressing them and learning from them is how we grow as scientists. Similarly, if you disagree with lab members on any issue you are encouraged to challenge them directly.</p> <p>To foster the intended lab environment, everyone must follow the code of conduct. Lab members are also expected and encouraged to participate in trainings, committees, and self or group education to strive towards a more equitable, inclusive, and just lab and departmental community. Here is a non-exhaustive list of DEI resources available to you at UW and beyond: DEI-Resources. Additionally, all members of the lab meet \\~1x per week to discuss project progress, diversity, equity, and inclusion issues, and to get help from others. Here is an example of our weekly meeting schedule.</p> <p>NOTE: You are expected to attend all lab meetings, within reason (but no need to ask permission to miss an occasional meeting). Science hour is optional, but highly encouraged!</p> <ul> <li> <p>Biweekly Project Progress Lab Meetings (1.5 hour): All members discuss their activities since the last meeting, planned activities for the next two weeks, and to get help from lab members on project-related issues.</p> </li> <li> <p>Biweekly Diversity, Equity and Inclusion Meetings (1.5 hour): This biweekly meeting provides space to learn, discuss, and engage in initiatives that further lab members' understanding about the institutionalized oppression present in academia. </p> </li> </ul> <p>Code of Conduct for DEI Meetings</p> <p>We are dedicated to providing a welcoming and supportive environment for all people, regardless of background, identity, physical appearance, or manner of communication. Any form of language or behavior used to exclude, intimidate, or cause discomfort will not be tolerated. This applies to all course participants (instructor, students, guests). In order to foster a positive and professional learning environment, we will be using progressive stack discussion methods and these discussion rules:</p> <p>Discussion Rules</p> <ol> <li>We will listen with the intent to understand.</li> <li>We will monitor our own air time, aiming to share the space and time so others may participate as well.</li> <li>We will respect those who do not wish to speak.</li> <li>We will use \"I\" statements as opposed to generalizations.</li> <li>We will not ask anyone to speak on behalf of any group we perceive them to identify with, or that they self-identify with.</li> <li>We will expect discomfort.</li> <li>We will resist the urge to \"fix\" others' discomfort.</li> <li>We will elevate impact above intent, and we will apologize when necessary.</li> <li>We will expect and accept non-closure. We acknowledge that these conversations may not be resolved in a single meeting.</li> <li>We will take lessons learned, but not others' stories, out of this space.</li> <li> <p>We will not participate in ad hominem attacks.</p> </li> <li> <p>Weekly Science Hour (Fridays): A casual meeting to hang out, and sometimes tackle science issues/questions with the \"hive mind\" - e.g. we spend time debugging a script, interpreting a statistical analysis, interpreting/providing feedback on figures, or discuss science concepts that require more time than is available during the biweekly lab meetings.</p> </li> <li> <p>Practice presentation meetings (occasionally): When members prepare a presentation for a conference or symposium (etc.), they are expected to give a practice presentation to the lab group. For a 15 minute presentation, we schedule at least 1hr to deliver it, then receive lots of feedback. This exercise is invaluable, and greatly improves presentations.</p> </li> </ol>"},{"location":"Environment-and-Expectations/#roberts-mentoring-approach","title":"Roberts Mentoring Approach","text":"<p>My mentoring approach will be somewhat specific per person, however generally I view my role as providing you the resources to succeed in your educational experience. There will be regular lab meetings where we primarily address any challenges members might be having while reaching their goals. Goals are important and I will working with you in developing long-term goals, however you will need to develop monthly goals. You might not always achieve them, but this helps you stay focused. Beyond lab meetings we have established a number means of communication.</p> <p>Utmostly important as you get into research, is to communicate issues and challenges. I will work with you to address these, though often we might find that the most effective solutions are resources outside of the lab.</p> <p>I will provide honest feedback in an effort to push you to be your best. This will include pushing you to consistently be stepping back to re-evaluate your work in a larger context, and consider areas of improvement.</p> <p>The predominantly white and cis/het, amongst other factors, community at SAFS may not meet everyone's needs. For this reason, you are encouraged to seek mentorship and community in the way that is best for you.</p>"},{"location":"Environment-and-Expectations/#personnel-expectations","title":"Personnel Expectations","text":""},{"location":"Environment-and-Expectations/#research-methods","title":"Research Methods","text":"<p>A lot of our research involves computational analysis of large, novel datasets. You will need to be competent in computing skills including basics of bash and R. A common task you should be able to accomplish is installing and running Blast on your own computer. You should also be familiar with Jupyter Notebooks. As might be evident, we using GitHub extensively and you will be using this to document code and data (and everything else).</p> <p>Electronic Open Lab Notebooks are also central to the lab. You are required to document your activity in real time. This will include not only benchwork and computational work, but also reflections, questions, and monthly goals.</p> <p>Writing. Always be doing it. Do not wait until you have completed a project but rather write the methods as you carry them out (or preferably before). This goes hand in hand with the lab notebook. Document your work in a detail that you and a stranger can completely reproduce it in 5 years.</p>"},{"location":"Environment-and-Expectations/#graduate-students","title":"Graduate Students","text":"<p>Graduate school is not easy, and not for everyone. Graduate school will be very challenging, and for most, very rewarding. Graduate school is not a job where you check-in and check-out each day, but rather an educational endevour where you gain a deep understanding of a scientific area and complete your tenure by contributing a valuable research product, that substantially advances knowledge. Understanding this fact might help you deal with the challenges and frustrations you will face.</p> <p>There is a lot going on during your graduate education. Staying organized and not overwhelmed is key. In the same vein, time-management is key. There are several strategies for this. I suggest reading \"Getting Things Done\". Finding time outside of lab to recharge your mind and body is essential.</p>"},{"location":"Environment-and-Expectations/#expectations-on-performance","title":"Expectations on Performance","text":"<p>Graduate students will complete a Graduate Research Plan that will be revisited on a quarterly basis.</p> <p>This document is in part meant to delineate expected progress on thesis research. If there is inadequate progress made on thesis research (determined in part by entire committee when in place), action will be taken at the department level (commonly a written warning with specific expectations outlined). If targets are not reached, the situation will be reported to the UW Graduate School where a formal probation period could be initiated. </p> <p>Research Credit Hours: The following information regarding research credit hours should be confirmed with SAFS Graduate Program Advisor, but typically a graduate student will need to be signed up for at least 10 credit hours during the academic year. If these are not graded courses they should be research credit hours. Note, with the exception of summer, students are limited to a maximum of 10 credits per quarter of any combination of courses numbered 600, 700, or 800. Unsatisfactory progress on thesis research could result in no credit (NC).</p> <p>Graduate Student stipends are paid in a variety of manners. There are often specific responsibilities associated with this. If you are a TA you are expected to perform duties set forth for the position no more than 20 hours a week. If you are asked to perform duties that exceed 20 hours a week you need to inform Professor Roberts ASAP.</p> <p>Another common form of stipend payment is a RA. A RA can be associated with a faculty grant or certain funds from SAFS are distributed as an RA. Responsibilities as set forth as part of a RA require 20 hours of effort per week. If you are unclear of responsibilities of a RA for any given quarter please contact Professor Roberts ASAP. </p> <p>To simplify efficient documentation of progress (useful for grant reporting) students on RAs will need summarize activity at the end of each month (or end of quarter) when funded on an RA. Please use this form: https://forms.gle/ePCTJvBo2XnazGf47</p> <p>Prospective graduate students interested in graduate school and joining the lab, please submit this form. Please feel free to contact current graduate students for more information.</p>"},{"location":"Environment-and-Expectations/#undergraduate-students","title":"Undergraduate students","text":"<p>I enjoy having the opportunity to provide motivated undergraduate students with a chance to gain hands-on lab experience and get a better understanding of an array of approaches that can be used to study aquatic organisms. I feel this is an important component of your education. Depending on your status (i.e. intern, work-study, course credit, capstone etc.) there will likely be specific details that will need to be discussed.</p> <p>Undergraduates must review and sign the Undergraduate Commitment Contract prior to starting in the lab.</p>"},{"location":"Environment-and-Expectations/#postdocs","title":"Postdocs","text":"<p>Postdocs should complete an Individual Development Plan (e.g. https://myidp.sciencecareers.org/) that should be reviewed and updated on a quarterly basis.</p>"},{"location":"Experiment-Database/","title":"Experiment Database","text":"<p>Holding place for a database / link to database of all Roberts Lab experiments </p> <p>Proposed fields for database:  - Experiment Dates  - Species  - Very short description  - Project lead / contact person  - Samples collected &amp; status of samples - Type of data produced with links to where it's stored  - Status of experiment / project  - Products (i.e. papers, presentations, other write-ups)  </p> <p>Preliminary database is located in a Google Spreadsheet in the Roberts Lab Google Drive </p>"},{"location":"External-Communication-and-Funding/","title":"External Communication","text":"<p>This is a living document that lists conferences, community outreach, and funding sources that past and present lab members recommend.  </p>"},{"location":"External-Communication-and-Funding/#conferences-pertinent-travel-grants","title":"Conferences &amp; pertinent travel grants","text":"<ol> <li> <p>National Shellfisheries Association (NSA) annual meeting. March, USA, location changes annually.  Travel grant: NSA Student Endowment Fund </p> </li> <li> <p>Pacific Shellfish Growers' Association / Pacific Coast NSA chapter annual meeting. September, PNW. Travel grant: Apply for travel award upon submitting poster/presentation abstract. </p> </li> <li> <p>Aquaculture America February, USA, location changes annually. </p> </li> <li> <p>Salish Sea Ecosystem Conference. April, Washington or British Columbia. </p> </li> <li> <p>Western Society of Naturalists. October/November, U.S. west coast. </p> </li> <li> <p>Association for the Sciences of Limnology and Oceanography (ASLO) Aquatic Sciences. February/March, international. </p> </li> <li> <p>Ecological Society of America. August, USA, location changes annually. </p> </li> <li> <p>American Fisheries Society. Various subchapter meetings. </p> </li> <li> <p>WA Sea Grant Conference for Shellfish Growers. March, Puget Sound (usually Alderbrook Resort).  </p> </li> <li> <p>Plant and Animal Genome Conference. January, San Diego. </p> </li> </ol>"},{"location":"External-Communication-and-Funding/#general-conference-funding-for-uw-students","title":"General conference funding for UW Students:","text":"<ul> <li>College of the Environment Student Travel Award: $750 for North America, $1,000 for international. Can only receive once during degree. Post-docs are eligible.</li> <li>UW Graduate School: $300 for domestic, $500 for international.  SAFS provides matching funds.</li> <li>Fisheries Interdisciplinary Network of Students: Funding for SAFS-affiliated graduate students for travel and/or poster printing and publication costs. Awards preferentially given to individuals who have not received it previously and those that are involved in the department.</li> </ul>"},{"location":"External-Communication-and-Funding/#posters","title":"Posters","text":"<ul> <li>How to print a poster</li> <li>Traditional poster example</li> <li>Poster 2.0 example</li> </ul>"},{"location":"External-Communication-and-Funding/#community-outreach-education","title":"Community Outreach &amp; Education","text":"<ul> <li>Students Explore Aquatic Sciences: SEAS is an outreach program at UW. The program provides project-based learning activities, free of charge, for K-12 students in the Seattle area.</li> <li>Ocean Inquiry Project </li> </ul>"},{"location":"External-Communication-and-Funding/#fellowships-research-grants","title":"Fellowships &amp; Research Grants","text":"<p>The following are sources of funding, and people in the Roberts Lab who previously received them (with year)  </p>"},{"location":"External-Communication-and-Funding/#graduate-student-funding","title":"Graduate Student Funding","text":"<p>National Science Foundation Graduate Research Fellowship Program (NSF GRFP) - 3 years of stipend funding - Deadline: ~October annually  - Prospective grad students can apply  - Recipients: Laura Spencer (2016), Yaamini Venkataraman (2018) </p> <p>UW College of the Environment Hall Conservation Genetics Research Fund - $6,000 to be used towards within one year of award. - Deadline: ~March annually  - Recipients: James Dimond (2016), Laura Spencer (2017), Yaamini Venkataraman (2017)</p> <p>National Shellfisheries Association research grants:    - The Melbourne R. Carriker Student Research Grant, $1,250. Recipients: Laura Spencer (2017)   - Michael Castagna Student Grant for Applied Research, $1,250   - George R. Abbe Student Research Grant, $1,250 </p> <p>Libbie H. Hyman Memorial Scholarship for undergrads also  - $1,840 towards invertebrate coursework or research at a field station (e.g. Friday Harbor Labs). Laura Spencer (2017)</p> <p>Other Field Station Research Grants for undergrads also</p>"},{"location":"External-Communication-and-Funding/#postdoc-funding","title":"Postdoc Funding","text":""},{"location":"External-Communication-and-Funding/#grants-for-study-abroad-internships","title":"Grants for study abroad / internships","text":"<ul> <li>NSF Graduate Research Opportunity Worldwide (GROW); only available to NSF GRFP recipients. Recipients: Laura Spencer (2018) </li> <li>Australia-Americas PhD Research Internship program. Recipients: Laura Spencer (2018) </li> </ul>"},{"location":"Genomic-Resources/","title":"Genomic Resources","text":"<p>Here we try to compile genomic resources such that they are readily available and somewhat described. An effort will be made to keep respective index files alongside so these files can be directly used in IGV etc.</p> <p>Related Resources - Archived Versions of this page - 091319;</p> <ul> <li>Nightingales (Google Sheet) : Database of all raw high-throughput sequencing data</li> </ul>"},{"location":"Genomic-Resources/#chionoecetes-bairdi","title":"Chionoecetes bairdi","text":"<ul> <li>cbai_genome_v1.01.fasta (18MB)<ul> <li>MD5 = <code>5a08d8b0651484e3ff75fcf032804596</code></li> <li>BUSCOs: <code>C:0.4%[S:0.3%,D:0.1%],F:0.2%,M:99.4%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_genome_v1.01.fasta.fai</li> </ul> </li> <li>Assembly from 20200923<ul> <li>Q7-filtered NanoPore data. Includes Hematodinium-infected sample.</li> <li>Subset of <code>cbai_genome_v1.0.fasta</code> with contigs &gt;1000bp</li> </ul> </li> </ul> </li> <li>cbai_genome_v1.0.fasta (19MB)<ul> <li>MD5 = <code>2f3b651bb0b875b0287e71e315cad59a</code></li> <li>BUSCOs: <code>C:0.4%[S:0.3%,D:0.1%],F:0.3%,M:99.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_genome_v1.0.fasta.fai</li> </ul> </li> <li>Assembly from 20200917<ul> <li>Q7-filtered NanoPore data. Includes Hematodinium-infected sample. Assembly Stats Table (Google Sheet) RNA-seq sample list</li> </ul> </li> </ul> </li> <li>cbai_transcriptome_v4.0.fasta<ul> <li>MD5 = <code>6450d6f5650bfb5f910a5f42eef94913</code></li> <li>BUSCOs: <code>C:73.8%[S:45.8%,D:28.0%],F:7.9%,M:18.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v4.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW BLASTx against NCBI C.opilio genome.</li> </ul> </li> <li>cbai_transcriptome_v3.1.fasta<ul> <li>MD5 = <code>aeec8ffbf8fa44fb1750caee6abaf68a</code></li> <li>BUSCOs: <code>C:96.5%[S:40.3%,D:56.2%],F:2.2%,M:1.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v3.1.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with non_Alveolata. Derived from <code>cbai_transcriptome_v3.0.fasta</code></li> </ul> </li> <li>cbai_transcriptome_v3.0.fasta<ul> <li>Assembly from 20200518</li> <li>MD5 = <code>5516789cbad5fa9009c3566003557875</code></li> <li>BUSCOs: <code>C:97.6%[S:39.1%,D:58.5%],F:1.6%,M:0.8%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v3.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with no taxonomic filter.</li> </ul> </li> <li>cbai_transcriptome_v2.1.fasta<ul> <li>MD5 = <code>1fb788175f9bb7cd5145370a399ae857</code></li> <li>BUSCOs: <code>C:98.3%[S:25.2%,D:73.1%],F:1.4%,M:0.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v2.1.fasta.fai</li> </ul> </li> <li>BLASTx annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with non_Alveolata. Derived from <code>cbai_transcriptome_v2.0.fasta</code></li> </ul> </li> <li>cbai_transcriptome_v2.0.fasta<ul> <li>Also referred to as <code>20200507.C_bairdi.Trinity.fasta</code>.</li> <li>MD5 = <code>01adbd54298495c147767b19ee5c0de9</code></li> <li>BUSCOs: <code>C:98.8%[S:24.9%,D:73.9%],F:0.9%,M:0.3%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v2.0.fasta.fai</li> </ul> </li> <li>BLASTx annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with no taxonomic filter.</li> </ul> </li> <li>cbai_transcriptome_v1.7.fasta<ul> <li>MD5 = <code>032d1f81c7744736ebeefe7f63ed6d95</code></li> <li>Assembly from 20200527</li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.7.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.7.fasta.fai</code></li> </ul> </li> <li>BUSCOs: <code>C:86.7%[S:66.5%,D:20.2%],F:8.2%,M:5.1%,n:978</code></li> <li>BLASTx Annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-UW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.6.fasta<ul> <li>MD5 = <code>46d77ce86cdbbcac26bf1a6cb820651e</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.6.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.6.fasta.fai</code></li> </ul> </li> <li>BUSCOs: <code>C:91.7%[S:62.6%,D:29.1%],F:6.2%,M:2.1%,n:978</code></li> <li>BLASTx Annotation (outfmt6)</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.5.fasta<ul> <li>MD5 = <code>e61d68c45728ffbb91e3d34c087d9aa9</code></li> <li>BUSCOs: C:91.8%[S:64.0%,D:27.8%],F:5.9%,M:2.3%,n:978</li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.5.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.5.fasta.fai</code></li> </ul> </li> <li>Updated assembly from 20200330. Also referred to as <code>20200408.C_bairdi.megan.Trinity.fasta</code></li> <li>BLASTx Annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019, 2020-GW with Arthropoda only reads.</li> </ul> </li> <li>cbai_transcriptome_v1.0.fasta<ul> <li>MD5 = <code>fb28a203154b44b67ec2e2476d96d326</code></li> <li>BUSCOs: <code>C:85.5%[S:64.7%,D:20.8%],F:9.3%,M:5.2%,n:978</code></li> <li>FastA index (<code>samtools faidx</code>)<ul> <li>cbai_transcriptome_v1.0.fasta.fai :   <code>https://owl.fish.washington.edu/halfshell/genomic-databank/cbai_transcriptome_v1.0.fasta.fasta.fai</code></li> </ul> </li> <li>Initial Trinity assembly from 20200122</li> <li>BLASTx Annotation</li> <li>GO Terms Annotation (Trinotate)</li> <li>internal short-hand: includes 2018, 2019 with Arthropoda only reads. editor_options:    markdown:  wrap: 72</li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#cgoreaui","title":"C.goreaui","text":"<p>Genomes:</p> <ul> <li> <p><code>/volume1/web/halfshell/genomic-databank/Cladocopium_goreaui_genome_fa</code> (1.1GB)</p> <ul> <li> <p>MD5 checksum: <code>eb4a1a7ac2fc0cbc6f5c178240beb932</code></p> </li> <li> <p>Downloaded 20230216: https://espace.library.uq.edu.au/view/UQ:fba3259</p> </li> <li> <p>Access to the genome requires agreeing to some licensing provisions (primarily the requirement to cite the publication whenever the genome is used), so we will not be providing any public links to the file.</p> </li> <li> <p>Chen et. al, 2022</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p>`` (tarball gzip; 563MB)</p> <ul> <li> <p>MD5 checksum: ``</p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p><code>/volume1/web/halfshell/genomic-databank/Cladocopium_goreaui_genes_gff3</code> (225MB)</p> <ul> <li> <p>MD5 checksum: <code>ab47babf331507b9284e9d35406aefac</code></p> </li> <li> <p>Downloaded 20230216: https://espace.library.uq.edu.au/view/UQ:fba3259</p> </li> <li> <p>Access to the GFF requires agreeing to some licensing provisions (primarily the requirement to cite the publication whenever the genome is used), so we will not be providing any public links to the file.</p> </li> <li> <p>Chen et. al, 2022</p> </li> </ul> </li> <li> <p><code>Cladocopium_goreaui_genes_gff3.gtf</code> (197MB)</p> <ul> <li> <p>MD5 checksum: <code>97e69a850faf2e6d9b60df828ad02671</code></p> </li> <li> <p>Created 20230217: Data-Wrangling-C.goreaui-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-gigas-cgigas_uk_roslin_v1","title":"Crassostrea gigas - cgigas_uk_roslin_v1","text":"<ul> <li> <p>NCBI Assembly GCF_902806645.1</p> </li> <li> <p>A chromosome-level genome assembly for the Pacific oyster Crassostrea gigas</p> </li> <li> <p>NCBI Crassostrea gigas Annotation Release 102</p> </li> <li> <p>cgigas_uk_roslin_v1_fuzznuc_CGmotif.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_fuzznuc_CGmotif.gff</code> (CG motif track)</p> </li> </ul> <p>Genome assembly with mitochondrial DNA included: - cgigas_uk_roslin_v1_genomic-mito.fa: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/cgigas_uk_roslin_v1_genomic-mito.fa</code></p> <ul> <li>cgigas_uk_roslin_v1_genomic-mito.fa.fai: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/cgigas_uk_roslin_v1_genomic-mito.fa.fai</code></li> </ul> <p>Genome feature tracks generated from the NCBI RefSeq link in this Jupyter notebook</p> <ul> <li> <p>cgigas_uk_roslin_v1_gene.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_gene.gff</code></p> </li> <li> <p>GCF_902806645.1_cgigas_uk_roslin_v1_genomic-mito.gtf: <code>https://gannet.fish.washington.edu/panopea/Cg-roslin/GCF_902806645.1_cgigas_uk_roslin_v1_genomic-mito.gtf</code></p> </li> <li> <p>cgigas_uk_roslin_v1_mRNA.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_mRNA.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_CDS.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_CDS.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_nonCDS.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_nonCDS.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_exon.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_exon.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_exonUTR.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_exonUTR.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_intron.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_intron.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_intergenic.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_intergenic.bed</code></p> </li> <li> <p>cgigas_uk_roslin_v1_flanks.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_flanks.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_upstream.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_upstream.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_downstream.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_downstream.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_lncRNA.gff: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_lncRNA.gff</code></p> </li> <li> <p>cgigas_uk_roslin_v1_rm.te.bed: <code>http://owl.fish.washington.edu/halfshell/genomic-databank/cgigas_uk_roslin_v1_rm.te.bed</code></p> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-gigas-oyster_v9","title":"Crassostrea gigas - oyster_v9","text":"<p>Related Resources</p> <ul> <li> <p>NCBI Datasets</p> </li> <li> <p>Compilation of DNA Methylation Genome Feature Tracks (Crassostrea gigas) circa 2015</p> </li> <li> <p>Re-defining Cgigas Canonical features circa 2015</p> </li> <li> <p>Gigaton</p> </li> <li> <p>TJGR</p> </li> </ul> <p>Genome:</p> <ul> <li> <p>Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa</code></p> <ul> <li> <p>MD5 = 6de9d1239eb10ea0545bed6c4e746d6c</p> </li> <li> <p>FastA index (<code>samtools faidx</code>) : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa.fai</code></p> </li> </ul> </li> </ul> <p>Bisulfite Genome:</p> <ul> <li> <p>Crassostrea_gigas.oyster_v9.dna_sm.toplevel_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.dna_sm.toplevel_bisulfite.tar.gz</code></p> <ul> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Cgigas_v9_gene.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_gene.gff</code></p> </li> <li> <p>Cgigas_v9_exon.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_exon.gff</code></p> </li> <li> <p>Cgigas_v9_intron.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_intron.gff</code></p> </li> <li> <p>Cgigas_v9_TE.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_TE.gff</code></p> <ul> <li>Contains Tandem Repeats and wublastx features.</li> </ul> </li> <li> <p>Cgigas_v9_CG.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_CG.gff</code></p> <ul> <li>index: <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_CG.gff.idx</code></li> </ul> </li> <li> <p>Cgigas_v9_1k5p_gene_promoter.gff : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_1k5p_gene_promoter.gff</code></p> </li> <li> <p>Cgigas_v9_COMP_gene_prom_TE.bed : <code>https://eagle.fish.washington.edu/trilobite/Crassostrea_gigas_v9_tracks/Cgigas_v9_COMP_gene_prom_TE.bed</code></p> </li> <li> <p>Crassostrea_gigas.oyster_v9.40.gff3 : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.40.gff3</code></p> <ul> <li>MD5 = 90a747fbc94a0a9225c43f75cc40b9db</li> </ul> </li> <li> <p>Crassostrea_gigas.oyster_v9.40.abinitio.gff3 : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Crassostrea_gigas.oyster_v9.40.abinitio.gff3</code></p> <ul> <li>MD5 = c2a8c388f5a8afb22a115d61dee3dda0</li> </ul> </li> <li> <p>Crassostrea_gigas.oyster_v9.40_mRNA.gff3</p> <ul> <li><code>grep \"mRNA\" Crassostrea_gigas.oyster_v9.40.gff3 &gt; Crassostrea_gigas.oyster_v9.40_mRNA.gff3</code></li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#crassostrea-virginica","title":"Crassostrea virginica","text":"<p>NCBI FTP</p> <p>Genomes:</p> <ul> <li> <p>Cvirginica_v300.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300.fa</code></p> <ul> <li> <p>MD5 = f9135e323583dc77fc726e9df2677a32</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Cvirginica_v300.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300.fa.fai</code></li> </ul> </li> </ul> </li> <li> <p>GCF_002022765.2_C_virginica-3.0_genomic.fna.gz : <code>ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/002/022/765/GCF_002022765.2_C_virginica-3.0/GCF_002022765.2_C_virginica-3.0_genomic.fna.gz</code></p> <ul> <li>compressed version of <code>Cvirginica_v300.fa</code> (same files)</li> </ul> </li> </ul> <p>Annotations:</p> <ul> <li> <p>geneGO.txt (2.8MB)</p> <ul> <li> <p>MD5 = <code>cc587fe765825ca5f76886ab829c556c</code></p> </li> <li> <p>Notebook details</p> <ul> <li>Originally created in MarineOmics repo commit <code>cacd795b71caaf4f1b9e04ba955037f4128b801d</code></li> </ul> </li> </ul> </li> </ul> <p>Bisulfite Genomes:</p> <ul> <li> <p>Cvirginica_v300_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Cvirginica_v300_bisulfite.tar.gz</code></p> <ul> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>C_virginica-3.0_Gnomon_mRNA.gff3 : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_mRNA.gff3</code></p> </li> <li> <p>C_virginica-3.0_Gnomon_genes.bed : <code>https://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_genes.bed</code></p> <ul> <li> <p>MD5 = <code>c8f203de591c0608b96f4299c0f847dc</code></p> </li> <li> <p>Notebook entry</p> </li> </ul> </li> <li> <p>C_virginica-3.0_Gnomon_exon.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_Gnomon_exon.bed</code></p> </li> <li> <p>C_virginica-3.0_intron.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_intron.bed</code></p> </li> <li> <p>C_virginica-3.0_CG-motif.bed : <code>http://eagle.fish.washington.edu/Cvirg_tracks/C_virginica-3.0_CG-motif.bed</code></p> <ul> <li> <p>MD5 = <code>f88c171bccf45a6f3afcf455b6be810f</code></p> </li> <li> <p>Dead link in this Jupyter Notebook obscures details on how this was generated (via Galaxy):</p> <ul> <li>https://github.com/sr320/nb-2018/blob/master/C_virginica/22-CG-track.ipynb</li> </ul> </li> </ul> </li> <li> <p>C_virginica-3.0_TE-all.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/C_virginica-3.0_TE-all.gff</code></p> <ul> <li> <p>MD5 = d0d81fc6cf7525bc2c61984bee23521b</p> </li> <li> <p>Details</p> </li> </ul> </li> <li> <p>C_virginica-3.0_TE-Cg.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/C_virginica-3.0_TE-Cg.gff</code></p> <ul> <li> <p>MD5 = 83cd753c171076464fee1165b7e1c6ba</p> </li> <li> <p>Details</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#hematodinium-sp-host-chionoecetes-bairdi","title":"Hematodinium sp. (Host: Chionoecetes bairdi)","text":"<p>Transcriptomes</p> <p>Assembly Stats Table (Google Sheet)</p> <ul> <li> <p>hemat_transcriptome_v1.7.fasta</p> <pre><code>- internal short-hand: includes 2018, 2019, 2020-UW with _Alveolata_ only reads.\n\n- MD5 = `f9c8f96a49506e1810ff4004426160d8`\n\n- FastA index (```samtools faidx```)\n\n    - [hemat_transcriptome_v1.7.fasta.fai](https://gannet.fish.washington.edu/Atumefaciens/20210308_hemat_trinity_v1.6_v1.7/hemat_transcriptome_v1.7.fasta_trinity_out_dir/hemat_transcriptome_v1.7.fasta.fai)\n\n- [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/08/Transcriptome-Assembly-Hematodinium-Transcriptomes-v1.6-and-v1.7-with-Trinity-on-Mox.html)\n\n- BUSCOs: `C:15.0%[S:12.2%,D:2.8%],F:12.3%,M:72.7%,n:978`\n\n    - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Assessment-BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox.html)\n\n- BLASTx Annotation\n\n  - [hemat_transcriptome_v1.7.fasta.blastx.outfmt6](https://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.7.fasta.blastx.outfmt6)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Annotation-Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox.html)\n\n- GO Terms Annotation\n\n  - [20210310.hemat_transcriptome_v1.7.fasta.trinotate.go_annotations.txt](https://gannet.fish.washington.edu/Atumefaciens/20210309_hemat_trinotate_transcriptome-v1.7/20210309.hemat_transcriptome_v1.7.fasta.trinotate.go_annotations.txt) (Trinotate)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/09/Transcriptome-Annotation-Trinotate-Hematodinium-v1.7-on-Mox.html)\n</code></pre> </li> <li> <p>hemat_transcriptome_v1.6.fasta</p> <pre><code>- internal short-hand: includes 2018, 2019, 2020-GW, 2020-UW with _Alveolata_ only reads.\n\n- MD5 = `f9c8f96a49506e1810ff4004426160d8`\n\n- FastA index (```samtools faidx```)\n\n    - [hemat_transcriptome_v1.6.fasta.fai](https://gannet.fish.washington.edu/Atumefaciens/20210308_hemat_trinity_v1.6_v1.7/hemat_transcriptome_v1.6.fasta_trinity_out_dir/hemat_transcriptome_v1.6.fasta.fai)\n\n- [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/08/Transcriptome-Assembly-Hematodinium-Transcriptomes-v1.6-and-v1.7-with-Trinity-on-Mox.html)\n\n- BUSCOs: `C:26.5%[S:20.7%,D:5.8%],F:11.2%,M:62.3%,n:978`\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Assessment-BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox.html)\n\n- BLASTx Annotation\n\n  - [hemat_transcriptome_v1.6.fasta.blastx.outfmt6](https://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.6.fasta.blastx.outfmt6)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2020/08/14/Transcriptome-Annotation-Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox.html)\n\n- GO Terms Annotation\n\n  - [20210309.hemat_transcriptome_v1.6.fasta.trinotate.go_annotations.txt](https://gannet.fish.washington.edu/Atumefaciens/20210309_hemat_trinotate_transcriptome-v1.6/20210309.hemat_transcriptome_v1.6.fasta.trinotate.go_annotations.txt) (Trinotate)\n\n  - [Notebook entry](https://robertslab.github.io/sams-notebook/2021/03/09/Transcriptome-Annotation-Trinotate-Hematodinium-v1.6-on-Mox.html)\n</code></pre> </li> <li> <p>hemat_transcriptome_v1.5.fasta</p> <ul> <li> <p>MD5 = <code>b8d4a3c1bad2e07da8431bf70bdabfdd</code></p> </li> <li> <p>BUSCOs: <code>C:25.6%[S:20.7%,D:4.9%],F:11.7%,M:62.7%,n:978</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>hemat_transcriptome_v1.5.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/hemat_transcriptome_v1.5.fasta.fai</code></li> </ul> </li> <li> <p>Updated assembly from 20200330.</p> </li> <li> <p>BLASTx Annotation (txt; 355KB)</p> </li> <li> <p>Trinotate GO Terms Annotation (txt; 2.3MB)</p> </li> <li> <p>internal short-hand: includes 2018, 2019, 2020-GW with Alveolata only reads.</p> </li> </ul> </li> <li> <p>hemat_transcriptome_v1.0.fasta (3.9MB)</p> <ul> <li> <p>MD5 = <code>fa5eb74767d180af5265d2d1f80b6430</code></p> </li> <li> <p>BUSCOs: <code>C:25.1%[S:19.2%,D:5.9%],F:9.5%,M:65.4%,n:978</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>hemat_transcriptome_v1.0.fasta.fai : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/hemat_transcriptome_v1.0.fasta.fai</code></li> </ul> </li> <li> <p>Initial Trinity assembly from 20200122</p> </li> <li> <p>BLASTx Annotation (txt; 308KB)</p> </li> <li> <p>Trinotate GO Terms Annotation (txt; 2.1MB)</p> </li> <li> <p>internal short-hand: includes 2018, 2019 with Alveolata only reads.</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#metacarcinus-magister-cancer-magister","title":"Metacarcinus magister (Cancer magister)","text":"<p>Genome:</p> <ul> <li> <p><code>mmag_pilon_scaffolds.fasta</code></p> <ul> <li> <p>MD5 = 5dfa2ba11edf0ff8191f112e0b1378d1</p> </li> <li> <p>Not shared publicly until permission received from NOAA.</p> </li> <li> <p>Roberts Lab members can access on Owl: <code>/web/halfshell/genomic-databank/mmag_pilon_scaffolds.fasta</code></p> </li> <li> <p>Original filename: <code>pilon_scaffolds.fasta</code></p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li><code>mmag_pilon_scaffolds.fasta.fai</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#montipora-capitata","title":"Montipora capitata","text":"<p>Genomes:</p> <ul> <li> <p><code>GCA_006542545.1_Mcap_UHH_1.1_genomic.fna</code> (569MB)</p> <ul> <li> <p>MD5 checksum: <code>25efbc3110c0791b5eb2e5ac5c2a472f</code></p> </li> <li> <p>Downloaded 20230125: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_006542545.1/</p> </li> </ul> </li> <li> <p><code>Montipora_capitata_HIv3.assembly.fasta</code> (745MB)</p> <ul> <li> <p>MD5 checksum: <code>99819eadba1b13ed569bb902eef8da08</code></p> </li> <li> <p>Downloaded 2023017: http://cyanophora.rutgers.edu/montipora/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>)</p> <ul> <li> <p><code>Montipora_capitata_HIv3-hisat2-indices.tar.gz</code> (tarball gzip; 1.2GB)</p> <ul> <li> <p>MD5 checksum: <code>c8accb6c54e843198c776f0d6f0c603d</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p><code>Montipora_capitata_HIv3.genes.gff3</code> (67MB)</p> <ul> <li> <p>MD5 checksum: <code>5f6b80ba2885471c8c1534932ccb7e84</code></p> </li> <li> <p>Downloaded 2023017: http://cyanophora.rutgers.edu/montipora/</p> </li> </ul> </li> <li> <p><code>Montipora_capitata_HIv3.genes.gtf</code> (101MB)</p> <ul> <li> <p>MD5 checksum: <code>ceef8eca945199415b23d2f1f0dd2066</code></p> </li> <li> <p>Created 2023017: https://robertslab.github.io/sams-notebook/2023/01/27/Data-Wrangling-M.capitata-Genome-GFF-to-GTF-Using-gffread.html</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#mytilus-trossulus","title":"Mytilus trossulus","text":"<p>Transcriptome:</p> <ul> <li> <p>Mtros-hq_transcripts.fasta</p> <ul> <li>MD5 = 381f7b6970fd20ff6b0e72006c80a</li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#ostrea-lurida","title":"Ostrea lurida","text":"<p>Genome:</p> <ul> <li> <p>Olurida_v081.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081.fa</code></p> <ul> <li> <p>MD5 = 3ac56372bd62038f264d27eef0883bd3</p> </li> <li> <p>This is <code>v080</code> with only contigs &gt; 1000bp. Details of how <code>v080</code> was reduced found here.</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Olurida_v081.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081.fa.fai</code></li> </ul> </li> </ul> </li> <li> <p>Olurida_v080.fa : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080.fa</code></p> <ul> <li> <p>MD5 = 9258398f554493e08fdc30e9c1409864</p> </li> <li> <p>FastA index (<code>samtools faidx</code>)</p> <ul> <li>Olurida_v080.fa.fai : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080.fa.fai</code></li> </ul> </li> <li> <p>Also known as <code>pbjelly_sjw_01</code>. Details found here, though confirmation would be good.</p> </li> </ul> </li> </ul> <p>Bisulfite Genomes:</p> <ul> <li> <p>Olurida_v080_bisulfite.tar.gz : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v080_bisulfite.tar.gz</code></p> </li> <li> <p>Gzipped tarball of bisulfite genome for use with Bismark</p> </li> <li> <p>Creation details here</p> </li> </ul> <p>Transcriptomes:</p> <ul> <li> <p>Olurida_transcriptome_v3.fasta</p> <ul> <li>MD5 = 9da3242af2be0463051ec7e1f39b2593</li> </ul> </li> </ul> <p>Tissue-specific transcriptomes generated by Katherine Silliman</p> <ul> <li> <p>Olurida_CA_adductor_Trinity.fasta.gz</p> </li> <li> <p>Olurida_CA_ctenidia_Trinity.fasta.gz</p> </li> <li> <p>Olurida_CA_mantle_Trinity.fasta.gz</p> </li> <li> <p>Olurida_gonad_Trinity.fasta.gz</p> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Olurida_v081_genome_snap02.all.renamed.putative_function.domain_added.gff (2.9GB) : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_genome_snap02.all.renamed.putative_function.domain_added.gff</code></p> <ul> <li>MD5 = <code>f54512bd964f45645c34b1e8e403a2b0</code></li> </ul> </li> <li> <p>Olurida_v081-20190709.CDS.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.CDS.gff</code></p> </li> <li> <p>Olurida_v081-20190709.exon.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.exon.gff</code></p> </li> <li> <p>Olurida_v081-20190709.gene.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.gene.gff</code></p> </li> <li> <p>Olurida_v081-20190709.mRNA.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081-20190709.mRNA.gff</code></p> </li> <li> <p>Olurida_v081_TE-Cg.gff : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_TE-Cg.gff</code></p> <ul> <li> <p>MD5 = 977fd7cdb460cd0b9df5e875e1e880ea</p> </li> <li> <p>Transposable Element track - more details in Sam's Notebook, including a summary table.</p> </li> </ul> </li> <li> <p>Olurida_v081_CG-motif.gff : <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081_CG-motif.gff</code></p> </li> </ul>"},{"location":"Genomic-Resources/#panopea-generosa","title":"Panopea generosa","text":"<p>Genome:</p> <ul> <li> <p>Panopea-generosa-v1.0.fa : <code>https://gannet.fish.washington.edu/Atumefaciens/20191105_swoose_pgen_v074_renaming/Panopea-generosa-v1.0.fa</code></p> <ul> <li> <p>ENA Accession: GCA_902825435</p> </li> <li> <p>Version of 070 containing 18 largest scaffolds (details on subsetting)</p> </li> <li> <p>FastA file and scaffolds were renamed on 20191105 (notebook)</p> </li> <li> <p>MD5 = 32976550b9030126c07920d5f2db179c</p> </li> <li> <p>BUSCO scores:</p> <ul> <li> <p><code>C:71.6%[S:70.7%,D:0.9%],F:4.7%,M:23.7%,n:978</code></p> </li> <li> <p>Notebook entry</p> </li> </ul> </li> <li> <p>FastA index (<code>samtools faidx</code>):</p> <ul> <li><code>https://gannet.fish.washington.edu/Atumefaciens/20191105_swoose_pgen_v074_renaming/Panopea-generosa-v1.0.fa.fai</code></li> </ul> </li> <li> <p>Gene annotation file:</p> <ul> <li> <p>20220419-pgen-gene-accessions-gene_id-gene_name-gene_description-alt_gene_description-go_ids.tab</p> <ul> <li> <p><code>gene_ID</code>: Gene ID from our Panopea generosa (Pacific geoduck) genome.</p> </li> <li> <p><code>SPIDs</code>: Semicolon-delimited list of SPIDs from UniProt. One SPID in this list is a match corresponding to the our original BLAST annotations.</p> </li> <li> <p><code>UniProt_gene_ID</code>: Gene accession from UniProt.</p> </li> <li> <p><code>gene</code>: Abbreviated gene name from UniProt.</p> </li> <li> <p><code>gene_description</code>: Human-readable gene description from UniProt.</p> </li> <li> <p><code>alternate_gene_description</code>: Human-readable alternate gene description from UniProt.</p> </li> <li> <p><code>GO_IDs</code>: Semicolon-delimited GO IDs from UniProt.</p> </li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Bisulfite Genome:</p> <p>Genome Feature Tracks:</p> <ul> <li> <p>Panopea-generosa-vv0.74.a4</p> <p>These originate from GenSAS annotation on 20190928</p> <p>Individual feature GFFs were made with the following shell commands:</p> </li> </ul> <pre><code>```bash\n\nfeatures_array=(CDS exon gene mRNA repeat_region rRNA tRNA)\n\ninput=\"Panopea-generosa-vv0.74.a4-merged-2019-10-07-4-46-46.gff3\"\n\nfor feature in ${features_array[@]}\n  do\n  output=\"Panopea-generosa-vv0.74.a4.${feature}.gff3\"\n  head -n 3 ${input} \\\n  &gt;&gt; ${output}\n  awk -v feature=\"$feature\" '$3 == feature {print}' ${input} \\\n  &gt;&gt; ${output}\ndone\n```\n\n- [GFF files and scaffolds were renamed on 20191105](https://robertslab.github.io/sams-notebook/2019/11/05/Data-Wrangling-Rename-Pgenerosa_v074-Files-and-Scaffolds.html) (notebook)\n</code></pre> <ul> <li> <p>Panopea-generosa-v1.0.a4.gff3</p> <ul> <li>Primary GFF containing all features.</li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4_biotype-trna_strand_converted-no_RNAmmer.gtf</p> <ul> <li> <p>GTF file with formatting to avoid downstream parsing problems.</p> </li> <li> <p>GitHub Issue describing creation and problems</p> </li> </ul> </li> <li> <p>Panopea-generosa-v1.0.CpG.gff</p> </li> <li> <p>Panopea-generosa-v1.0.a4.CDS.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.exon.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.intergenic.bed</p> </li> <li> <p>Panopea-generosa-v1.0.a4.introns.bed</p> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.rRNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeat_region.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.DNA.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.LINE.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.LTR.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.RC.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.SINE.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.Simple_repeat.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.repeats.Unknown.gff3</p> </li> <li> <p>Panopea-generosa-v1.0.a4.tRNA.gff3</p> </li> </ul> <p>Fasta files:</p> <ul> <li> <p>Panopea-generosa-v1.0.a4.CDS.fasta (67M)</p> <ul> <li>MD5: <code>fb192eab0aefd5d3ba5bebef2a012f15</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.CDS.fasta.fai (26M)</p> <ul> <li>MD5: <code>f2266a449290ea0383d2eb98eb3ed426</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.fasta (362M)</p> <ul> <li>MD5: <code>7c956b1c27d14bd91959763403f81265 588d18f5fe0e4f2259a25586349fc244</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.gene.fasta.fai (2.4M)</p> <ul> <li>MD5: <code>588d18f5fe0e4f2259a25586349fc244</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.fasta (475M)</p> <ul> <li>MD5: <code>1823be75694cf70f0ea6f1abc072ba16 e120b4c1d3bb0917868e72cd22507bbc</code></li> </ul> </li> <li> <p>Panopea-generosa-v1.0.a4.mRNA.fasta.fai (3.4M)</p> <ul> <li>MD5: <code>e120b4c1d3bb0917868e72cd22507bbc</code></li> </ul> </li> </ul> <p>Jupyter notebook with creation deets (NB Viewer):</p> <ul> <li>20220324-pgen-gffs_to_fastas.ipynb</li> </ul> <p>CDS FastA description lines look like this:</p> <ul> <li><code>PGEN_.00g000010.m01.CDS01|PGEN_.00g000010.m01::Scaffold_01:2-125</code></li> </ul> <p>Explanation for CDS:</p> <ul> <li><code>PGEN_.00g000010.m01.CDS01</code>: Unique sequence ID.</li> <li><code>PGEN_.00g000010.m01</code>: \"Parent\" ID. Corresponds to unique mRNA ID.</li> <li><code>Scaffold_01</code>: Originating scaffold.</li> <li><code>2-125</code>: Sequence coordinates from scaffold mentioned above.</li> </ul> <p>mRNA FastA description looks like this:</p> <ul> <li><code>PGEN_.00g000030.m01|PGEN_.00g000030::Scaffold_01:49248-52578</code></li> </ul> <p>Explanation for mRNA:</p> <ul> <li><code>PGEN_.00g000030.m01</code>: Unique sequence ID.</li> <li><code>PGEN_.00g000030</code>: \"Parent\" ID. Corresponds to unique gene ID.</li> <li><code>Scaffold_01</code>: Originating scaffold.</li> <li><code>49248-52578</code>: Sequence coordinates from scaffold mentioned above.</li> </ul> <ul> <li> <p>Pgenerosa_transcriptome_v5.fasta : <code>http://owl.fish.washington.edu/halfshell/genomic-databank/Pgenerosa_transcriptome_v5.fasta</code></p> <ul> <li>MD5 = <code>5a21424ecbc88c3b01daefe56bed79da</code></li> </ul> </li> </ul> <p>Transcriptome generated from various libaries - details here.</p> <ul> <li> <p>Kallisto index for <code>Pgenerosa_transcriptome_v5.fasta</code> (8.2GB):</p> <ul> <li><code>https://gannet.fish.washington.edu/seashell/wd/062821/transcriptome_v5.idx</code></li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillipora-acuta","title":"Pocillipora acuta","text":"<p>Genome:</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2.assembly.fasta</code> (389MB)</p> <ul> <li> <p>MD5 checksum: <code>ce3b69ff3f5dafb8fb7416dc862ef4a0</code></p> </li> <li> <p>Downloaded 20230125: http://cyanophora.rutgers.edu/Pocillopora_acuta/</p> </li> </ul> </li> </ul> <p>Genome Index (<code>HISAT2</code>):</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2-hisat2-indices.tar.gz</code> (597MB)</p> <ul> <li> <p>MD5 checksum: <code>80dbf8ca589f569f43ef2a75ab57e17d</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks:</p> <ul> <li> <p><code>Pocillopora_acuta_HIv2.genes.gff3</code> (54MB)</p> <ul> <li> <p>MD5 checksum: <code>fad5aa85afd7e3bec4400ca6da7d706d</code></p> </li> <li> <p>Downloaded 20230125: http://cyanophora.rutgers.edu/Pocillopora_acuta/</p> </li> </ul> </li> <li> <p><code>Pocillopora_acuta_HIv2.gtf</code> (82MB)</p> <ul> <li> <p>MD5 checksum: <code>34196bd945eb4965e665097648037132</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.acuta-Genome-GFF-to-GTF-Conversion-Using-gffread.html</p> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillopora-meandrina","title":"Pocillopora meandrina","text":"<p>Genome(s):</p> <ul> <li> <p><code>Pocillopora_meandrina_HIv1.assembly.fasta</code> (360MB)</p> <ul> <li> <p>MD5 checksum: <code>36eb9cdaf92db69906e6d1486a8406f5</code></p> </li> <li> <p>Downloaded 20230519: http://cyanophora.rutgers.edu/Pocillopora_meandrina/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p><code>Pocillopora_meandrina_HIv1.assembly-hisat2-indices.tar.gz</code> (tarball gzip; MB)</p> <ul> <li> <p>MD5 checksum: ``</p> </li> <li> <p>Needs to be unpacked before use!</p> </li> <li> <p>Notebook: </p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>Genes</p> <ul> <li> <p>https://owl.fish.washington.edu/halfshell/genomic-databank/Pocillopora_meandrina_HIv1.genes-valid.gff3 (55MB)</p> </li> <li> <p>MD5 checksum: <code>5865589d1f2764b4b74df91ea78d5652</code></p> </li> <li> <p>A GFF3-compliant version of <code>Pocillopora_meandrina_HIv1.genes.gff3</code> (see below). Created GFF3 compliant version via the following command (replace <code>transcript</code> with <code>mRNA</code>):</p> <ul> <li><code>sed 's/transcript/mRNA/' Pocillopora_meandrina_HIv1.genes.gff3 &gt; Pocillopora_meandrina_HIv1.genes-valid.gff3</code></li> </ul> </li> <li> <p>Pocillopora_meandrina_HIv1.genes.gff3 (55MB)</p> <ul> <li> <p>MD5 checksum: <code>ace5c9a588321fada8e6771a1c758861</code></p> </li> <li> <p>Downloaded 20230519: http://cyanophora.rutgers.edu/Pocillopora_meandrina/</p> </li> <li> <p>NOTE: This is labelled as a GFF3, but in reality closer to a GTF file; as it only contains transcript/exon/CDS features. There are no gene features (e.g. 5'/3'UTR, mRNA, gene, etc). Additionally, the feature label of <code>transcript</code> is not GFF or GTF compliant.</p> </li> </ul> </li> </ul> </li> <li> <p>Repeats</p> <ul> <li> <p>Pocillopora_meandrina_HIv1.assembly.fasta.out.gff (13MB)</p> <ul> <li> <p>MD5 checksum: <code>6e7a25bf51a7c838b9659dd7ec37990f</code></p> </li> <li> <p>Notebook: Repeats-Identification-P.meandrina-Using-RepeatMasker-on-Mox.html</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"Genomic-Resources/#pocillipora-verrucosa","title":"Pocillipora verrucosa","text":"<p>Genomes:</p> <ul> <li> <p><code>GCA_014529365.1_Pver_genome_assembly_v1.0_genomic.fna</code> (369MB)</p> <ul> <li> <p>MD5 checksum: <code>6ca98fae6a8b86183d75b23cf52a6651</code></p> </li> <li> <p>Downloaded 20230125: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCA_014529365.1/</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0.fasta</code> (363MB)</p> <ul> <li> <p>MD5 checksum: <code>cb1ed5a1b724d92456347a28bb25f228</code></p> </li> <li> <p>Downloaded 20230127: http://pver.reefgenomics.org/download/</p> </li> </ul> </li> </ul> <p>Genome Indexes (<code>HISAT2</code>):</p> <ul> <li> <p><code>pver-GCA_014529365.1-hisat2-indices.tar.gz</code> (tarball gzip; 563MB)</p> <ul> <li> <p>MD5 checksum: <code>f1669e7d88cf014fcfa10c6c06e03802</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-hisat2-indices.tar.gz</code> (tarball gzip; 594MB)</p> <ul> <li> <p>MD5 checksum: <code>57e193e101396fab67de04c851f63240</code></p> </li> <li> <p>Needs to be unpacked before use!</p> </li> <li> <p>Notebook: Genome-Indexing-P.verrucosa-v1.0-Assembly-with-HiSat2-on-Mox.html</p> </li> </ul> </li> </ul> <p>Genome Feature Tracks</p> <ul> <li> <p>~~<code>Pver_genome_assembly_v1.0.gff3</code>~~ (70MB)</p> <ul> <li> <p>NOTE: DO NOT USE! NOT A VALID GFF3 FORMAT!</p> <ul> <li> <p>Retaining to maintain provenance of data.</p> </li> <li> <p>Use updated/validated <code>Pver_genome_assembly_v1.0-valid.gff3</code>.</p> </li> </ul> </li> <li> <p>MD5 checksum: <code>3f1d52afa2801f9aa126623aba3c149d</code></p> </li> <li> <p>Downloaded 20230127: http://pver.reefgenomics.org/download/</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.gff3</code> (70MB)</p> <ul> <li> <p>MD5 checksum: <code>5dd8f21a4faea1f46c48a5ab253749d7</code></p> </li> <li> <p>Modified/validated version of <code>Pver_genome_assembly_v1.0.gff3</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.verrucosa-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.gtf</code> (48MB)</p> <ul> <li> <p>MD5 checksum: <code>c3cc8fb576bcf39dd17b6d229100aa56</code></p> </li> <li> <p>Created 20230127: Data-Wrangling-P.verrucosa-Genome-GFF-to-GTF-Using-gffread</p> </li> </ul> </li> <li> <p><code>Pver_genome_assembly_v1.0-valid.genes.bed</code> (1.2MB)</p> <ul> <li> <p>MD5 checksum: <code>f19672f65c4e376f96c6ab23c202c2e0</code></p> </li> <li> <p>Created 20230227 by Sam White:</p> <pre><code>bedops_linux_x86_64-v2.4.40/gff2bed \\\n&lt; Pver_genome_assembly_v1.0-valid.genes.gff3 \\\n| awk -F\"\\t\" 'BEGIN {OFS=\"\\t\"} {print $1, $2, $3, $4, $5, $6}' \\\n&gt; Pver_genome_assembly_v1.0-valid.genes.bed\n</code></pre> </li> </ul> </li> <li> <p>Pver_CGmotif.gff: <code>https://owl.fish.washington.edu/halfshell/genomic-databank/Pver_CGmotif.gff</code> (1.3G)</p> </li> </ul>"},{"location":"Genomic-Resources/#qpx","title":"QPX","text":"<p>Genome:</p> <ul> <li>QPX_v017.fasta : <code>http://eagle.fish.washington.edu/QPX_genome/QPX_v017.fasta</code></li> </ul> <p>CLC v5.1 Mismatch cost = 2; Perform scaffolding = Yes; Mapping mode = Map reads back to contigs (slow); Deletion cost = 3; Similarity fraction = 0.9; Length fraction = 0.8; Insertion cost = 3; Update contigs = Yes; Automatic word size = Yes; Minimum contig length = 10000; Automatic bubble size = Yes; input: filtered_QPX_DNA_GTGAAA_L001_R1 trimmed.</p> <ul> <li>QPX_v017.fasta : <code>https://ndownloader.figshare.com/files/3085550</code></li> </ul> <p>CLC v5.1 Mismatch cost = 2; Perform scaffolding = Yes; Mapping mode = Map reads back to contigs (slow); Deletion cost = 3; Similarity fraction = 0.9; Length fraction = 0.8; Insertion cost = 3; Update contigs = Yes; Automatic word size = Yes; Minimum contig length = 10000; Automatic bubble size = Yes; input: filtered_QPX_DNA_GTGAAA_L001_R1 trimmed.</p> <ul> <li>QPX_v015.fasta : <code>https://doi.org/10.1371/journal.pone.0074196.s001</code></li> </ul> <p>De novo assembly was performed with Genomics Workbench v. 5.0 (CLC Bio, Germany) on quality trimmed sequences with the following parameters: mismatch cost = 2, deletion cost = 3, similarity fraction = 0.9, insertion cost = 3, length fraction = 0.8 and minimum contig size of 100 bp for genomic data and 200 bp for transcriptomic data. In order to remove ribosomal RNA sequences from the transcriptome data, consensus sequences were compared to the NCBI nt database using the BLASTn algorithm [59]. Sequences with significant matches (9) were removed and not considered in subsequent analyses.</p> <p>Manuscript: https://doi.org/10.1371/journal.pone.0074196</p> <p>Transcriptome:</p> <ul> <li>QPX_transcriptome_v1_clean.fasta</li> </ul> <p>QPX_Transcriptome v2.1</p> <p>Subset of version 1 (v1) that only includes sequences with e-value \\&lt; 1E-20. Based on Swiss-Prot blastx output, all sequences are oriented 5' - 3'. nucleotides between stop codons; minimum size 200.</p>"},{"location":"Genomic-Resources/#salvelinus-namaycush-lake-trout","title":"Salvelinus namaycush (lake trout)","text":"<p>Genome:</p> <ul> <li>SaNama_1.0_genomic.fna: <code>https://owl.fish.washington.edu/halfshell/genomic-databank/SaNama_1.0_genomic.fna</code></li> </ul> <p>Genome Feature Tracks:</p> <ul> <li> <p>20220818-snam-GCF_016432855.1_SaNama_1.0_genes.bed</p> <ul> <li>Notebook entry</li> </ul> </li> </ul>"},{"location":"Jupyter-Notebook-Guide/","title":"A Roberts Lab Guide to Installing and Using Jupyter Notebooks","text":""},{"location":"Lab-Communication/","title":"Lab Communication","text":"<p>An overarching philosophy on lab communication is inclusivity and leveraging the common wisdom. Further, the intent is that prior conversations and issues (hopefully resolved) can be found by others (and future you). To that end, email is often considered a last resort. A side benefit is this should reduce email anxiety and overload. </p>"},{"location":"Lab-Communication/#slack","title":"Slack","text":"<p>Our means of general communication in the lab is through Slack. This is in lieu of email, providing a simple means of archiving, searching, and easy user management. IMPORTANT: This is considered to be ethereal in nature. Anything worth coming back to needs to live somewhere else.</p>"},{"location":"Lab-Communication/#github-issues","title":"GitHub Issues","text":"<p>A critical form of lab communication is via RobertsLab/resources GitHub Issues. This serves as a catch-all for problems, concerns, troubleshooting, purchasing, wish list, lab meeting topics, and other miscellaneous things that you might need help with (also for which the ideas/resolutions might be useful for the rest of the lab).</p>"},{"location":"Lab-Communication/#lab-meetings","title":"Lab Meetings","text":"<p>We generally have weekly lab meetings. These can be attended in person or remotely via video/audio chat. Steven will post link(s) for joining the chats in Slack and/or in the event on the Roberts Lab Google Calendar.</p> <p>We alternate between a DEI focus and academic discovery. Themes can be found below. In general we will use DEI slots for a book club focused discussion and academic discovery will be a mix of modules including but not limited to...</p> <ul> <li>coding mini lectures    </li> <li>list of knowledge gaps    </li> <li>journal club (potential model - foundational paper coupled with new paper)    </li> <li>formal presentations (including practice talks)   </li> <li>revisit common tasks (eg writing, ref managing, notebooks)   </li> <li>round robin code show and tell   </li> <li>handbook focus (update / highlight)</li> <li>peer feedback   </li> <li>data workshop   </li> <li>issue triage</li> <li>website update</li> <li>specific Q &amp; A</li> </ul> <p>A traditional update with be rolled into new format that might include presentation or simply recent notebook posts.</p> <p>If you have any suggestions for topics, papers, demos (or anything for lab meeting) please submit here.</p> <p>go here to edit sheet</p>"},{"location":"Lab-Inventory/","title":"Lab Inventory","text":""},{"location":"Lab-Inventory/#general","title":"General","text":"<ul> <li> <p>Roberts Lab Inventory (includes refrigerators and -20C freezers)   See also Purchase Log to confirm existence and location</p> <ol> <li> <p>After receipt of new item(s), review the Roberts Lab Inventory and the Purchase Log to see if there's an established location for the item(s).</p> </li> <li> <p>If the item(s) have an existing storage location, put the new item(s) in the same location.</p> </li> <li> <p>If the item(s) do not have an existing storage location, select a storage location, and update both the Roberts Lab Inventory and the Purchase Log with the storage location info.</p> </li> </ol> </li> </ul>"},{"location":"Lab-Inventory/#-80-freezer","title":"-80 Freezer","text":"<ul> <li> <p>-80C Freezer Inventory Map</p> <ol> <li> <p>Review the -80C Freezer Inventory Map and find and empty slot in any freezer rack.</p> </li> <li> <p>Put the box (or boxes) in any empty rack slots.</p> </li> <li> <p>Fill in the appropriate info on the -80C Freezer Inventory Map</p> </li> </ol> </li> </ul>"},{"location":"Lab-Inventory/#histology","title":"Histology","text":"<ul> <li>Histology database includes information on blocks and slides</li> </ul>"},{"location":"Lab-Inventory/#primer-databases","title":"Primer Databases","text":"<ul> <li> <p>PrimerDatabase: Descriptive Google Sheet of primers.</p> </li> <li> <p>Primer Stocks: Google Sheets workbook of primer stock tube storage locations within FTR 213 -20<sup>o</sup>C freezer.</p> </li> </ul>"},{"location":"Lab-Notebooks/","title":"Lab Notebooks","text":"<p>We have been using online lab notebooks since 2007 and the platforms and workflows have certainly changed over the years. Below is a compendium of best practices based on our experience and the particular research we do. This is intended for those in our lab group, however comments and suggestions are welcome.</p> <p>An online lab notebook is required of all lab members. Entries need to be organized by date and in reverse chronological order, and Updated daily.</p>"},{"location":"Lab-Notebooks/#notebooks","title":"Notebooks","text":"Person Notebook Commitment Steven Roberts sr320.github.io Sam White robertslab.github.io Matt George mattgeorgephd.github.io Aspen Coyle aspencoyle.github.io Olivia Cattau ocattau.github.io Delaney Lawson drlawson.github.io Ariana Huffmyer ahuffmyer.github.io Chris Mantegna chrismantegna.github.io/cmlabsite Zach Bengtsson zbengt.github.io Celeste Valdivia valeste.github.io Larken Root larkenr.github.io Laura Spencer laurahspencer.github.io Yaamini Venkataraman yaaminiv.github.io Grace Crandall grace-ac.github.io Shelly Trigg shellytrigg.github.io/notebook Kathleen Durkin shedurkin.github.io"},{"location":"Lab-Notebooks/#platforms","title":"Platforms","text":"<p>The current recommendation is Quarto in Rstudio. </p> <p>See this page for a tutorial on how to set up. </p>"},{"location":"Lab-Notebooks/#make-sure-it-is-reproducible","title":"Make sure it is reproducible","text":"<p>Document in a fashion where someone could replicate your work.</p>"},{"location":"Lab-Notebooks/#document-daily","title":"Document daily","text":"<p>A record of your work should be published the day of activity. Yep, daily! Even if you feel like you did nothing, post something to describe what you did that day. Did you read some papers? Great! Make a post that lists the papers you read. Did you spend all day searching the web? Also great! Make a post about what you were searching for and how successful you were in finding what you wanted.</p>"},{"location":"Lab-Notebooks/#maintain-backup","title":"Maintain backup","text":"<p>Have a copy of your notebook in another location. This could be done in several ways. - composing in text editor and hosting on GitHub - using IFTTT to post/save entries elsewhere - run script (i.e. wget) to archive contents</p> <p>Periodically, you will be asked to show where your backup is and demonstrate that it is functional.</p> <p>All GitHub-based notebooks are also backed up to Gannet: https://gannet.fish.washington.edu/github_backups/notebooks/</p>"},{"location":"Lab-Protocols/","title":"Lab Protocols","text":"<p>Protocols for benchwork in the lab (e.g. RNA isolation), for commonly used instruments and software (e.g. proteomics data analysis in Skyline), and for commonly performed hatchery practices and tissue sampling.</p> <p>Foundational protocols can be found here. As they become prominent, they will be migrated here for posterity.</p>"},{"location":"Lab-Protocols/#rna-extraction","title":"RNA Extraction","text":"<p>We often use MRC RNA-zol RT (protocol). Depending on downstream needs we might engage in DNAase treatment. </p>"},{"location":"Lab-Protocols/#reverse-transcription","title":"Reverse Transcription","text":""},{"location":"Lab-Protocols/#standard-operating-protocol-sop","title":"Standard Operating Protocol (SOP)","text":"<p>Written 20150702 by Sam White.</p>"},{"location":"Lab-Protocols/#reagents","title":"Reagents:","text":"<ul> <li>M-MLV Reverse Transcriptase (Promega: M1701)</li> <li>Primers (oligo dT: Promega: C1101 OR random: Promega: C1181)</li> <li>10mM dNTPs (Promega: U1511)</li> </ul>"},{"location":"Lab-Protocols/#personal-protective-equipment-ppe","title":"Personal Protective Equipment (PPE):","text":"<ul> <li>Gloves</li> </ul>"},{"location":"Lab-Protocols/#equipment","title":"Equipment:","text":"<ul> <li>Pipettes (10 - 1000uL)</li> <li>Filtered pipette tips</li> <li>0.5mL snap-cap microfuge tubes (Genesee: 22-178A)</li> <li>Sterile 1.7mL snap-cap microfuge tubes (Genesee: 22-281S)</li> <li>Thermal cycler, water bath, or heating block capable of 37C OR 42C.</li> <li>vortexer</li> <li>ice</li> </ul>"},{"location":"Lab-Protocols/#procedure","title":"Procedure","text":""},{"location":"Lab-Protocols/#total-time-15-20hrs","title":"Total Time: ~ 1.5 - 2.0hrs","text":""},{"location":"Lab-Protocols/#costsample-150","title":"Cost/sample: ~ $1.50","text":"<p>IMPORTANT: A single reaction volume = 25uL. The volume of RNA, primer(s) and M-MLV RT used in this protocol are variable and will be specific to your current experiment. The directions below apply to a reaction using 1ug of total RNA. You may need to make changes to accommodate your own conditions.</p> <ol> <li>Read the manufacturer's protocol (PDF).</li> <li>Read this protocol.</li> <li>Verify sufficient quantities of reagents and samples before beginning.</li> <li>Wear clean gloves.</li> <li>Thaw all RNA and reagents on ice. Prepare all reactions on ice.</li> <li>Transfer 1ug of RNA to 0.5mL snap cap tubes or PCR plate. Adjust volumes of individual samples to 17.75uL with H2O.</li> <li>Add 0.25ug primer per 1ug of RNA in sample (= 0.5uL of Promega oligo dT Cat#C1101 in this example). Total volume (RNA + primers) should equal 18.25uL.</li> <li>Heat samples at 70C for 5 min in thermal cycler, heating block, or water bath.</li> <li>Place samples on ice IMMEDIATELY.</li> <li> <p>Make Master Mix:</p> <p>Per Reaction</p> <ul> <li> <p>5 uL 5x Buffer (M-MLV RT Buffer)</p> </li> <li> <p>VORTEX THOROUGHLY TO DISSOLVE PRECIPTATE</p> </li> <li> <p>1.25 uL 10mM dNTPs</p> </li> <li> <p>0.5 uL M-MLV RT per ug of RNA</p> </li> </ul> </li> <li> <p>Mix well by flicking; do not vortex.</p> </li> <li>Add 6.75uL of master mix to each reaction.</li> <li>Mix by pipetting; do not vortex.</li> <li>Incubate @ 42C for 1hr for oligo dT primers OR @ 37C for random primers.</li> <li>Heat inactivate @ 95C for 3 min.</li> <li>Spot spin and store @-20C.</li> </ol>"},{"location":"Lab-Protocols/#qpcr","title":"qPCR","text":"<p>One of the most used application is for gene quantification. Generally we will use SsoFast Evagreen Supermix (BioRad) (protocol). This requires that we start with cDNA.</p>"},{"location":"Lab-Protocols/#qpcr-data-analysis","title":"qPCR Data Analysis","text":"<p>Step 1: Check for quality control of the qPCR data</p> <p>Before starting the analysis, it is important to check the quality control of the qPCR data to ensure that the data is reliable. Quality control can be done using the following methods:</p> <ul> <li>Check for amplification curves: Ensure that amplification curves are present for all the samples. Absence of amplification curves might indicate poor quality RNA or experimental errors.     </li> <li>Check for amplification efficiency: Calculate the amplification efficiency for the target and reference genes. The efficiency should be between 90-110%.    </li> <li>Check for melting curves: Ensure that melting curves show a single peak for all the samples. Presence of multiple peaks might indicate non-specific amplification or primer-dimer formation.    </li> <li>Check for threshold cycle (Ct) values: Ensure that Ct values are consistent across all the samples.  </li> </ul> <p>Step 2: Calculate the relative expression of the target gene    </p> <p>To calculate the relative expression of the target gene, use the following formula:</p> <p>\u0394Ct = Ct_target \u2013 Ct_reference</p> <p>Where Ct_target is the cycle threshold of the target gene and Ct_reference is the cycle threshold of the reference gene (in this case, actin).</p> <p>Step 3: Calculate the fold change of the target gene</p> <p>To calculate the fold change of the target gene, use the following formula:   </p> <p>Fold change = 2^(-\u0394Ct)</p> <p>Step 4: Statistical analysis</p> <p>After calculating the fold change, perform statistical analysis to determine the significance of the results. This can be done using t-tests or ANOVA. A p-value of less than 0.05 is considered significant.</p> <p>Step 5: Interpretation of results</p> <p>After obtaining the statistical results, interpret the results by comparing the fold change of the target gene in the experimental group to the control group. A fold change greater than 1 indicates upregulation, while a fold change less than 1 indicates downregulation.</p>"},{"location":"Lab-Protocols/#common-physiological-assays-of-interest","title":"Common Physiological Assays of Interest","text":"Assay Measurement Reference Oxygen consumption (OC) Volume of O2 consumed animal-1 hour-1 (J. Widdows and Johnson 1988) Clearance rate (CR) Volume of water cleared of particles animal-1 hour-1 (Pernet et al. 2007) Filtration rate (FR) (weight of faeces + pseudofaeces h-1) x [(weight total particulates per volume seawater) \u00f7 (weight inorganic matter per volume seawater)] (Hawkins et al. 1996) Excretion rate (ER) Ammonia excreted hour-1 (John Widdows, Donkin, and Evans 1985) Net organic ingestion rate (NOIR) FR x (organic fraction within total particulates available) (Hawkins et al. 1996) Net organic absorption rate (NOAR) NOIR - [(weight of total faeces egested h-1) x (organic fraction of faces)] (Hawkins et al. 1996) Total carbohydrates Total carbohydrate content of oyster meat (Dubois et al. 1956) Total lipids Total lipid content of oyster meat (Bligh and Dyer 1959) Total protein Total protein content of oyster meat (Jeung et al. 2016) Glycogen content Total glycogen content as a fraction of total protein (Krisman 1962) Condition index (CI) Dry meat weight (internal shell cavity volume)-1 x 100 (Lawrence and Scott 1982) Reproductive status Stage of gonadal development determined through histological observation (Matt and Allen 2021) Ash free dry weight (AFDW) Dry weight of oyster meat after incineration at 500\u2103 (Ricciardi and Bourget 1998) <p>Associated Calculations</p> Parameter Calculation Reference Protein synthesis rate (PR) Mass of protein synthesized individual-1 hour-1 (Pace and Manahan 2006) Protein turnover rate protein synthesis rate \u00f7 (total protein content)-1 x 100 (Pan, Applebaum, and Manahan 2015) Net absorption efficiency (AE) NOAR \u00f7 NOIR (Hawkins et al. 1996) Standard metabolic rate (SMR) OC hour-1 mass-1 Consumption (C) CR (l g-1 h-1) x POM (mg l-1) x 23 J mg-1 ash-free dry weight (J. Widdows and Johnson 1988) Respiration (R) VO2 (ml 02 g-1 h-1) x 20.33 J ml-1O2 (J. Widdows and Johnson 1988) Energy lost to excreta (U) mg NH4 g-1 h-1 x 19.4 J mg-1 NH4 (J. Widdows and Johnson 1988) Absorbed ration (A) C x AE (J. Widdows and Johnson 1988) Production (P) A - (R + U) (J. Widdows and Johnson 1988) Scope for growth (SFG) SFG = A - (R + U), where A = energy absorbed; R = respiratory energy expenditure; U = energy lost through excreta (J. Widdows and Johnson 1988)"},{"location":"Lab-Safety/","title":"Roberts Lab Safety","text":""},{"location":"Lab-Safety/#in-any-emergency-dial-911-from-any-laboratory-phone","title":"In any emergency, dial 911 from any laboratory phone.","text":""},{"location":"Lab-Safety/#before-beginning-any-work-in-the-laboratory-please-complete-the-following","title":"Before beginning any work in the laboratory, please complete the following:","text":"<ol> <li> <p>Read through the Personal Protective Equipment (PPE) Hazard Assessment for our lab:</p> <ul> <li>Personal Protective Equipment (PPE) Hazard Assessment</li> </ul> </li> <li> <p>Print the UW Lab PPE Assessment Completion form, fill in the fields, and return to Sam:</p> <ul> <li>UW Lab PPE Assessment Completion form</li> </ul> </li> <li> <p>Print the UW Roberts Lab-specific Training guide:</p> <ul> <li> <p>UW Lab Training guide</p> <ul> <li>NOTE: If you will be shipping hazardous goods (i.e. dry ice and/or ethanol), please print this form instead: UW Lab Training guide with shipping</li> </ul> </li> <li> <p>Complete all the trainings marked \"Yes\". Online training is available here:</p> <ul> <li>UW EH&amp;S Training</li> </ul> </li> <li>Fill out the date you completed each of the trainings</li> <li>Print/sign your name at the top of the form</li> <li>Return form to Sam</li> </ul> </li> <li> <p>Provide Sam with your UW NetID and he will add you as a user to the UW MyChem system for access to the Roberts Lab chemical inventory and Safety Data Sheets (SDS).</p> </li> <li> <p>Review our Standard Operating Protocols (SOPs) for chemical handling and disposal:</p> <ul> <li>Roberts Lab SOPs</li> </ul> </li> <li> <p>Schedule a time with Sam to tour the labs to learn the locations of phones, eye wash stations, fire extinguishers, first aid kits, emergency showers, other lab-specific points of emphasis.</p> </li> <li> <p>Download &amp; print the UW Roberts Lab-specific Training Checklist:</p> <ul> <li> <p>Lab-specific training checklist</p> </li> <li> <p>Check all boxes</p> </li> <li>Date/sign your name at the bottom of the form</li> <li>Return form to Sam</li> </ul> </li> </ol>"},{"location":"Lab-Safety/#roberts-lab-safety-resources","title":"Roberts Lab Safety Resources","text":"<ul> <li> <p>UW MyChem</p> </li> <li> <p>Roberts Lab SOPs</p> </li> </ul>"},{"location":"Lab-Safety/#official-university-of-washington-safety-resources","title":"Official University of Washington Safety Resources","text":"<p>UW Environmental Health &amp; Safety (EH&amp;S)</p> <p>UW Lab Safety Manual</p> <p>UW Online Accident Reporting System (OARS)</p> <p>Chemical Inventory &amp; Safety Data Sheets (MyChem)</p> <p>Hazardous Waste Online Collection Request</p>"},{"location":"Lab-Software/","title":"Lab Software","text":""},{"location":"Lab-Software/#computer-hummingbird","title":"Computer: hummingbird","text":""},{"location":"Lab-Software/#os-os-x-1095","title":"OS: OS X (10.9.5)","text":"<p>FastQC (0.11.2)</p> <pre><code> path = /usr/local/bioinformatics/FastQC/\n</code></pre> <p>Trimmomatic (0.30)</p> <pre><code> path = /usr/local/bioinformatics/Trimmomatic-0.30/\n</code></pre> <p>Trinotate (Release 2014-07-08)</p> <pre><code> path = /usr/local/bioinformatics/Trinotate_r20140708/\n</code></pre> <p>bedtools (2.22.1)</p> <pre><code> path = /usr/local/bioinformatics/bedtools-2.22.1/\n</code></pre> <p>bismark (0.14.2)</p> <pre><code> path = /usr/local/bioinformatics/bismark_v0.14.2/\n</code></pre> <p>bowtie (1.0.0)</p> <pre><code> path = /usr/local/bioinformatics/bowtie-1.0.0/\n</code></pre> <p>bowtie2 (2.1.0)</p> <pre><code> path = /usr/local/bioinformatics/bowtie2-2.1.0/\n</code></pre> <p>cufflinks (2.2.1.OSX_x86_64)</p> <pre><code> path = /usr/local/bioinformatics/cufflinks-2.2.1.OSX_x86_64/\n</code></pre> <p>fastx_toolkit (0.0.13.2)</p> <pre><code> path = /usr/local/bioinformatics/fastx_toolkit-0.0.13.2/\n</code></pre> <p>hmmer (3.1b1)</p> <pre><code> path = /usr/local/bioinformatics/hmmer-3.1b1/\n</code></pre> <p>libgtextutils (0.6.1)</p> <pre><code> path = /usr/local/bioinformatics/libgtextutils-0.6.1/\n</code></pre> <p>ncbi-blast (2.2.29+)</p> <pre><code> path = /usr/local/bioinformatics/ncbi-blast-2.2.29+/\n</code></pre> <p>ngsplot (2.08)</p> <pre><code> path = /usr/local/bioinformatics/ngsplot-2.08/\n</code></pre> <p>rsem (1.2.10)</p> <pre><code> path = /usr/local/bioinformatics/rsem-1.2.10/\n</code></pre> <p>signalp (4.1)</p> <pre><code> path = /usr/local/bioinformatics/signalp-4.1/\n</code></pre> <p>stacks (1.13)</p> <pre><code> path = /usr/local/bioinformatics/stacks-1.13/\n</code></pre> <p>tophat (2.0.13.OSX_x86_64)</p> <pre><code> path = /usr/local/bioinformatics/tophat-2.0.13.OSX_x86_64/\n</code></pre> <p>trinity (Release 2013-11-10)</p> <pre><code> path = /usr/local/bioinformatics/trinityrnaseq_r20131110/\n</code></pre> <p>ipython (3.0.0)</p> <p>Geneious (5.3.6)</p>"},{"location":"Lab-Software/#computer-ostrich","title":"Computer: ostrich","text":""},{"location":"Lab-Software/#os-os-x-10116","title":"OS: OS X (10.11.6)","text":"<p>Anaconda3 (with R kernel and rpy2 for jupyter)</p> <pre><code> path = /Users/Shared/anaconda3\n</code></pre> <p>FastQC (0.11.5)</p> <pre><code> path = /Users/Shared/bioinformatics/FastQC/\n</code></pre> <p>Trimmomatic (0.30)</p> <pre><code> path = /Users/Shared/bioinformatics/Trimmomatic-0.36/\n</code></pre> <p>Trinotate (3.0.1)</p> <pre><code> path = /Users/Shared/bioinformatics/Trinotate-3.0.1/\n</code></pre> <p>bedtools (2.26.0)</p> <pre><code> path = /Users/Shared/bioinformatics/bedtools2/\n</code></pre> <p>bismark (0.16.3)</p> <pre><code> path = /Users/Shared/bioinformatics/bismark_v0.15.0/\n</code></pre> <p>bowtie (1.1.2)</p> <pre><code> path = /Users/Shared/bioinformatics/bowtie1-1.1.2\n</code></pre> <p>bowtie2 (2.2.9)</p> <pre><code> path = /Users/Shared/bioinformatics/bowtie2-2.2.9\n</code></pre> <p>celera assembler (8.3rc2)</p> <pre><code>path = /Users/Shared/bioinformatics/wgs-8.3rc2\n</code></pre> <p>cufflinks (2.2.1.OSX_x86_64)</p> <pre><code> path = /Users/Shared/bioinformatics/cufflinks-2.2.1.OSX_x86_64\n</code></pre> <p>hmmer (3.1b2)</p> <pre><code> path = /Users/Shared/bioinformatics/hmmer-3.1b2-macosx-intel\n</code></pre> <p>ncbi-blast (2.5.0)</p> <pre><code> path = /Users/Shared/bioinformatics/ncbi-blast-2.5.0+\n</code></pre> <p>ngsplot (2.08)</p> <pre><code> path = /Users/Shared/bioinformatics/ngsplot\n</code></pre> <p>rsem (1.3.0)</p> <pre><code> path = /Users/Shared/bioinformatics/RSEM-1.3.0\n</code></pre> <p>stacks (1.44)</p> <pre><code> path = /Users/Shared/bioinformatics/stacks-1.44\n</code></pre> <p>tophat (2.1.1)</p> <pre><code> path = /Users/Shared/bioinformatics/tophat-2.1.1.OSX_x86_64\n</code></pre> <p>trinity (2.3.2)</p> <pre><code> path = /Users/Shared/bioinformatics/trinityrnaseq-Trinity-V2.3.2\n</code></pre>"},{"location":"Lab-Software/#computer-raven","title":"Computer: raven","text":""},{"location":"Lab-Software/#os-ubuntu-1604","title":"OS: Ubuntu 16.04","text":""},{"location":"Lab-Software/#cpus-48","title":"CPU(s): 48","text":""},{"location":"Lab-Software/#memory-256gb","title":"Memory: 256GB","text":""},{"location":"Lab-Software/#hdd-capacity-10tb","title":"HDD Capacity: 1.0TB","text":""},{"location":"Lab-Software/#ext-hdd-1-capacity-mediaext_hdd01-10tb","title":"Ext. HDD 1 Capacity (<code>/media/ext_HDD01</code>): 1.0TB","text":""},{"location":"Lab-Software/#ext-hdd-2-capacity-mediaext_hdd01-10tb","title":"Ext. HDD 2 Capacity (<code>/media/ext_HDD01</code>): 1.0TB","text":""},{"location":"Lab-Software/#int-hdd-1-capacity-homeshared8tb_hdd_01-80tb","title":"Int. HDD 1 Capacity (<code>//home/shared/8TB_HDD_01</code>): 8.0TB","text":""},{"location":"Lab-Software/#int-hdd-2-capacity-homeshared8tb_hdd_02-80tb","title":"Int. HDD 2 Capacity (<code>/home/shared/8TB_HDD_02</code>): 8.0TB","text":"<pre><code>$/home/shared\nblast_dbs  blobtoolkit-v2.6.2  bowtie2-2.4.4-linux-x86_64  jellyfish-2.3.0  kallisto  ncbi-blast-2.11.0+  salmon-1.4.0_linux_x86_64  samtools-1.12  trinityrnaseq-v2.12.0\n</code></pre>"},{"location":"Lab-Software/#rstudio-server","title":"RStudio Server","text":"<ol> <li> <p>Activate Husky OnNet VPN service.</p> </li> <li> <p>Paste the following URL in your internet browser:</p> <ul> <li> <p><code>http://172.25.149.12:8787</code></p> </li> <li> <p>If you receive a notice from your browser regarding \"insecure connection\", you may safely ignore this and proceed.</p> </li> </ul> </li> <li> <p>Use login credentials provided by Steven or Sam.</p> </li> <li> <p>If you encounter any issues, please create a new Issue. Please post screenshots and paste text of any error messages you encounter.</p> </li> </ol>"},{"location":"Lab-Software/#computer-roadrunner","title":"Computer: roadrunner","text":""},{"location":"Lab-Software/#os-ubuntu-1604_1","title":"OS: Ubuntu 16.04","text":""},{"location":"Lab-Software/#cpus-16","title":"CPU(s): 16","text":""},{"location":"Lab-Software/#memory-48gb","title":"Memory: 48GB","text":""},{"location":"Lab-Software/#hdd-capacity-18tb","title":"HDD Capacity: 1.8TB","text":"<pre><code>$/home/shared\nalpaca           Bismark-v0.17.0               bwa-0.7.17      igv-webapp              macau                  ncbi-blast-2.7.1+-src  RepeatMasker-4.0.7         SOAPdenovo2-r241\nanaconda3        BisSNP                        ectools-0.1     jellyfish-2.2.6         meraculous-2.2.5       parallel-20180422      rmblast_2.6.0              TrimGalore-0.4.5\nbbmap_38.44      bowtie2-2.3.3.1-linux-x86_64  EMBOSS-6.6.0    kallisto_linux-v0.43.1  Meraculous-v2.2.5      PBSuite_15.8.24        salmon-1.2.1_linux_x86_64  wgs-assembler\nbedtools-2.28.0  bowtie2-2.3.4.1-linux-x86_64  fastqc_v0.11.7  kmergenie-1.7044        MultiQC                pecan                  samtools-1.6\nbin              BSMap                         IGVTools        Log-Log4perl-1.49       ncbi-blast-2.6.0+-src  pyfaidx-0.5.3.1        samtools-1.8\n</code></pre> <p><pre><code>/usr/bin\ncutadapt\nR (Microsoft Open R 3.5.1)\n</code></pre> <pre><code>/home/shared/anaconda3/bin\njupyter (with R Kernel)\n</code></pre></p>"},{"location":"Lab-Software/#jbrowse-genome-viewer-v1154","title":"JBrowse Genome Viewer v1.15.4","text":"<p>http://roadrunner.fish.washington.edu/jbrowse/</p>"},{"location":"Lab-Software/#computer-mox-hyak","title":"Computer: Mox (Hyak)","text":""},{"location":"Lab-Software/#os-red-hat-enterprise-72-login-nodes","title":"OS: Red Hat Enterprise 7.2 (login nodes)","text":""},{"location":"Lab-Software/#os-centos-linux-721511-build-interactive-nodes-execute-nodes","title":"OS: CentOS Linux 7.2.1511 (build,  interactive nodes, &amp; execute nodes)","text":"<pre><code>$/gscratch/srlab/programs\n2bRAD_GATK            busco-v3      git-sym         mdust                    perl                samtools-1.4              supernova-2.0.0\nargparse-1.4.0            bwa-0.7.15    graphviz-2.40.1     megahit_v1.1.4_LINUX_CPUONLY_x86_64-bin  picard_2.18.4           samtools-1.9              tmhmm-2.0c\nAugustus-3.3.2            bwa-0.7.17    hisat2-2.1.0        MetaGeneMark_linux_64_3.38       picard-2.9.1            scripts                   transdecoder\nbamtools-2.5.1            canu      hmmer-2.3       Metassembler                 pigz-2.4            seqtk-1.3                 TransDecoder-v5.3.0\nbbmap_38.34           celera        hmmer-3.1b2     minimap                  pilon               setuptools-36.0.1             TransDecoder-v5.5.0\nbcftools-1.9              cmake-3.12.1  hmmer-3.2.1     mummer                   pitchfork           signalp-4.1               TrimGalore-0.4.5\nbcl2fastq-v2.20           cutadapt-1.16 htslib-1.9      MUMmer3.23               platanus_1.2.4          smrtanalysis_2.3.0.140936.run     Trimmomatic-0.36\nbedtools-2.27.1           decorator-4.0.11  interproscan-5.31-70.0  ncbi-blast-2.6.0+            pyfaidx-0.5.5.2         snap                  Trinity-v2.8.3\nbin               FastaIndex    jellyfish-2.2.10    ncbi-blast-2.8.1+            pyScaf              SOAPdenovo2               Trinotate-v3.1.1\nBismark-0.19.0            FastQC-0.11.5 jsoncpp-1.8.4       ncbi-blast-2.8.1+_orginal        quast-4.5           SOAPec_bin_v2.03              wtdbg-2.1_x64-linux\nBismark-0.21.0            gapcloser-1.12    kmergenie-1.7048    networkx-1.11                racon               SPAdes-3.13.0-Linux\nBismark-0.21.0_dev        GARM_v0.7.5   last-852        networkx2                redundans           SparseAssembler\nbowtie2-2.1.0             GATK      likelybin-0.1.0     parallel-20180822            resources           sqlite\nbowtie2-2.3.4.1-linux-x86_64  gcc       maker-2.31.10       PBSuite                  RNAMMER-1.2             SSPACE-LongRead_v1-1\nbsmap-2.89            get-pip.py    MaSuRCA-3.2.3       pecan                    salmon-0.11.2-linux_x86_64  SSPACE-STANDARD-3.0_linux-x86_64\n</code></pre>"},{"location":"Lab-Software/#computer-woodpecker","title":"Computer: woodpecker","text":""},{"location":"Lab-Software/#os-windows-7-enterprise-64-bit","title":"OS: Windows 7 Enterprise (64-bit)","text":"<p>Microsoft Office 2016 Pro Plus</p> <pre><code>      path = C:\\Program Files\\Microsoft Office\n</code></pre> <p>Protein Digest Simulator v2.2.6138.19320</p> <pre><code>      path = C:\\Program Files (x86)\\ProteinDigestionSimulator\n</code></pre> <p>Proteowizard v3.0.10577</p> <pre><code>      path = C:\\Program Files\\ProteoWizard\\ProteoWizard 3.0.10577\n</code></pre> <p>Skyline v3.6</p> <pre><code>      path =\n</code></pre>"},{"location":"Lab-Software/#computer-swan","title":"Computer: swan","text":""},{"location":"Lab-Software/#os-windows-7-enterprise-64-bit_1","title":"OS: Windows 7 Enterprise (64-bit)","text":"<p>Microsoft Office Professional 2016 64-bit - Access - Excel - Power Point - Word</p> <p>R v3.4.2</p> <p>R Studio 1.1383</p> <p>Skyline v3.7.0.11317</p> <p>Skyline Daily v3.7.1.11446</p> <p>Virtual Clonedrive v5.5.0.0</p> <p>ProteoWizard 3.0.11516 64-bit - MSConvert - SeeMS</p> <p>LabX v. 8.0.0 Build 3444</p> <p>Protein Digest Simulator v2.2.6471; September 19, 2017</p>"},{"location":"Onboarding/","title":"Onboarding","text":"<p>Onboarding to the Roberts Lab at the University of Washington.</p> <p>For newcomers, please read the following pages. Please read carefully, complete any required tasks (e.g. safety documentation).</p> <ol> <li> <p>Code of Conduct</p> </li> <li> <p>Lab Safety</p> </li> <li> <p>Lab Notebooks</p> </li> <li> <p>Data Management</p> </li> <li> <p>Lab Communication</p> </li> <li> <p>Computing</p> </li> </ol>"},{"location":"Onboarding/#lab-iaqs","title":"Lab IAQs","text":"<p>(Initially Asked Questions) or TLDR Handbook</p>"},{"location":"Onboarding/#what-things-do-i-need-to-do-to-get-connected","title":"What things do I need to do to get \"connected\"?","text":"<p>Get on lab Slack, added to the lab GitHub Organization, added to Lab Calendar, attend Lab Meetings, post regularly to your lab notebook.</p>"},{"location":"Onboarding/#what-do-i-need-to-have-on-my-devices-to-get-started","title":"What do I need to have on my device(s) to get started?","text":"<ul> <li>shell</li> <li>git    </li> <li>GitHub Desktop   </li> <li>RStudio   </li> </ul>"},{"location":"Onboarding/#what-do-you-recommend-for-learning-more-about-the-process-and-output-of-the-labss-scientific-endevours","title":"What do you recommend for learning more about the process and output of the labs's scientific endevours?","text":"<ul> <li>tusk</li> <li>FISH546</li> </ul>"},{"location":"Onboarding/#getting-connected-at-the-university-of-washington","title":"Getting connected at the University of Washington","text":"<p>At the University of Washington, there are a number of departments, schools, programs, institutes, and people that you may find beneficial to connect with. Below are some resources to help get you connected.</p>"},{"location":"Onboarding/#dei-groups-committees-centers-and-resources","title":"DEI Groups, Committees, Centers, and Resources","text":"<p>This is a list (non-exhaustive) of DEI groups, committees, centers, and resources available to you at UW and beyond: Our DEI page</p>"},{"location":"Onboarding/#listservs","title":"Listservs","text":"<p>If you experience any problems in joining these listservs, email SAFS computing administrator, Michael Parker (safshelp@uw.edu)</p> <ul> <li>SAFS social safssocial@uw.edu: click here to join</li> <li>SAFS job postings safsjobs@uw.edu: click here to join</li> <li>SAFS community Slack: click here to join. If you have trouble joining, email Steven Roberts (sr320@uw.edu)</li> </ul>"},{"location":"Onboarding/#undergraduate-students","title":"Undergraduate students","text":"<ul> <li>SAFS Undergraduate Resources: Research and Internships, Study Abroad</li> <li>SAFS Undergraduate funding</li> <li>Undergraduate Research Symposium</li> <li>College of the Environment's undergraduate research journal, FieldNotes</li> </ul>"},{"location":"Onboarding/#graduate-students","title":"Graduate students","text":"<ul> <li>UW Graduate School</li> <li>Graduate Opportunities and Minority Achievement Program (GO-MAP): Community for graduate students of color across the three UW campuses</li> <li> <p>Graduate and Professional Student Senate (GPSS)</p> </li> <li> <p>UW College of the Environment</p> </li> <li>Graduate student resources</li> <li>listserv environment_grads@uw.edu : Stay updated on graduate student opportunities and seminars. Click here to join</li> <li> <p>CoEnv travel funding</p> </li> <li> <p>SAFS Graduate Program</p> </li> <li>Assistant Director of Student Services and DEI: Samantha Scherer (iamsams@uw.edu)</li> <li>HR Mananger : Amy Fox (amyfox@uw.edu) </li> <li>Fisheries Interdisciplinary Network of Students (FINS): Graduate student organization within the School of Aquatic and Fishery Sciences. In addition to serving as an umbrella organization for several graduate student committees, FINS also raises funds to support student travel to conferences and organizes academic and social events throughout the year.<ul> <li>Student travel and conference awards</li> </ul> </li> <li>listserv safsgrads@uw.edu: click here to join</li> <li>SAFS Graduate Student Slack: click here to join</li> </ul>"},{"location":"Onboarding/#postdocs","title":"Postdocs","text":"<ul> <li> <p>UW Office of Postdoctoral Affairs</p> <ul> <li>UW Office of Postdoctoral Affairs listserv: to join, send an email request to uwopa@uw.edu</li> <li>UW Postdoc Association Twitter: @UWPostDocs</li> <li>UW Postdoc Association Slack channel: to join, send an email request to uwpa@uw.edu</li> <li>Postdoc Parenting Group</li> <li>Postdoc Diversity Alliance</li> </ul> </li> <li> <p>UW College of the Environment Postdocs</p> <ul> <li>more CoEnv Postdoc resources: https://environment.uw.edu/intranet/academics/postdoctoral-resources/</li> <li>listserv environment_postdocs@uw.edu : Stay in the loop on career preparation seminars, career panels, opportunities to give practice talks, etc. To join, email the CoEnv Graduate Student and Postdoctoral Services Specialist, Anthony Salazar (asalazar@uw.edu)</li> <li>CoEnv travel funding</li> </ul> </li> <li> <p>UW SAFS Postdocs</p> <ul> <li>join SAFS postdoc channel on Slack: click here to join</li> <li>join the SAFS Postdocs listserv safspostdocs@uw.edu: click here to join</li> </ul> </li> </ul>"},{"location":"Onboarding/#faculty","title":"Faculty","text":"<p>https://uwnetid.sharepoint.com/sites/safs/facultygovernance (Log in with UW net id)</p> <p>In particular under \"Policies\" 1. \"Salary recovery policy\" explains how if you have too many grants for your salary, you can use some to cover state salary, and then the state salary gets shifted to SAFS (benefits portion) and your RCR (the remainder).</p> <ol> <li> <p>\"Salary recovery policy\" teaching buyout. You can buy out from 1 quarter of teaching a small seminar course, for 1.5 mo of salary, or a large course for 2 mo of salary. Restrictions apply.</p> </li> <li> <p>\"Teaching release\", when substantially revamping a course or developing a new course, it is possible to get a one-quarter teaching release.</p> </li> </ol> <p>In addition, there are University-wide policies that some of us have signed up for: 1. A/B salary. For those who often have extra grant funding, it is possible to use the A/B salary. Your state income stays the same, but pays for only 80% or 90% of your time (basically an increase in monthly salary rate), and the extra time is covered by external grants. More details here: https://environment.uw.edu/intranet/personnel/academic-human-resources/salary-compensation/ab-salary-retention-adjustment-policy</p> <ol> <li>Personal mobile phone use for business. It is possible to cover a portion of your cell phone bill from RCR if you use your cell phone for UW business. More details here: https://www.washington.edu/admin/rules/policies/APS/55.01.html This one depends on departmental policy to some extent.</li> </ol>"},{"location":"Pubathon/","title":"Pub-a-thon 2022","text":"<p>15) CEABiGR Yaamini, Sam et al    Working Draft Paper Repo </p> <p>10) Single cell RNA-seq - Mac Working Draft GitHub </p> <p>9) Mussel (Mytilus trossulus) heat stress response - Zach &amp; Chris et al  Working Draft Paper Repo </p> <p>10) Diploid and triploid Pacific oysters display different DNA methylation patterns following desiccation stress  - Matt Working Draft GitHub </p> <p>11) The impact of ploidy on the physiological and genetic response of Pacific oysters following multiple stress exposure  - Matt Working Draft GitHub </p> <p>6) Tanner crab and Hematodinium gene expression - Aspen et al Working draft Paper repo </p> <p>7) Citrate Synthase Response and Multiple Stress in Pacific Oysters (C. gigas) - Olivia Working Draft Paper Repo </p> <p>3) Coral nutritional exchange across ontogeny - Ariana et al     Working draft Paper repo </p> <p>4) Coral nutritional exchange in larvae under thermal stress - Ariana et al     Working draft Paper repo </p> <p>5) Coral phenotypes shaped by host and symbiont physiological plasticity across environments in Moorea French Polynesia - Ariana et al     Working draft Paper repo </p> <p>8) Comparative Transcriptome Analysis of Geoduck Clam (P. generosa) - Olivia Working Draft Paper Repo 1 Paper Repo 2 </p> <p>12) The impact of environmental stressors on the expression of byssal thread proteins  - Matt Working Draft GitHub </p> <p>13) Berdahl-sockeye-salmon manuscript  - Matt Working Draft GitHub </p> <p>13) Factors associated with Bitter Crab Syndrome in Southeast Alaskan Tanner crab  - Aspen Working Draft GitHub </p> <p>14) Geoduck OA and reproductive development - Shelly et al Working draft Paper repo </p> <p>14) Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo </p> <p>15) Temp and Salinity effects on Salmon with sea lice - Shelly et al Working draft Paper repo </p> <p>17) Effects of OA on Manila and Littleneck clams - Larken et al Working draft Paper repo </p> <p>1) Proteomic response of early juvenile Pacific Oysters to temperature - Grac et al Working Draft GitHub  Journal: PeerJ     </p> <p>2) Geoduck Env Memory Genome Paper - Hollie and Shelly et al   Working draft OSF GitHub </p>"},{"location":"Pubathon/#pub-a-thon-2021","title":"Pub-a-thon 2021","text":"<p>Tier Red</p> <p>1) Geoduck Env Memory Genome Paper - Hollie et al   Working draft OSF GitHub </p> <p>4) Geoduck OA and reproductive development - Shelly et al Working draft Paper repo  Journal:</p> <p>5) Geoduck OA transgenerational effects - Shelly et al Working draft Paper repo  Journal:</p> <p>11) Characterization of the gene repertoire and environmentally driven expression patterns in Tanner crab (Chionoecetes bairdi) - Grace Working Draft GitHub Reviews </p> <p>24) Tanner crab and Hematodinium gene expression - Aspen et al Working draft Paper repo  Journal:</p> <p>Tier Yellow</p> <p>6) Temp and Salinity effects on Salmon with sea lice - Shelly et al Working draft Paper repo  Journal:</p> <p>8) Oly epigenetics by population - Laura, Katherine, Steven Working Draft GitHub </p> <p>9) Oly pCO2 Carryover Gene Expression via QuantSeq - Laura Working Draft GitHub </p> <p>12) Proteomic response of early juvenile Pacific Oysters to temperature - Grace Working Draft GitHub </p> <p>13) Differential methylation in response to OA with diploid and triploid oysters - Yaamini Working Draft Github </p> <p>14) Differential gonad methylation in female oysters - Yaamini Working Draft Github </p> <p>15) Harnessing the Power of Single-cell RNA Sequencing to Control Reproductive Development in Bivalves - Mac Working Draft GitHub </p> <p>17) Oly WGBS - Steven Working Draft GitHub </p> <p>20) Differential gene expression in Hematodinium  - Aspen Working Draft GitHub </p> <p>22) Epigenetic response of diploidy and triploid Pacific Oysters to desiccation stress  - Matt Working Draft GitHub </p> <p>23) Cvirg Methylation and Gene Expression Working Draft Github </p> <p>Tier Blue</p> <p>2) Coupled Microbiome Analyses Highlights Relative Functional Roles of Bacteria in a Bivalve Hatchery - Emma et al   https://doi.org/10.1186/s40793-021-00376-z        Journal: Environmental Microbiome      </p> <p>3) Invertebrate methylomes provide insight into mechanisms of environmental tolerance and reveal methodological biases - Shelly and Yaamini et al Working draft Paper repo  Journal:  Molecular Ecology</p> <p>7) Latent effects of winter warming on Olympia oyster reproduction and larval viability - Laura  https://doi.org/10.1016/j.jembe.2021.151604    GitHub  Journal of Experimental Marine Biology and Ecology. doi:10.1016/j.jembe.2021.151604</p> <p>16) DNA methylation profiling of a cnidarian-algal symbiosis using nanopore sequencing - Jay  https://doi.org/10.1093/g3journal/jkab148  GitHub  Journal: G3</p> <p>21) OA impact on invertebrate reproduction - Laura and Yaamini Working Draft </p> <p>19) Chromosome-scale genome assembly of the sea louse Caligus rogercresseyi by SMRT sequencing and Hi-C analysis  https://doi.org/10.1038/s41597-021-00842-w    Journal: Scientific Data   Figshare</p>"},{"location":"Pubathon/#pub-a-thon-2020","title":"Pub-a-thon 2020","text":"<p>1) Oyster larval proteomics - 2015  -   Grace Working draft Rhonda's repo Paper repo (clean repo) </p> <p>2) Crab project - 2020  -  Grace First transcriptome working draft New transcriptome working draft Crab project repo </p> <p>3) Virginica gonad methylation - Yaamini Working draft Repo  Journal: Frontiers</p> <p>4) Gigas/Virginica gonad/offspring methylation - Yaamini Associated repo and draft coming soon</p> <p>5) Gigas/Virginica multiple tissue/method - Yaamini Associated repo and draft coming soon</p> <p>5) Oly larvae food and temp - Laura draft  Journal: Aquaculture  </p> <p>6) Oly epigenetics by population - Laura, Katherine, Steven Working Draft GitHub </p> <p>7) Geoduck Env Memory Genome Paper - Hollie et al   Working draft OSF GitHub  Journal:</p> <p>8)  Hatchery Microbiome   - Emma Working Draft WSG Final Report Megan Files Megan Publications </p> <p>9) Polydora risk to WA aquaculture - Laura Submitted Draft (pre-reviewer edits) </p> <p>10) Oly pCO2 Carryover Gene Expression via QuantSeq - Laura DRAFT LINK COMING SOON </p>"},{"location":"Pubathon/#pub-a-thon-2019","title":"Pub-a-thon 2019","text":""},{"location":"Pubathon/#wsg-bracket","title":"WSG Bracket","text":"<p>a) Hatchery Microbiome   - Emma Working Draft </p> <p>b) Geoduck pH proteomic   - Emma Working Draft </p> <p>c) Oyster larval proteomics - 2015  -   Grace Working draft Rhonda's repo Paper repo (clean repo) </p> <p>d) 2016 Temperature treated C.gigas larvae   - Shelly BioRxiv Clean Manuscript Repo Working Draft Shelly's Repo (ASCA on NSAF values, proportions test and fold change analysis on total num spectra, network analysis) Kaitlyn's Repo (with clustering analysis) Rhonda's Repo (with original survival and development data, and initial analyses) Rhonda's initial draft paper and Rhonda's other draft </p> <p>e) Winter temp/pH affect Oly reproduction &amp; larval viability (2017 exp.)  - Laura Working Draft Repo </p> <p>d) Oly larvae food and temp - Laura draft </p>"},{"location":"Pubathon/#pub-a-thon-2018","title":"Pub-a-thon 2018","text":"<p>list of papers</p> <p>1) Geoduck epigenetics and genome sequencing 1-Authorea  2-Draft - Genome Sequencing (G Docs) Repo (URL needed) </p> <p>2) Olympia Oyster WGBS Draft</p> <p>14) Oly DNA methylation and population structure.  Sam   Early Draft (Overleaf)  Repo URL Needed      </p> <p>2) Geoduck Outplant, pH/DNR Working Draft Repo </p> <p>4) 2018 Oly experiment Working Draft Repo </p> <p>6) Oil Exposure and DNA methylation in oysters  repo-URL: https://github.com/sr320/paper-Cvirg-oil  </p> <p>7) Effects of temperature change and Hematodinium sp. infection (Bitter Crab Disease) on Tanner crab (Chionoecetes bairdi) (Grace)     Working draft  repo-URL: https://github.com/grace-ac/paper-bitter-crab      </p> <p>10) Virginica gonad methylation Working draft Repo </p> <p>11) C.gigas methylation analysis Working draft Repo </p> <p>5) Response of DNA methylation to experimental transplantation in Porites astreoides Repo coming soon</p> <p>1) Adult low pH exposure influences larval abundance in Pacific oysters (Crassostrea gigas)  - Yaamini Working draft Repo reviews  Journal: JSR</p> <p>7) Gigas DNR Working draft Repo reviews  Journal: Marine Ecological Progress Series  </p> <p>3) Polydora risk to WA aquaculture Working Draft </p> <p>10) Geoduck Transcriptome  repo-URL: https://osf.io/3xf6m/    </p>"},{"location":"Pubathon/#pub-a-thon-2017","title":"Pub-a-thon 2017","text":"<p>list of papers</p> <p>17) Aquaculture and Epigenetics Repo-URL:        draft: on GoogleDocs  Journal 1: NOAA Technical Note     Journal 2: PeerJ    Response to Reviews: on GoogleDocs  PeerJ Revisions: on Google Docs</p> <p>19) Shellfish Functional Genomics  Repo-URL: https://github.com/sr320/fun-gen             draft: on GoogleDocs  Journal: JSR   </p> <p>6) Differential response to stress in Ostrea lurida (Carpenter 1864) as indicated by GENE EXPRESSION  repo-URL: https://github.com/RobertsLab/paper-Olurida-gene draft:  (see repo)     preprint:  https://peerj.com/preprints/1595/  Review Response: GoogleDocs </p> <p>21) Oyster Reproduction  / Genetics and Epigenetics  repo-URL:   draft: googledoc  Submission - Book Chapter    </p> <p>4) Puget Sound Oly Larval Performance repo-URL: https://github.com/ksil91/PS-Oly-Larvae-Growth draft: google-doc, Scientific Report version google-doc    - Paperpile     Journal: Scientific Reports    </p> <p>5) Juvenile Geoduck OA Exposure: Growth and Methylation (Hollie et al.)     repo-URL: https://github.com/hputnam/project_juvenile_geoduck_OA    draft: authorea </p> <p>10) Geoduck Transcriptome  repo-URL: https://osf.io/3xf6m/   </p> <p>13) Oly paper Megan (Megan)      repo-URL: https://github.com/MeganHintz/Paper---Oly-fingerprinting      draft: google-doc   - Paperpile</p> <p>15) Climate adaptability in Ostrea lurida (Laura)    Repo-URL: https://github.com/laurahspencer/O.lurida_Temp-OA_Gonad    draft: on GoogleDocs </p> <p>14)  C.gigas methylation analysis (Yaamini)   repo-URL: https://github.com/RobertsLab/paper-gigas-metaanalysis     draft: google-doc </p> <p>11) Oyster Hatchery 2015 Proteomics  repo-URL: https://github.com/RobertsLab/project-pacific.oyster-larvae draft: 2015 Google Doc </p> <p>23) Geoduck OA Larval Proteomics Jose    repo-URL:     draft: GoogleDoc </p> <p>20) Assessment of Toxicant Impact to Coho Salmon using a Novel Toxicogenetic Biomarker Assay  Repo-URL:        draft: on GoogleDocs </p> <p>22) Oyster Hatchery 2016 Proteomics  repo-URL: https://github.com/RobertsLab/project-pacific.oyster-larvae     draft: 2016 Google Doc </p> <p>12) Geoduck / Oyster DNR proteomics (Laura + Yaamini)     repo-URL:  https://github.com/RobertsLab/Paper-DNR-Proteomics   draft: google-doc   -  Paperpile</p> <p>18) Flounder Gene Expression  Repo-URL:        draft: on GoogleDocs </p> <p>8) Oly Pop Gen (2bRAD - BS)  repo-URL:   draft:   </p> <p>2) A non-lethal, field-based anesthesia protocol for sampling the mantle cavity of Olympia oysters (Megan)  repo-URL: draft:google doc  preprint: https://www.dropbox.com/s/dfwtw8e2s2ix6zf/AnesthesiaPaper_v87.docx?dl=0      Journal: Journal of Shellfish Research</p> <p>16) What goes up must come down: Diel vertical migration in the deepwater sablefish (Anoplopoma fimbria) revealed by satellite popup tags  Journal: Fisheries Oceanography</p> <p>9) Coral Epi RAD (Jay)    repo-URL: https://github.com/jldimond/Branching-Porites   preprint: http://biorxiv.org/content/early/2017/03/22/119156     Journal: Molecular Ecology</p> <p>1) Integrating discovery-driven proteomics and selected reaction monitoring to develop a non-invasive assay for geoduck reproductive maturation (Emma)   repo-URL:https://github.com/sr320/supp-geoduck-proteomics    draft:        preprint: https://doi.org/10.1101/094615   Journal: Journal of Proteome Research</p> <p>3) Evidence of Ostrea lurida (Carpenter 1864) population structure in Puget Sound, WA  repo-URL: https://github.com/RobertsLab/OluridaSurvey2014    draft:    preprint: https://peerj.com/preprints/704/    Journal: Marine Ecology</p> <p>7) Oly GBS (Sam)   data records repo-URL: https://osf.io/j8rc2/   draft repo-URL: https://github.com/kubu4/paper_oly_gbs    draft: https://www.authorea.com/users/4974/articles/149442  preprint (Overleaf): https://www.overleaf.com/read/mqbbvmwxhncg  preprint (PDF): https://osf.io/cdj7m/   Status Details  Review Response: on GoogleDocs  Journal: Scientific Data</p>"},{"location":"Publications/","title":"Publications","text":"<p>"},{"location":"Publications/#peer-reviewed-publications","title":"Peer-Reviewed Publications","text":"<p>see also preprints and Google Scholar</p> <p>Shelly A. Trigg, Kaitlyn R. Mitchell, Rhonda Elliott Thompson, Benoit Eudeline, Brent Vadopalas, Emma B. Timmins-Schiffman &amp; Steven B. Roberts. (2020) Temporal proteomic profiling reveals insight into critical developmental processes and temperature-influenced physiological response differences in a bivalve mollusc BMC Genomics 21, 723 doi:10.1186/s12864-020-07127-3 </p> <p></p> <p>Yong-Kian Lim, Khan Cheung, Xin Dang, Steven B. Roberts, Xiaotong Wang, Vengatesen Thiyagarajan (2020) DNA methylation changes in response to ocean acidification at the time of larval metamorphosis in the edible oyster, Crassostrea hongkongensis Marine Environmental Research, Volume 163 doi:10.1016/j.marenvres.2020.105214 </p> <p>Downey-Wall Alan M., Cameron Louise P., Ford Brett M., McNally Elise M., Venkataraman Yaamini R., Roberts Steven B., Ries Justin B., Lotterhos Katie E (2020) Ocean Acidification Induces Subtle Shifts in Gene Expression and DNA Methylation in Mantle Tissue of the Eastern Oyster (Crassostrea virginica) Frontiers in Marine Science v7 p828 doi:10.3389/fmars.2020.56641 </p> <p>Cristian Gallardo-Esc\u00e1rate; Valentina Valenzuela-Mu\u00f1oz; Gustavo N\u00fa\u00f1ez-Acu\u00f1a; Diego Valenzuela-Miranda; B\u00e1rbara P. Benaventel; Constanza S\u00e1ez-Vera; Homero Urrutia; Beatriz Novoa; Antonio Figueras; Steven Roberts; Paulina Assmann; Marta Bravo (2020) The wastewater microbiome: A novel insight for COVID-19 surveillance Science of The Total Environment Page: 142867 doi:10.1016/j.scitotenv.2020.142867 </p> <p>Bonnie J. Becker, Michael D. Behrens, Brian Allen, Megan Hintz, Hannah Parker, Michelle M. McCartha, and Sarah M. White (2020) Spatial and Temporal Distribution of the Early Life History Stages of the Native Olympia Oyster Ostrea lurida (Carpenter, 1864) in a Restoration Site in Northern Puget Sound, Wa Journal of Shellfish Research 39(1), 43-58. doi:/10.2983/035.039.0105 </p> <p>Emma Timmins-Schiffman, Jos\u00e9 M. Guzm\u00e1n, Rhonda Elliott Thompson, Brent Vadopalas, Benoit Eudeline and Steven B. Roberts (2020) Larval Geoduck (Panopea generosa) Proteomic Response to Ciliates Scientific Reports 10, 6042. doi:10.1038/s41598-020-63218-x </p> <p>Venkataraman Yaamini R., Downey-Wall Alan M., Ries Justin, Westfield Isaac, White Samuel J., Roberts Steven B., Lotterhos Kathleen E (2020) General DNA Methylation Patterns and Environmentally-Induced Differential Methylation in the Eastern Oyster (Crassostrea virginica) Frontiers in Marine Science, Volume 7, Page 225. doi:10.3389/fmars.2020.00225  </p> <p>Gurr SJ, Vadopalas B, Roberts SB, Putnam HM (2020) Metabolic recovery and compensatory shell growth of juvenile Pacific geoduck Panopea generosa following short-term exposure to acidified seawater Conservation Physiology, Volume 8, Issue 1, coaa024. doi:10.1093/conphys/coaa024 </p> <p>Spencer, LH, Venkataraman, YR, Crim R, Ryan S, Horwith MJ, and Roberts SB (2020) Carryover effects of temperature and pCO2 across multiple Olympia oyster populations. Ecological Applications 00( 00):e02060. doi:10.1002/eap.2060 </p> <p>Dimond JL and Roberts SB. (2020) Convergence of DNA Methylation Profiles of the Reef Coral Porites astreoides in a Novel Environment Frontiers in Marine Science. vol 6. doi:10.3389/fmars.2019.00792 </p> <p>Venkataraman YR, Spencer LH, Roberts SB. (2019) Larval Response to Parental Low pH Exposure in the Pacific Oyster Crassostrea gigas Journal of Shellfish Research, 38(3), 743-750. doi:10.2983/035.038.0325 </p> <p>Timmins\u2010Schiffman E, Guzm\u00e1n JM, Elliott Thompson R, Vadopalas B, Eudeline B, Roberts SB. (2019) Dynamic response in the larval geoduck (Panopea generosa) proteome to elevated pCO2. Ecol Evol.00: 1\u2013 13. doi:10.1002/ece3.5885 </p> <p></p> <p>Gallardo-Esc\u00e1rate C, Valenzuela-Mu\u00f1oz V, N\u00fa\u00f1ez-Acu\u00f1a , Carrera C, Gon\u00e7alves AT, Valenzuela-Miranda D, Benavente BP, Roberts SB. (2019) Catching the complexity of salmon-louse interactions Fish &amp; Shellfish Immunology. doi:10.1016/j.fsi.2019.04.065 </p> <p>Spencer LH, Horwith M, Lowe AT, Venkataraman YR, Timmins-Schiffman E, Nunn BL, Roberts SB. (2019) Pacific geoduck (Panopea generosa) resilience to natural pH variation Comparative Biochemistry and Physiology Part D: Genomics and Proteomics. doi:10.1016/j.cbd.2019.01.010  bioRxiv</p> <p>Venkataraman YR, Timmins-Schiffman E, Horwith MJ, Lowe AT, Nunn B, Vadopalas B, Spencer LH, Roberts SB. (2019) Characterization of Pacific oyster Crassostrea gigas proteomic response to natural environmental differences Mar Ecol Prog Ser 610:65-81. doi:10.3354/meps12858  bioRxiv</p> <p>Ju\u00e1rez, O., Lafarga-De la Cruz, F., Leyva-Valencia, I., L\u00f3pez-Landavery, E., Garc\u00eda-Esquivel, Z., D\u00edaz, F., Re-Araujo, D., Vadopalas, B., and C. Galindo-S\u00e1nchez. (2018). Transcriptomic and metabolic response to chronic and acute thermal exposure of juvenile geoduck clams Panopea globosa. Marine Genomics. doi:10.1016/j.margen.2018.09.003 </p> <p>Javier A. Rodriguez\u2010Casariego, Mark C. Ladd, Andrew A. Shantz, Christian Lopes, Manjinder S. Cheema, Bohyun Kim, Steven B. Roberts, James W. Fourqurean, Juan Ausio, Deron E. Burkepile, and Jose M. Eirin\u2010Lopez. (2018) Coral epigenetic responses to nutrient stress: Histone H2A.X phosphorylation dynamics and DNA methylation in the staghorn coral Acropora cervicornis Ecol Evol. 2018;00:1\u201315. doi:10.1002/ece3.4678  pdf</p> <p>Roberts SB, Gavery MR. (2018) Opportunities in Functional Genomics: A Primer on Lab and Computational Aspects Journal of Shellfish Research 37(4):747-754. doi:10.2983/035.037.0406  </p> <p>Silliman KE, Bowyer TK, Roberts SB. (2018) Consistent differences in fitness traits across multiple generations of Olympia oysters Scientific Reports volume 8, Article number:6080. doi:10.1038/s41598-018-24455-3 </p> <p>Heare JE, White SJ, Vadopalas B, Roberts SB. (2018) Differential response to stress in Ostrea lurida as measured by gene expression PeerJ 6:e4261. doi: 10.7717/peerj.4261 </p> <p>Goetz FW, Jasonowicz AJ, Roberts SB. (2017) What goes up must come down: Diel vertical migration in the deep-water sablefish (Anoplopoma fimbria) revealed by pop-up satellite archival tags Fish Oceanogr. 2017;00:1\u201316. doi: 10.1111/fog.12239 </p> <p>Gavery MR, Roberts SB. (2017) Epigenetic considerations in aquaculture PeerJ 5:e4147 doi: 10.7717/peerj.4147 </p> <p></p> <p>Jake Emerson Heare, Brady Blake, Jonathan P Davis, Brent Vadopalas, Steven Roberts (2017) Evidence of Ostrea lurida Carpenter, 1864 population structure in Puget Sound, WA Marine Ecology 38:e12458 doi: 10.1111/maec.12458 </p> <p>Megan Hintz, Katherine Gratz, Bonnie Becker, Brent Vadopalas, and Steven Roberts (2017) A Nonlethal Anesthesia Protocol for Accessing the Mantle Cavity of Olympia Oysters in the Laboratory or Field Journal of Shellfish Research 2017 36 (2), 353-357 doi: 10.2983/035.036.0207 </p> <p>Samuel J. White, Brent Vadopalas, Katherine Silliman &amp; Steven B. Roberts (2017) Genotoype-by-sequencing of three geographically distinct populations of Olympia oysters, Ostrea lurida Scientific Data 4, Article number: 170130 doi: 10.1038/sdata.2017.130 </p> <p>Dimond JL, Gamblewood SK, Roberts SB. (2017) Genetic and epigenetic insight into morphospecies in a reef coral Molecular Ecology. 00:1\u201312. doi: 10.1111/mec.14252 </p> <p>Emma B. Timmins-Schiffman, Grace A Crandall, Brent Vadopalas, Michael E. Riffle, Brook L. Nunn and Steven Roberts (2017) Integrating discovery-driven proteomics and selected reaction monitoring to develop a non-invasive assay for geoduck reproductive maturation Journal of Proteome Research doi: 10.1021/acs.jproteome.7b00288  pdf</p> <p>C. Gallardo-Esc\u00e1rate V. Valenzuela-Mu\u00f1oz S. Bolta\u00f1a G. Nu\u00f1ez-Acu\u00f1a D. Valenzuela-Miranda A.T. Gon\u00e7alves C. D\u00e9tr\u00e9e E. Tarife\u00f1o-Saldivia R. Farlora S. Roberts H.M. Putnam (2017) The Caligus rogercresseyi miRNome: Discovery and transcriptome profiling during the sea lice ontogeny AgriGene doi: 10.1016/j.aggene.2017.03.002 </p> <p>The Aquaculture Genomics, Genetics and Breeding Workshop (2017) Aquaculture genomics, genetics and breeding in the United States: current status, challenges, and priorities for future research BMC Genomics 18:191. doi: 10.1186/s12864-017-3557-1 </p> <p>Detree C, N\u00fa\u00f1ez-Acu\u00f1a G, Roberts S, Gallardo-Esc\u00e1rate C (2016) Uncovering the Complex Transcriptome Response of Mytilus chilensis against Saxitoxin: Implications of Harmful Algal Blooms on Mussel Populations PLoS ONE 11(10): e0165231. doi:10.1371/journal.pone.0165231 </p> <p></p> <p>Dimond JL and Roberts SB  (2016), Germline DNA methylation in reef corals: patterns and potential roles in response to environmental change Molecular Ecology doi:10.1111/mec.13414  preprint</p> <p>Jasonowicz AJ, Goetz FW, Goetz GW, Nichols KM (2016) Love the one you're with: Genomic evidence of panmixia in the sablefish (Anoplopoma fimbria) Canadian Journal of Fisheries and Aquatic Sciences doi: 10.1139/cjfas-2016-0012 </p> <p>Froehlich HE, Roberts SB, Essington TE (2015) Evaluating hypoxia-inducible factor-1\u03b1 mRNA expression in a pelagic fish, Pacific herring Clupea pallasii, as a biomarker for hypoxia exposure Comparative Biochemistry and Physiology - Part A: Molecular and Integrative Physiology doi:10.1016/j.cbpa.2015.07.016 </p> <p>Cook MA, Massee KC, Wade TH, Oden SM, Jensen C, Jasonowicz A, Immerman DA, Goetz FW (2015) Culture of sablefish (Anoplopoma fimbria) larvae in four experimental tank designs Aquacultural Engineering doi:10.1016/j.aquaeng.2015.09.003 </p> <p></p> <p>Fuess LE, Eisenlord ME, Closek CJ, Tracy AM, Mauntz R, Gignoux-Wolfsohn S, Moritsch MM,  Yoshioka R,  Burge CA, Harvell CD, Friedman CS, Hewson I, Hershberger PK, Roberts SB (2015) Up in Arms: Immune and Nervous System Response To Sea Star Wasting Disease PLoS ONE doi:10.1371/journal.pone.0133053 </p> <p>Timmins-Schiffman E, Coffey WD, Hua W, Nunn BL, Dickinson GH and Roberts SB. (2014). Shotgun proteomics reveals physiological response to ocean acidification in Crassostrea gigas BMC Genomics 2014, 15:951  doi:10.1186/1471-2164-15-951 </p> <p>Immerman DA and Goetz FW (2014). The activation and cryopreservation of sablefish (Anoplopoma fimbria) sperm Aquaculture doi:10.1016/j.aquaculture.2014.04.010  </p> <p>Olson CE and Roberts SB. (2014). Genome-wide profiling of DNA methylation and gene expression in Crassostrea gigas male gametes Frontiers in Physiology. 5:224. doi: 10.3389/fphys.2014.0022   </p> <p>Gavery MR and Roberts SB. (2014) A context specific role for DNA methylation in bivalves Briefings in Functional Genomics. doi:10.1093/bfgp/elt054 (pdf)   </p> <p>Gavery MR and Roberts SB. (2013) Predominant intragenic methylation is associated with gene expression characteristics in a bivalve mollusc PeerJ 1:e215. doi:10.7717/peerj.215   </p> <p></p> <p>Garcia-Vedrenne AE, Groner M, Page-Karjian A, Siegmund G-F, Singhal S, Sziklay J and Roberts SB. (2013) Development of Genomic Resources for a thraustochytrid Pathogen and Investigation of Temperature Influences on Gene Expression PLoS ONE 8(9): e74196. doi:10.1371/journal.pone.0074196   </p> <p>Storer CS, Quinn TP and Roberts SB. (2013) Quantitative PCR analysis used to characterize physiological changes in brain tissue of senescent sockeye salmon Biogerontology. doi:10.1007/s10522-013-9448-1 (pdf)   </p> <p>Burge CA, Mouchka ME, Harvell CD and Roberts SB. (2013) Immune response of the Caribbean sea fan, Gorgonia ventalina, exposed to an Aplanochytrium parasite as revealed by transcriptome sequencing Frontiers in Physiology 4:180. doi:10.3389/fphys.2013.00180   </p> <p>Timmins-Schiffman EB, Nunn BL, Goodlett DR and Roberts SB. (2013) Shotgun proteomics as a viable approach for biological discovery in the Pacific oyster Conservation Physiology. doi:10.1093/conphys/cot009  </p> <p>Timmins-Schiffman EB, Friedman CS, Metzger DC, White SJ and Roberts SB. (2013) Genomic resource development for shellfish of conservation concern Molecular Ecology Resources. doi:10.1111/1755-0998.12052   </p> <p>Timmins-Schiffman EB and Roberts SB. (2012) Characterization of genes involved in ceramide metabolism in the Pacific oyster Crassostrea gigas BMC Research Notes 5:502.  doi:10.1186/1756-0500-5-502   </p> <p></p> <p>Storer CG, Pascal CE, Roberts SB, Templin WD, Seeb LW and Seeb JE. (2012) Rank and Order: Evaluating the Performance of SNPs for Individual Assignment in a Non-Model Organism PLoS ONE 7(11): e49018. doi:10.1371/journal.pone.0049018    </p> <p>Timmins-Schiffman EB,  O\u2019Donnell M, Friedman CS, and Roberts SB. (2012) Elevated pCO2 causes developmental delay in early larval Pacific oysters, Crassostrea gigas Marine Biology. doi:10.1007/s00227-012-2055-x pdf </p> <p>Burge CA, Douglas N, Conti-Jerpe I, Weil E, Roberts SB, Friedman CS and CD Harvell. (2012) Friend or foe: the association of Labyrinthulomycetes with the Caribbean sea fan, Gorgonia ventalina Diseases of Aquatic Organisms 101:1-12. doi:10.3354/dao02487   </p> <p>Metzger DC, Pratt P and Roberts SB. (2012) Characterizing the effects of heavy metal and Vibrio exposure on hsp70 expression in Crassostrea gigas gill tissue Journal of Shellfish Research 31(3):627-630. doi:10.2983/035.031.0305 pdf </p> <p>Roberts SB, Hauser L, Seeb LW and Seeb JE (2012) Development of genomic resources for Pacific herring through targeted transcriptome pyrosequencing PLoS ONE 7(2): e30908. doi:10.1371/journal.pone.0030908   </p> <p>Roberts SB and Gavery MR (2012) Is there a relationship between DNA methylation and phenotypic plasticity in invertebrates? Frontiers in Physiology 2:116. doi:10.3389/fphys.2011.00116   </p> <p></p> <p>Gavery MR and Roberts SB (2012) Characterizing short read sequencing for gene discovery and RNA-Seq analysis in Crassostrea gigas Comparative Biochemistry and Physiology Part D: Genomics and Proteomics 7:2 94-99. doi:10.1016/j.cbd.2011.12.003 </p> <p>Morera D, Roher N, Ribas L, Balasch JC, Do\u00f1ate C, Callol A, Bolta\u00f1a A, Roberts SB, Goetz G, Goetz FW and Mackenzie SA. (2011) RNA-Seq reveals an integrated immune response in nucleated erythrocytes PLoS ONE 6(10): e26998. doi:10.1371/journal.pone.0026998 </p> <p>Roberts SB, Sunila I, and Wikfors G. (2011) Immune response and mechanical stress susceptibility in diseased oysters, Crassostrea virginica Journal of Comparative Physiology B 182:1 41-48. doi:10.1007/s00360-011-0605-z </p> <p>Seeb JE, Carvalho G, Hauser L, Naish K, Roberts SB and Seeb LW. (2011) Single-nucleotide polymorphism (SNP) discovery and applications of SNP genotyping in nonmodel organisms Molecular Ecology Resources 11 1\u20138. doi:10.1111/j.1755-0998.2010.02979.x </p> <p>Seeb JE, Pascal CE, Graue ED, Seeb LW, Templin WD, Harkins T and Roberts SB. (2010) Transcriptome sequencing and high-resolution melt analysis advance single nucleotidepolymorphism discovery in duplicated salmonids Molecular Ecology Resources. doi: 10.1111/j.1755-0998.2010.02936.x </p> <p>Gavery MR and Roberts SB. (2010) DNA methylation patterns provide insight into epigenetic regulation in the Pacific oyster (Crassostrea gigas) BMC Genomics 11:483. doi:10.1186/1471-2164-11-483 </p> <p>Mathger L, Roberts SB, and Hanlon R. (2010) Evidence for distributed light sensing in the skin of cuttlefish, Sepia officinalis Biology Letters. doi: 10.1098/rsbl.2010.0223 </p> <p></p> <p>Goetz FW, Rosauer D, Sitar S, Goetz G, Simchick C, Roberts SB, Johnson R, Murphy C, Bronte C, and Mackenzie S. (2010) A genetic basis for the phenotypic differentiation between siscowet and lean lake trout (Salvelinus namaycush) Molecular Ecology 19 176\u2013196. </p> <p>Defaveri J, Smolowitz R, and Roberts S (2009*) Development and validation of a real-time quantitative PCR assay for the detection and quantification of Perkinsus marinus in the Eastern oyster, Crassostrea virginica Journal of Shellfish Research Vol. 28 No. 3 459-464. </p> <p>Roberts SB, Goetz G, White S, and Goetz F (2009) Analysis of genes isolated from plated hemocytes of the Pacific Oyster, Crassostrea gigas Marine Biotechnology 11:24-44. doi: 10.1007/s10126-008-9117-6 </p> <p>Roberts SB, Gueguen Y, de Lorgeril J, and Goetz F. (2008) Rapid accumulation of an interleukin 17 homolog transcript in Crassostrea gigas hemocytes following bacterial exposure Developmental and Comparative Immunology 32, 1099-1104. doi: 10.1016/j.dci.2008.02.006 </p> <p></p> <p>Lyons MM, Lau Y-T, Carden WE, Ward JE, Roberts SB, Smolowitz R, Vallino J, and Allam B. (2007*) Characteristics of marine aggregates in shallow-water ecosystems: Implications for disease ecology EcoHealth 4, 406\u2013420.</p> <p>Weiss E, Bennie M, Hodgins-Davis A, Roberts SB, and Gerlach G. (2007) Characterization of new SSR-EST markers in cod, Gadus morhua Molecular Ecology Notes 7: 866\u2013867. doi: 10.1111/j.1471-8286.2007.01731.x</p> <p>Hodgins-Davis A, Roberts SB, Cowan D, Atema J, Avolio C, Defaveri J, and Gerlach G. (2007*) Characterization of SSRs from the American lobster, Homarus americanus  Molecular Ecology Notes 7:330-332.</p> <p>Rodgers BD, Roalson EH, Weber GM, Roberts SB, Goetz FW. (2007) A Proposed Nomenclature Consensus for the Myostatin Gene Family AJP- Endocrinology and Metabolism 292(2):E371-2.</p> <p>Lyons MM, Smolowitz R, Dungan C, and Roberts SB. (2006*) Development of a real-time quantitative PCR assay for the hard clam pathogen, Quahog Parasite Unknown (QPX) Diseases of Aquatic Organisms 72(1):45-52.</p> <p>Biga PR, Roberts SB, Iliev DB, McCauley LA, Moon JS, Collodi P, and Goetz FW. (2005) The isolation, characterization, and expression of a novel GDF11 gene and a second myostatin form in zebrafish, Danio rerio. Comparative Biochemistry and Physiology Part B: Biochemistry and Molecular Biology 141: 218-230.</p> <p>Roberts SB, Romano C, and Gerlach G. (2005) Characterization of EST derived SSRs from the bay scallop, Argopectens irradians Molecular Ecology Notes 5: 567-568.</p> <p>Jentoft S, Topp N, Seeliger M, Malison JA, Barry TP, Held JA, Roberts SB, and Goetz FW. (2005) Lack of growth enhancement by exogenous growth hormone treatment in yellow perch in four separate experiments Aquaculture 250:471-479.</p> <p></p> <p>Hollis DM, Goetz FW, Roberts SB, and Boyd SK. (2004) Acute neurosteroid modulation and subunit isolation of the GABAa receptor in the bullfrog, Rana catesbeiana Journal of Molecular Endocrinology 32(3):921-34.</p> <p>Biga PR, Cain KD, Hardy RW, Schelling GT, Overturf K, Roberts SB, Goetz FW, Ott TL.  (2004) Growth hormone differentially regulates muscle myostatin1 and -2 and increases circulating cortisol in rainbow trout Oncorhynchus mykiss  General and Comparative Endocrinology Vol 138(1):32-41.</p> <p>Roberts SB, McCauley LAR, Devlin RH, Goetz FW.  (2004)  Transgenic salmon over-expressing growth hormone exhibit decreased myostatin transcript and protein expression Journal of Experimental Biology  207(Pt 21):3741-8.</p> <p>Kim H-W, Mykles DL, Goetz FW, Roberts SB.  (2004) Characterization of an invertebrate myostatin homologue from the bay scallop, Argopecten irradians BBA \u2013 Gene Structure and Expression 1679(2):174-9.</p> <p>Roberts SB, Barry T, Malison J, Goetz FW. (2004) Production of a recombinantly-derived growth hormone antibody and the characterization of growth hormone levels in yellow perch Aquaculture Vol.232/1-4: 591-602.</p> <p>Roberts SB, Goetz FW. (2003)  Expressed sequence tag analysis of genes expressed in the bay scallop, Argopecten irradians Biological Bulletin 205: 227-228.</p> <p>Roberts SB, Goetz FW. (2003) Myostatin protein and mRNA transcript levels in adult and developing brook trout Molecular and Cellular Endocrinology 210(1-2): 9-20.</p> <p>Roberts SB, Goetz FW. (2001) Differential skeletal muscle expression of myostatin across teleost species, and the isolation of multiple myostatin isoformsFEBS Letters Vol 49:3,212-216.</p> <p></p> <p>Roberts SB, Langenau DM, Goetz FW. (2000) Cloning and characterization of prostaglandin endoperoxide synthase-1 and -2 from the brook trout ovary Molecular and Cellular Endocrinology 160(1-2):89-97.</p> <p></p> <p>Moser ML, Roberts SB. (2000) Effects of nonindigenous ictalurids and recreational electrofishing on the ictalurid community of the Cape Fear River drainage, North Carolina in Catfish 2000: Proceedings of the International Ictalurid Symposium; ER Irwin, WA Hubert, CF Rabeni, HL Schramm, Jr., and T Coon, editors. Davenport, IA. June 23-25, 1998. pp 479-485.</p> <p>Roberts SB, Langenau DM, Goetz FW. (2000) Isolation through cloning of fish prostaglandin endoperoxide synthase (cyclooxygenase) in Proceedings of the 6th International Symposium on the Reproductive Physiology of Fish; B Norberg, OS Kjesbu, GL Taranger, E Andersson, and SO Stefansson, editors. Bergen, Norway. July 4-9, 1999. p 197.</p> <p>Langenau DM, Goetz FW, Roberts SB. (1999)  The upregulation of messenger ribonucleic acids during 17a, 20b-dihydroxy-4-pregnen-3-one-induced ovulation in the perch ovary Journal of Molecular Endocrinology 23(2):137-52.</p> <p>Roberts SB, Jackson LF, King WK, Taylor RG, Grier HJ, Sullivan CV. (1999) Annual reproductive cycle of the common snook: Endocrine correlates of maturation Transactions of the American Fisheries Society 128:426-445.</p> <p>"},{"location":"Publications/#book-chapters","title":"Book Chapters","text":"<p>Moreira Sanmart\u00edn R, Roberts SB, Figueras A. (2016) Molluscs. pages 223-245, in Genomics in Aquaculture. Editors: Simon A. MacKenzie and Sissel Jentoft. ISBN: 978-0-12-801418-9</p> <p>Gavery, M., &amp; Roberts, S. (2018). Genetics &amp; Epigenetics in Life History and Reproduction: Oysters. In M. K. Skinner (Ed.), Encyclopedia of Reproduction. vol. 6, pp. 736\u2013742. Academic Press: Elsevier. doi: 10.1016/B978-0-12-809633-8.20621-3 pdf</p> <p>"},{"location":"Publications/#preprints","title":"PrePrints","text":"<p>Shelly A Trigg, Kaitlyn R Mitchell, Rhonda Elliott Thompson, Benoit Eudeline, Brent Vadopalas, Emma B Timmins-Schiffman, Steven B Roberts (2020). Temporal proteomic profiling reveals insight into critical devleopmental processes and temperature-influenced physiological response differences in a bivalve mollusc. bioRxiv. https://doi.org/10.1101/2020.06.05.137059 </p> <p>Emma B. Timmins-Schiffman, Grace A. Crandall, Brent Vadopalas, Michael E. Riffle, Brook L. Nunn, Steven B. Roberts (2016) Integrating proteomics and selected reaction monitoring to develop a non-invasive assay for geoduck reproductive maturation. bioRxiv doi: https://doi.org/10.1101/094615 </p> <p>Heare JE, White SJ, Roberts SB. (2015) Differential response to stress in Ostrea lurida (Carpenter 1864) as measured by gene expression. PeerJ PrePrints 3:e1595v1 https://doi.org/10.7287/peerj.preprints.1595v1</p> <p>Gavery MR, Delrow J, Basom R, Roberts SB. (2015) Influence of 17\u03b1-ethinylestradiol on DNA Methylation in Oysters. GitHub / Zenodo https://github.com/sr320/paper-Oyster-EE2</p> <p>Heare JE, Blake B, Davis JP, Vadopalas B, Roberts SB. (2014) Evidence of Ostrea lurida (Carpenter 1894) population structure in Puget Sound, WA. PeerJ PrePrints 2:e704v1 http://dx.doi.org/10.7287/peerj.preprints.704v1 </p> <p>Claire E. Olson, Steven B. Roberts. Indication of family-specific DNA methylation patterns in developing oysters bioRxiv doi: http://dx.doi.org/10.1101/012831 </p> <p>Roberts et al. Sequence Data that never made it. https://www.authorea.com/users/3858/articles/3989/_show_article</p> <p>David C. Metzger, Paul McElhany, Shallin Busch, Carolyn S. Friedman, Steven B. Roberts (preprint) Underlying impact of ocean acidification on Manila clam (Ruditapes philippinarum) larvae revealed through RNA-Seq analysis. Status: Available for Comment peer reviews: BMC, MB</p> <p>David C. Metzger, Carolyn S. Friedman, Emma B. Timmins-Schiffman and Steven B. Roberts (preprint) Thermal tolerance and gene expression characterization in Manila clams  (Ruditapes philippinarum) exposed to elevated carbon dioxide. Status: Available for Comment peer reviews: AB</p> <p>Storer C, Goetz F, Roberts S. (preprint) Transcriptional variation in lake trout (Salvelinus namaycush) ecotypes raised under constant environmental conditions. Status: Available for Comment</p> <p>Steven Roberts, Roxanna Smolowitz, Richard Karney, Mackenzie Gavery et al. (preprint) Disease tolerance in the eastern oyster. Status: Available for Comment</p> <p>Roberts et al. (preprint) Hard clam gene expression analysis. Status: Available for Comment</p> <p>Archived</p> <p>Dimond JL and Roberts SB  (2015) Germline DNA methylation in reef corals: patterns and potential roles in response to environmental change UW ResearchWorks Archive uri:http://hdl.handle.net/1773/34298</p> <p>Mackenzie Gavery and Steven Roberts (preprint) A context specific role for DNA methylation in bivalves. Status: Archived download (Revised and later accepted at Briefings in Functional Genomics 10.1093/bfgp/elt054</p> <p>Emma Timmins-Schiffman, Carolyn Friedman, Steven Roberts, Sam White, Dave Metzger (preprint) Genomic resource development of shellfish of conservation concern. Status: on figshare (published - Molecular Ecology Resources)</p> <p>Timmins-Schiffman E,  O\u2019Donnell M, Friedman C, and Roberts S. (preprint) Elevated pCO2 causes developmental delay in early larval Pacific oysters, Crassostrea gigas Status: on figshare (published - Marine Biology)</p> <p>Lyons, Dungan, and Roberts \u2013 Thraustochytrid-like isolates from marine bivalve mollusks</p> Smolowitz, Schaff, DeFaveri, Roberts - Renal Trematodiasis of Largemouth Bass and Development of PCR Methods <p>White SJ and Roberts S. (preprint) Identification of myostatin interacting proteins using a yeast-two hybrid approach. Status: Available for Comment</p> <p>Gavery MR, White SJ, Roberts S (preprint)  Characterization of prostaglandin endoperoxide synthase from the Pacific oyster, Crassostrea gigas.  Status: Available for Comment</p> <p>Thompson R and Roberts SB (preprint) Influence of carbon dioxide-induced acidification and mechanical stress on gene expression and microbial community composition in oysters. Status: Available for Comment</p> <p>"},{"location":"Publications/#theses","title":"Theses","text":"<p>Patterns, dynamics, and potential roles of DNA methylation in reef corals and their allies. James Dimond. 2019 http://hdl.handle.net/1773/44815</p> <p>Response of Olympia oysters (Ostrea lurida) to changing environmental conditions.  Jake Heare. 2015 http://hdl.handle.net/1773/35206</p> <p>Genomic signatures of natural selection and population structure in West Coast and Alaskan sablefish (Anoplopoma fimbria).  Andrew Jasonowicz. 2014 http://hdl.handle.net/1773/33907</p> <p>DNA methylation variation in gametes and larvae of the Pacific oyster, Crassostrea gigas. Claire Ellis Olson. 2014 http://hdl.handle.net/1773/27478</p> <p>Epigenomic and transcriptomic regulation of environmental responses in the Pacific oyster, Crassostrea gigas. Mackenzie Gavery. 2014. http://hdl.handle.net/1773/25984</p> <p>The Effects of Ocean Acidification on Multiple Life History Stages of the Pacific Oyster, Crassostrea gigas: Implications for Physiological Trade-offs. Emma Timmins-Schiffman. 2014. http://hdl.handle.net/1773/25413</p> <p>Sablefish (Anoplopoma fimbria) sperm: The physiology of activation and the development of a cryopreservation protocol. Doug Immerman. 2014. http://hdl.handle.net/1773/25414</p> <p>Genetic and phenotypic diversity in sockeye salmon, Oncorhynchus nerka. Caroline Storer. 2012. figshare.  http://dx.doi.org/10.6084/m9.figshare.661720</p> <p>Characterizing the effects of ocean acidification in larval and juvenile Manila clam, Ruditapes philippinarum, using a transcriptomic approach. David Metzger. 2012  download</p>"},{"location":"Purchasing-and-Reimbursement/","title":"SAFS Purchasing","text":""},{"location":"Purchasing-and-Reimbursement/#general-purchasing","title":"General Purchasing","text":"<p>Here is the procedure for purchases. Generally, we are shifting to have SAFS admin staff handling purchasing as default (SAFS Purchasing Form).</p> <ol> <li> <p>Submit initial request in <code>#purchasing</code> channel on Slack.</p> <p>a.  Provide link(s) to desired product(s)</p> <ul> <li>University of Washington preferred vendors should always be given priority (i.e. don't default to buying from Amazon.com)</li> </ul> <p>b.  Purchasing approval will be confirmed by Steven and he will provide the appropriate budget number &amp; name to use</p> </li> <li> <p>Sumbit Purchase</p> <p>There are three basic means by which to submit a purchase. They are listed in order (top to bottom) of preferred usage:</p> <ul> <li> <p>treq</p> </li> <li> <p>eProcurement (Ariba)</p> <ul> <li>Requires pre-authorization from Steven and the department to use. Instructions, training, and tutorials are available from UW Procurement Services.</li> </ul> </li> <li> <p>ProCard</p> <ul> <li> <p>ProCard is a credit card issued to specific users via the University of Washington.</p> </li> <li> <p>Graduate students are not elligible for ProCard use.</p> </li> <li> <p>Sam is the only current lab member who has a ProCard.</p> </li> <li> <p>Obtaining a ProCard requires completing a University of Washington training course.</p> </li> <li> <p>ProCards cannot be used for travel or meal expenses.</p> </li> </ul> </li> </ul> </li> <li> <p>Fill out Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul> </li> <li> <p>Receiving Orders</p> <ol> <li> <p>Compare contents of box(es) and compare to packing slips.</p> </li> <li> <p>Sign and date all packing slips.</p> </li> <li> <p>If no packing slip is provided, email Lisa Smith indicating the vendor and date the items were received.</p> </li> <li> <p>Put packing slips in designated main office inbox (FSH 116).</p> </li> <li> <p>Indicate date order was received in Roberts Lab Purchasing Log</p> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE: If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#biochem-stores-purchasing","title":"Biochem Stores Purchasing","text":"<ol> <li> <p>Search the store catalog or just head down to Room J-014 in the Health Sciences Building basement and ask for your product. If you are off-campus, you must use a VPN such as Husky OnNet to connect to the UW network.</p> </li> <li> <p>Order your product. They will need to know your lab, your name, and the budget number. They will give you a sales receipt for your purchase, but you don't need to submit this anywhere.</p> </li> <li> <p>Update the Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE: If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#primer-purchasing","title":"Primer Purchasing","text":"<ol> <li> <p>Enter primer details in Primer Database (Google Sheet).</p> </li> <li> <p>Minimum info needed for each primer:</p> <ul> <li>Unique primer name.</li> <li>Primer sequence.</li> <li>Initials.</li> <li>Species.</li> </ul> </li> <li> <p>Pickup primers from Biochem Stores after 24hrs. A budget number will be needed upon pickup.</p> </li> <li> <p>Update the Roberts Lab Purchasing Log with receipt date and budget number.</p> </li> <li> <p>After reconstitution, store primers in a box in the -20<sup>o</sup>C in FTR 213. Update the Primer Stocks database (Google Sheet) with storage locations of each primer.</p> </li> <li> <p>All primer stocks should be reconstituted to a concentration of 100uM in 1X Tris-EDTA (TE).</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#chem-store-purchasing","title":"Chem Store Purchasing","text":"<ol> <li>Search the store catalog or just go down to 036 Bagley Hall and ask for your product. If you are off-campus, you must use a VPN such as Husky OnNet to connect to the UW network.</li> <li>They will need to know your lab, your name, and the budget number. They will give you a sales receipt for your purchase, but you don't need to submit this anywhere.</li> <li> <p>Update the Roberts Lab Purchasing Log</p> </li> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> <li> <p>Add lab storage location of item(s) to appropriate fields in Roberts Lab Purchasing Log and Roberts Lab Inventory Google Sheets.</p> </li> <li> <p>NOTE:If a chemical, the chemical also needs to be added to MyChem inventory.</p> </li> </ol>"},{"location":"Purchasing-and-Reimbursement/#personal-purchases-reimbursed-by-safs-budget","title":"Personal Purchases (reimbursed by SAFS Budget)","text":"<p>Use https://treq.environment.uw.edu</p> <p>Fill out Roberts Lab Purchasing Log</p> <ul> <li> <p>Spreadsheet is organized by date ordered.</p> </li> <li> <p>Each row represents an order submitted to a single vendor; list all items, quantities, and catalogue numbers in a single cell for a given order.</p> </li> </ul>"},{"location":"Purchasing-and-Reimbursement/#travel","title":"Travel","text":"<p>Note Steps 1 and 2 need to occur prior to travel</p> <p>Travel is handled via https://treq.environment.uw.edu</p> <p>Step 1) Need to identify and apply for any supplemental support. This includes at the School and College level. This also includes support offered by the conference itself. Many conferences have early-bird rates and discounted hotels. These should be considered. Note:  -   The College of the Environment travel fund is only for future travel so make sure you apply for this two quarters in advance if possible. -   FINS travel funds are prioritized for those involved in FINS or some other type of service related to SAFS (CoEnv SAC, SEAS, GSS, etc.).</p> <p>Step 2) For any travel you need to complete Travel Pre-Authorization as soon as you know you would like to travel. (It is optional to complete for local transit to research sites)</p> <p></p> <p>During the Pre-Authorization step you can request a per diem Advance. But if your projected per diem for the length of travel is not $300 or more, you are not eligible for per diem advance.</p> <p>Note that there are options to have UW directly pay for conference registration, if you can get an invoice from the conference When this is the case you would simply submit this invoice for payment with the \"Pay an Invoice\" option in Treq and not include in Travel Authorization / Reimbursement. Make sure you upload your invoice to the OneDrive folder associated with your request.</p> <p>Step 3) Secure transit and lodging following all rules and regulations set forth by UW. </p> <p>In order to have UW pay directly for your flight and lodging, you must follow these steps.  -   Once you have completed your travel pre-authorization, click on the \"+Task\" button on the main page of your travel request.  -   Leave \"Assign To\" blank and fill in \"Task Title\" with something like \"UW direct payment\".  -   Fill in the description with the parts of your travel request you would like to get UW to pay for directly. For example: \"Could I get UW to directly pay for airfare and lodging so I don't have to use personal card?\" -   Save the task</p> <p>Someone from UW will be assigned to the task and will reach out with further instructions to reserve your flight and/or reserve lodging. For flights, you will be contacted via email by Tangerine Travel Agency. You'll need to provide them with the exact flight itinerary you want so they can book your flight.</p> <p>Step 4) When travel is complete, submit required documentation via Treq</p> <p>If you need technical assistance you can email efast\\@uw.edu.</p>"},{"location":"Undergraduate-contract/","title":"Undergraduate Contract","text":"<p>I enjoy having the opportunity to provide motivated undergraduate students with a chance to gain hands-on lab experience and get a better understanding of an array of approaches that can be used to study aquatic organisms. I feel this is an important component of your education. Depending on your status (i.e. intern, work-study, course credit, capstone etc.) there will likely be specific details that will need to be discussed, however all personnel need to agree to, and understand the following.</p> <p>If there are any issues (e.g. allergies) or assistance you might need/want that will help you succeed during your time in the lab, please record them on this page.</p> <p>Signing this document acknowledges the following:</p> <p>1)  I have read through all components of Onboarding:</p> <p>2)  I have completed all required Lab Safety training and provided the required documents to Sam White.</p> <p>3)  Research supplies (and equipment) are purchased through my grants and are very expensive.</p> <p>4)  You need to commit to at least 4-10 hours per week.</p> <p>5)  Always, Always ask Steven or someone else if you have any questions or are unsure about something. You are here to learn and you should take the initiative to make the most of your time here.</p> <p>6)  You need to maintain an e-lab notebook / journal that is updated on a daily basis. The platform for this will be genefish.wordpress.com.</p> <p>7)  If you are expected (or tell someone you are) to be in lab, and for some reason cannot make it -let us know ASAP</p> <p>8)  Your schedule of when you will be in the lab needs to be maintained on the lab calendar.</p> <p>9)  Make an effort to attend all lab meetings.</p>   Loading...   <p>Name:<code>______________________________</code></p> <p>Signature:<code>___________________________</code></p> <p>Date:<code>___________________________</code></p> <p>email used for Google Calendar: <code>_______________________________</code></p>"},{"location":"bio-Annotation/","title":"Annotation","text":""},{"location":"bio-Annotation/#intro-blast","title":"Intro (Blast)","text":"<p>Blast is a key component of working with lesser studied taxa. Here are some resources to help with this.</p> <p>First off, you should be familar with the command line interface and bash</p> <ul> <li>Introducing the Shell</li> <li>Introduction to the Command Line for Genomics</li> <li>https://explainshell.com/</li> </ul>"},{"location":"bio-Annotation/#blast-notebooks","title":"Blast Notebooks","text":"<ul> <li> <p>https://github.com/RobertsLab/code/blob/master/09-blast.ipynb - An example of how one might take a multi sequence fasta file and using NCBI Blast, compare the sequences with the Swiss-Prot Database on their own computer.</p> </li> <li> <p>https://github.com/RobertsLab/code/blob/master/10-blast-2-slim.ipynb - A notebook to seamlessly take blast output to GO Slim list</p> </li> <li> <p>https://github.com/RobertsLab/code/blob/master/script-box/complete_go_annotation_notebook.Rmd -</p> </li> <li> <p>https://github.com/sr320/ceabigr/blob/main/code/17-Swiss-Prot-Annotation.Rmd -  Blasting C virginica to Swiss-Prot. Author: Steven Roberts </p> </li> </ul>"},{"location":"bio-Annotation/#gene-ontology-go","title":"Gene Ontology (GO)","text":""},{"location":"bio-Annotation/#retrieve-go-terms-from-uniprot-using-swissprot-ids","title":"Retrieve GO terms from UniProt Using SwissProt IDs","text":"<p>The following steps will use the UniProt Python API to create a tab-delimited file of data retrieved from UniProt.</p> <ol> <li> <p>Create newline-delimited file of SwissProt IDs. (e.g. <code>SPIDS.txt</code>)</p> <pre><code>cat SPIDS.txt\n\nQ86IC9\nP04177\nQ8L840\nQ61043\nA1E2V0\nP34456\nP34457\nO00463\nQ00945\nQ5SWK7\n</code></pre> </li> <li> <p>Create Python file (e.g. <code>uniprot-retrieval.py</code>) with the following:</p> <pre><code>import re\nimport zlib\nimport gzip\nimport requests\nfrom requests.adapters import HTTPAdapter, Retry\nimport sys\nimport shutil\n\nre_next_link = re.compile(r'&lt;(.+)&gt;; rel=\"next\"')\nretries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\nsession = requests.Session()\nsession.mount(\"https://\", HTTPAdapter(max_retries=retries))\n\n\ndef get_next_link(headers):\n    if \"Link\" in headers:\n        match = re_next_link.match(headers[\"Link\"])\n        if match:\n            return match.group(1)\n\n\ndef get_batch(batch_url):\n    while batch_url:\n        response = session.get(batch_url)\n        response.raise_for_status()\n        total = response.headers[\"x-total-results\"]\n        yield response, total\n        batch_url = get_next_link(response.headers)\n\n\ndef process_accessions(accessions):\n    accession_batches = [accessions[i:i+500] for i in range(0, len(accessions), 500)]\n    all_lines = []\n\n    for accession_batch in accession_batches:\n        accession_query = '%29%20OR%20%28accession%3A'.join(accession_batch)\n        url = f\"https://rest.uniprot.org/uniprotkb/search?compressed=true&amp;fields=accession%2Creviewed%2Cid%2Cprotein_name%2Cgene_names%2Corganism_name%2Clength%2Cgo_p%2Cgo_c%2Cgo%2Cgo_f%2Cgo_id&amp;format=tsv&amp;query=%28%28accession%3A{accession_query}%29%29&amp;size=500\"\n\n        progress = 0\n        lines = []\n        for batch, total in get_batch(url):\n            # Decompress each batch as we want to extract the header\n            decompressed = zlib.decompress(batch.content, 16 + zlib.MAX_WBITS)\n            batch_lines = [line for line in decompressed.decode(\"utf-8\").split(\"\\n\") if line]\n            if not progress:\n                # First line so print TSV header\n                lines = [batch_lines[0]]\n            lines += batch_lines[1:]\n            progress = len(lines) - 1\n            print(f\"{progress} / {total}\")\n\n        all_lines.extend(lines)\n\n    return all_lines\n\n\nif __name__ == '__main__':\n    if len(sys.argv) &lt; 2:\n        print(\"Usage: python uniprot-retrieval.py &lt;input_file&gt;\")\n        sys.exit(1)\n\n    accession_file = sys.argv[1]\n    with open(accession_file, 'r') as f:\n        accessions = f.read().splitlines()\n\n    retrieved_data = process_accessions(accessions)\n\n    # Write to a temporary gzip file\n    temp_filename = \"uniprot-retrieval-temp.tsv.gz\"\n    with gzip.open(temp_filename, \"wt\", encoding=\"utf-8\") as f:\n        f.write('\\n'.join(retrieved_data))\n\n    # Merge the temporary file with the existing output file (if it exists)\n    try:\n        with gzip.open(\"uniprot-retrieval.tsv.gz\", \"rb\") as f_existing, open(temp_filename, \"rb\") as f_temp:\n            with gzip.open(\"uniprot-retrieval-merged.tsv.gz\", \"wb\") as f_merged:\n                shutil.copyfileobj(f_existing, f_merged)\n                shutil.copyfileobj(f_temp, f_merged)\n\n        # Replace the original output file with the merged file\n        shutil.move(\"uniprot-retrieval-merged.tsv.gz\", \"uniprot-retrieval.tsv.gz\")\n    except FileNotFoundError:\n        # If the existing output file doesn't exist, rename the temporary file\n        shutil.move(temp_filename, \"uniprot-retrieval.tsv.gz\")\n</code></pre> </li> <li> <p>Run the Python script:</p> <p><pre><code>python3 uniprot-retrieval.py SPIDS.txt\n</code></pre> - IMPORTANT: Requires Python &gt;= 3!</p> <pre><code>- If using R Markdown, run the above in a `bash` chunk:\n</code></pre> </li> </ol> <p>The resulting output file (<code>uniprot-retrieval.tsv.gz</code>) will be in your working directory.</p> <ol> <li> <p>Gunzip the output file:</p> <pre><code>gunzip uniprot-retrieval.tsv.gz\n</code></pre> </li> </ol> <p>The resulting file (<code>uniprot-retrieval.tsv</code>) will be formatted with the following columns:</p> Entry Reviewed Entry Name Protein names Gene Names Organism Length Gene Ontology (biological process) Gene Ontology (cellular component) Gene Ontology (molecular function) Gene Ontology (GO) Gene Ontology IDs <p>NOTES:</p> <ul> <li> <p>This requires Python &gt;= 3 to run. Simplest way to access Python 3 is via a conda environment.</p> </li> <li> <p>On the first attempt, you'll likely need to install the packages that are being imported at the very beginning of the script.</p> </li> <li> <p>Create an issue if you need help with any of the above.</p> </li> </ul>"},{"location":"bio-Annotation/#genome-features","title":"Genome features","text":"<p>In addition to sequence database alignment, finding spatial relationship within a genome is also an import approach for annotation. Often this is done using software tools such as <code>bedtools</code>.</p>"},{"location":"bio-Annotation/#bedtoolsintersectbed","title":"<code>bedtools::intersectbed</code>","text":"<p>see also https://bedtools.readthedocs.io/en/latest/content/tools/intersect.html</p>"},{"location":"bio-Annotation/#transcriptome-trinity","title":"Transcriptome (Trinity)","text":"<p>After transcriptome assembly using Trinity, run the numbered steps below, in order.</p> <p>NOTE: The following info is long and requires the use of many programs. All of the code listed below are solely examples. Making the commands functional requires a fair amount of organization (i.e. listing paths to programs and input/output files, creating subdirectories for organizing outputs, etc.). See the Use Cases at the end of this section for a more complete picture of how to organize/run this pipeline.</p> <ol> <li> <p>Transdecoder</p> <ul> <li> <p>Identify longest open reading frames (ORFs).</p> </li> <li> <p>Use transcriptome assembly and gene-trans map from Trinity assembly.</p> <pre><code>TransDecoder.LongOrfs \\\n--gene_trans_map Trinity.fasta.gene_trans_map \\\n-t Trinity.fasta\"\n</code></pre> </li> </ul> </li> <li> <p>BLASTp</p> <ul> <li> <p>Run blastp on long ORFs from Step 1 above.</p> </li> <li> <p>Output format 6 produces a standard BLAST tab-delimited file.</p> </li> <li> <p>Settings are recommended in TransDecoder documentation.</p> </li> <li> <p>Peptide database (<code>-db uniprot_sprot.pep</code>) is supplied with Trinotate (e.g. <code>Trinotate-v3.1.1/admin/uniprot_sprot.pep</code>), but can be changed to use your own version.</p> <pre><code>blastp \\\n-query longest_orfs.pep \\\n-db uniprot_sprot.pep \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads ${threads} \\\n&gt; Trinity.fasta.blastp.outfmt6\n</code></pre> </li> </ul> </li> <li> <p>BLASTx (<code>DIAMOND</code>)</p> <ul> <li> <p>Run <code>DIAMOND</code> blastx on long ORFs from Step 1 above.</p> </li> <li> <p>Output format 6 produces a standard BLAST tab-delimited file.</p> </li> <li> <p>Settings (<code>--evalue</code> and <code>--max-target-seqs</code>) are recommended in TransDecoder documentation.</p> </li> <li> <p><code>--block-size</code> and <code>--index-chunks</code> are specific to running <code>DIAMOND</code> BLASTx.</p> </li> <li> <p><code>--db uniprot_sprot.dmnd</code> is a <code>DIAMOND</code>-formatted BLAST database. User can generate their own.</p> <pre><code>```\ndiamond blastx \\\n--db uniprot_sprot.dmnd \\\n--query Trinity.fasta \\\n--out Trinity.fasta.blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n```\n</code></pre> </li> </ul> </li> <li> <p>pFam</p> <ul> <li> <p>Run pfam search on long ORFs from Step 1 above.</p> </li> <li> <p>Protein hidden Markov model database (<code>Pfam-A.hmm</code>) is supplied with Trinotate (e.g. <code>Trinotate-v3.1.1/admin/Pfam-A.hmm</code>), but can be changed to use your own version.</p> <pre><code>hmmscan \\\n--cpu ${threads} \\\n--domtblout Trinity.fasta.pfam.domtblout \\\nPfam-A.hmm \\\nlongest_orfs.pep\n</code></pre> </li> </ul> </li> <li> <p>Transdecoder</p> <ul> <li>Run Transdecoder using transcriptome assembly FastA, <code>blastp</code> and <code>Pfam</code> results.</li> </ul> <pre><code>TransDecoder.Predict \\\n    -t Trinity.fasta \\\n    --retain_pfam_hits Trinity.fasta.pfam.domtblout \\\n    --retain_blastp_hits Trinity.fasta.blastp.outfmt6\n</code></pre> </li> <li> <p>Trinotate</p> <ul> <li> <p>Trinotate requires a large number of steps and programs!</p> <ul> <li> <p>Run <code>signalp</code></p> <pre><code>signalp \\\n-f short \\\n-n Trinity.fasta.trinotate.signalp.out \\\nlongest_orfs.pep\n</code></pre> </li> <li> <p>Run <code>tmHMM</code></p> <pre><code>tmhmm \\\n--short \\\n&lt; longest_orfs.pep \\\n&gt; Trinity.fasta.trinotate.tmhmm.out\n</code></pre> </li> <li> <p>Run <code>RNAmmer</code></p> <ul> <li>Uses a special Trinotate implementation of <code>rnammer</code> (e.g. <code>Trinotate/util/rnammer_support/RnammerTranscriptome.pl</code>)</li> </ul> <pre><code>RnammerTranscriptome.pl \\\n--transcriptome Trinity.fasta \\\n--path_to_rnammer rnammer\n</code></pre> </li> <li> <p>Load transcripts and coding regions into Trinotate SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\ninit \\\n--gene_trans_map Trinity.fasta.gene_trans_map \\\n--transcript_fasta Tinity.fasta \\\n--transdecoder_pep longest_orfs.pep\n</code></pre> </li> <li> <p>Load BLASTp/x homologies into SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_swissprot_blastp \\\nTrinity.fasta.blastp.outfmt6\n</code></pre> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_swissprot_blastx \\\nTrinity.fasta.blastx.outfmt6\n</code></pre> </li> <li> <p>Load Pfam into SQLite database</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_pfam \\\nTrinity.fasta.pfam.domtblout\n</code></pre> </li> <li> <p>Load transmembrane domains</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_tmhmm \\\nTrinity.fasta.trinotate.tmhmm.out\n</code></pre> </li> <li> <p>Load signal peptides</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_signalp \\\nTrinity.fasta.trinotate.signalp.out\n</code></pre> </li> <li> <p>Load RNAmmer</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nLOAD_rnammer \\\nTrinity.fasta.rnammer.gff\n</code></pre> </li> <li> <p>Create annotation report</p> <pre><code>Trinotate \\\nTrinotate.sqlite \\\nreport \\\n&gt; Trinity.fasta.annotation_report.txt\n</code></pre> </li> <li> <p>Extract gene ontology (GO) terms from annotation report</p> <pre><code>extract_GO_assignments_from_Trinotate_xls.pl \\\n--Trinotate_xls Trinity.fasta.annotation_report.txt \\\n-G \\\n--include_ancestral_terms \\\n&gt; Trinity.fasta.go_annotations.txt\n</code></pre> <ul> <li>The output file is formatted like this (<code>&lt;trinity-id&gt;``&lt;tab&gt;``&lt;GO:NNNNNN,GO:NNNNN,...&gt;</code>):</li> </ul> <pre><code>TRINITY_DN0_c0_g1   GO:0003674,GO:0003824,GO:0003964,GO:0006139,GO:0006259,GO:0006310,GO:0006313,GO:0006725,GO:0006807,GO:0008150,GO:0008152,GO:0009987,GO:0016740,GO:0016772,GO:0016779,GO:0032196,GO:0034061,GO:0034641,GO:0043170,GO:0044237,GO:0044238,GO:0044260,GO:0044699,GO:0044710,GO:0044763,GO:0046483,GO:0071704,GO:0090304,GO:1901360\nTRINITY_DN0_c10_g1  GO:0003674,GO:0003824,GO:0004659,GO:0004660,GO:0005488,GO:0005575,GO:0005829,GO:0005875,GO:0005965,GO:0006464,GO:0006807,GO:0008150,GO:0008152,GO:0008270,GO:0008318,GO:0009987,GO:0016740,GO:0016765,GO:0018342,GO:0018343,GO:0019538,GO:0032991,GO:0036211,GO:0043167,GO:0043169,GO:0043170,GO:0043234,GO:0043412,GO:0044237,GO:0044238,GO:0044260,GO:0044267,GO:0044422,GO:0044424,GO:0044430,GO:0044444,GO:0044446,GO:0044464,GO:0046872,GO:0046914,GO:0071704,GO:0097354,GO:1901564,GO:1902494,GO:1990234\nTRINITY_DN0_c2_g4   GO:0000166,GO:0003674,GO:0005488,GO:0005524,GO:0005575,GO:0005737,GO:0005856,GO:0017076,GO:0030554,GO:0032553,GO:0032555,GO:0032559,GO:0035639,GO:0036094,GO:0043167,GO:0043168,GO:0043226,GO:0043228,GO:0043229,GO:0043232,GO:0044424,GO:0044464,GO:0097159,GO:0097367,GO:1901265,GO:1901363\n</code></pre> </li> </ul> </li> <li> <p>Make transcript features annotation map</p> <pre><code>```\nTrinotate_get_feature_name_encoding_attributes.pl \\\nTrinity.fasta.annotation_report.txt \\\n&gt; Trinity.fasta.annotation_feature_map.txt\n```\n</code></pre> </li> </ul> </li> </ol>"},{"location":"bio-Gene-expression/","title":"Gene Expression","text":"<p>This primarily refers to dealing with transcriptome wide analysis (eg RNA-seq, tag-seq). Please see also Roberts and Gavery (2018) Opportunities in Functional Genomics: A Primer on Lab and Computational Aspects There are several workflows out there, but here we outline common workflows in our lab.</p>"},{"location":"bio-Gene-expression/#qc","title":"QC","text":"<p>A normal starting point would be having raw sequence data provided by a core facility. When downloading said data you need to make sure you check the integrity by making sure the hash at the source is the same once you get it to where you want to analyse it. </p> <p>To begin with, you should run fastqc to assess quality. This might vary based on the details of your project but generally you can ID outliers and those samples with poor read quality. Presence of adapters can also be visualized.</p>"},{"location":"bio-Gene-expression/#trimming","title":"trimming","text":"<p>It is debatable how necessary how necessary trimming reads is, though if done correctly there is likely no reason it is detrimental.</p>"},{"location":"bio-Gene-expression/#reference-choice","title":"reference choice","text":"<p>The next step is to take the sequence reads, align, and compare counts. Alignent be done using either a transcriptome or genome. Distinct software that is genome-aware will be needed for the latter. </p>"},{"location":"bio-Gene-expression/#alignment-kallisto-pseudo-alignment","title":"alignment: kallisto (pseudo-alignment)","text":"<p>See the official documentation.</p> <p>User Guides</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<ul> <li>https://github.com/RobertsLab/paper-tanner-crab/blob/master/notebooks/kallisto-4libraries.ipynb tanner crab </li> </ul>"},{"location":"bio-Gene-expression/#alignment-hisat2","title":"Alignment: HiSat2","text":"<p>See the official documentation (linked above).</p> <p>Benefits to using <code>HISAT2</code> for alignments:</p> <ul> <li> <p>Fast.</p> </li> <li> <p>Can detect exon/intron junctions (i.e. alternative isoform splice sites).</p> </li> </ul> <p>For RNA-Seq, <code>HISAT2</code> alignments are frequently followed up using <code>StringTie</code> for transcript assembly and quantitation of splice variants.</p> <p>General usage:</p> <ol> <li> <p>Build a <code>HISAT2</code> reference sequence index:</p> <pre><code># Create Hisat2 exons tab file\n\"${programs_array[hisat2_exons]}\" \\\n\"${transcripts_gtf}\" \\\n&gt; \"${exons}\"\n\n# Create Hisat2 splice sites tab file\n\"${programs_array[hisat2_splice_sites]}\" \\\n\"${transcripts_gtf}\" \\\n&gt; \"${splice_sites}\"\n\n# Build Hisat2 reference index using splice sites and exons\n\"${programs_array[hisat2_build]}\" \\\n\"${genome_fasta}\" \\\n\"${genome_index_name}\" \\\n--exon \"${exons}\" \\\n--ss \"${splice_sites}\" \\\n-p \"${threads}\" \\\n2&gt; hisat2-build_stats.txt\n</code></pre> </li> <li> <p>Perform alignment(s):</p> <pre><code># Hisat2 alignments\n\"${programs_array[hisat2]}\" \\\n-x \"${genome_index_name}\" \\\n-1 \"${fastq_list_R1}\" \\\n-2 \"${fastq_list_R2}\" \\\n-S \"${sample_name}\".sam \\\n--threads \"${threads}\" \\\n2&gt; \"${sample_name}\"-hisat2_stats.txt\n\n# Sort SAM files, convert to BAM, and index\n${programs_array[samtools_view]} \\\n-@ \"${threads}\" \\\n-Su \"${sample_name}\".sam \\\n| ${programs_array[samtools_sort]} - \\\n-@ \"${threads}\" \\\n-o \"${sample_name}\".sorted.bam\n${programs_array[samtools_index]} \"${sample_name}\".sorted.bam\n\n\n# Delete unneccessary index files\nrm \"${genome_index_name}\"*.ht2\n\n# Delete unneeded SAM files\nrm ./*.sam\n</code></pre> </li> </ol> <p>See links in the \"use cases\" section below for full-fledged scripts and advanced usage (e.g. assigning read groups to alignment files (SAM) for improved downstream handling/accessiblity).</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li> <p>RNAseq Alignments - P.generosa Alignments and Alternative Transcript Identification Using Hisat2 and StringTie on Mox</p> </li> <li> <p>Splice Site Identification - S.namaycush Liver Parasitized and Non-Parasitized SRA RNAseq Using Hisat2-Stingtie with Genome GCF_016432855.1</p> </li> </ul>"},{"location":"bio-Gene-expression/#deseq2","title":"DESeq2","text":"<p>See also the official documentation.</p> <p>User Guides - Analyzing RNA-seq data with DESeq2</p>"},{"location":"bio-Gene-expression/#use-cases-from-our-lab_2","title":"Use cases from our lab","text":"<ul> <li> <p>https://github.com/laurahspencer/O.lurida_QuantSeq-2020/blob/master/notebooks/02-Adult-data-analysis-QuantSeq2020.Rmd - draft code analyzing QuantSeq data from Olympia oyster gill tissue by two factors (population, pCO2 treatment). See 2020-QuantSeq-Processing_Raw-to-Counts.ipynb and 01-Importing-data-QuantSeq2020.Rmd for steps prior to DeSeq2. Author: Laura Spencer  </p> </li> <li> <p>https://github.com/RobertsLab/paper-tanner-crab/blob/master/scripts/DESeq.Rmd </p> </li> </ul>"},{"location":"bio_Basics/","title":"Basics","text":"<p>A suite of core fundamental Bioinformatic workflows.</p>"},{"location":"bio_Basics/#shell","title":"Shell","text":"<ul> <li>Introducing the Shell</li> <li>Introduction to the Command Line for Genomics</li> </ul>"},{"location":"bio_Basics/#sequence-alignment-blast","title":"Sequence Alignment - BLAST","text":"<p>Tutorial from FISH546 - starting from a fasta and downloading blast.</p>"},{"location":"bio_Basics/#fastqc","title":"FastQC","text":"<p>Tutorial from FISH546 - running FastQC from Jupyter.</p>"},{"location":"bio_DNA-methylation/","title":"DNA Methylation Analysis","text":""},{"location":"bio_DNA-methylation/#bismark","title":"Bismark","text":"<p>See also the official documentation.</p> <p>User Guides</p> <p>1)  http://felixkrueger.github.io/Bismark/Docs/\\ 2)  https://www.bioinformatics.babraham.ac.uk/projects/bismark/</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<p>https://github.com/RobertsLab/code/blob/master/20-bismark.sh</p> <ul> <li> <p>https://github.com/sr320/paper-oly-mbdbs-gen/blob/master/code/00-Bismark.sh - used to processes BS-MBDSeq Data from Olympia oysters, run on Mox. Author: Steven Roberts </p> </li> <li> <p>https://raw.githubusercontent.com/laurahspencer/C.magister_methyl-oa/master/scripts/20201214_Cmag_bismark-align.sh - slurm script used to process MiSeq data from Dungeness crab, run on Mox. Here is a Jupyter Notebook with more details/narrative. Author: Laura Spencer, but derived from the MethCompare workflow. </p> </li> <li> <p>https://github.com/sr320/paper-oly-wgbs/blob/master/submission/Narrative.Rmd part of Rmd narrative, used for WGBS Olympia oyster data. Author: Steven Roberts </p> </li> <li> <p>https://github.com/hputnam/Geoduck_Meth/blob/master/code/03-bismark.sh geoduck environmental memory project. Run on Mox. Author: Steven Roberts </p> </li> <li> <p>https://raw.githubusercontent.com/epigeneticstoocean/paper-gonad-meth/master/code/02-bismark.sh eastern oyster data, run on Mox </p> </li> <li> <p>https://github.com/hputnam/Meth_Compare/blob/master/code/00.01-DNA-sequence-processing.md Complete DNA processing protocol from comparison of BS methods on corals. </p> </li> </ul>"},{"location":"bio_DNA-methylation/#diagram","title":"Diagram","text":""},{"location":"bio_DNA-methylation/#code-output-expectations","title":"Code Output Expectations","text":"<p>(Always default to the Manual/User Guide! - this is merely an attempt at explaining our workflow)</p>"},{"location":"bio_DNA-methylation/#bismark_1","title":"Bismark","text":"<p>Bismark User Guide</p> <p>(I) Running bismark_genome_preparation</p> <p>USAGE: bismark_genome_preparation [options]  <pre><code>${bismark_dir}/bismark_genome_preparation \\\n--verbose \\\n--parallel 28 \\\n--path_to_aligner ${bowtie2_dir} \\\n${genome_folder}\n</code></pre> <p>You should expect to prepared genome with directory structure similar to</p> <pre><code>./roslin_M/Bisulfite_Genome\n./roslin_M/Bisulfite_Genome/GA_conversion\n./roslin_M/Bisulfite_Genome/CT_conversion\n</code></pre> <p>(II) Running bismark</p> <p>USAGE: bismark [options] --genome  {-1  -2  | } <pre><code>find ${reads_dir}*_R1_001_val_1.fq.gz \\\n| xargs basename -s _R1_001_val_1.fq.gz | xargs -I{} ${bismark_dir}/bismark \\\n--path_to_bowtie ${bowtie2_dir} \\\n-genome ${genome_folder} \\\n-p 4 \\\n-score_min L,0,-0.6 \\\n--non_directional \\\n-1 ${reads_dir}{}_R1_001_val_1.fq.gz \\\n-2 ${reads_dir}{}_R2_001_val_2.fq.gz \\\n-o Mcap_tg\n</code></pre> <p>This will create bam files (sequence alignment files)</p> <p>(III) Running deduplicate_bismark</p> <p>deduplicate_bismark --bam [options]  <p>This command will deduplicate the Bismark alignment BAM file and remove all reads but one which align to the the very same position and in the same orientation. This step is recommended for whole-genome bisulfite samples, but should not be used for reduced representation libraries such as RRBS, amplicon or target enrichment libraries.</p> <pre><code>find *.bam | \\\nxargs basename -s .bam | \\\nxargs -I{} ${bismark_dir}/deduplicate_bismark \\\n--bam \\\n--paired \\\n{}.bam\n</code></pre> <p>This will create a deduplicated bam file.</p> <p>(IV) Running bismark_methylation_extractor</p> <p>USAGE: bismark_methylation_extractor [options]  <pre><code>${bismark_dir}/bismark_methylation_extractor \\\n--bedGraph --counts --scaffolds \\\n--multicore 14 \\\n--buffer_size 75% \\\n*deduplicated.bam\n</code></pre> <pre><code># ${bismark_dir}/bismark_methylation_extractor \\\n# --bedGraph \\\n# --counts \\\n# --comprehensive \\\n# --merge_non_CpG \\\n# --multicore 28 \\\n# --buffer_size 75% \\\n# *deduplicated.bam\n</code></pre> <p>This will create deduplicated.bismark.cov.gz, uncompressed is in this format. Not we are using <code>--bedGraph</code> output, this is not default.</p> <p>Alternatively, the output of the methylation extractor can be transformed into a bedGraph and coverage file using the option --bedGraph (see also --counts)... Optionally, the bedGraph counts output can be used to generate a genome-wide cytosine report which reports the number on every single CpG (optionally every single cytosine) in the genome, irrespective of whether it was covered by any reads or not. As this type of report is informative for cytosines on both strands the output may be fairly large.</p> <pre><code>NC_035784.1 141 141 37.5    3   5\nNC_035784.1 142 142 100 2   0\nNC_035784.1 155 155 70  7   3\nNC_035784.1 156 156 100 2   0\nNC_035784.1 291 291 0   0   2\nNC_035784.1 292 292 0   0   3\nNC_035784.1 313 313 0   0   1\nNC_035784.1 314 314 66.6666666666667    2   1\nNC_035784.1 470 470 66.6666666666667    4   2\nNC_035784.1 611 611 0   0   4\n</code></pre> <p><code>&lt;chromosome&gt; &lt;start position&gt; &lt;end position&gt; &lt;methylation percentage&gt; &lt;count methylated&gt; &lt;count unmethylated&gt;</code></p> <p>genome-wide cytosine report output</p> <p>Starting from the coverage output, the Bismark methylation extractor can optionally also output a genome-wide cytosine methylation report. The module coverage2cytosine (part of the Bismark package) may also be run individually. It is also sorted by chromosomal coordinates but also contains the sequence context and is in the following format:  <p>The main difference to the bedGraph or coverage output is that every cytosine on both the top and bottom strands will be considered irrespective of whether they were actually covered by any reads in the experiment or not. For this to work one has to also specify the genome that was used for the Bismark alignments using the option --genome_folder . As for the bedGraph mode, this will only consider cytosines in CpG context by default but can be extended to cytosines in any sequence context by using the option --CX (cf. Appendix (III)). Be aware though that this might mean an output with individual lines for more than 1.1 billion cytosines for any large mammalian genome... <pre><code>find *deduplicated.bismark.cov.gz \\\n| xargs basename -s _trimmed_bismark_bt2.deduplicated.bismark.cov.gz \\\n| xargs -I{} ${bismark_dir}/coverage2cytosine \\\n--genome_folder ${genome_folder} \\\n-o {} \\\n--merge_CpG \\\n--zero_based \\\n{}_trimmed_bismark_bt2.deduplicated.bismark.cov.gz\n</code></pre> <p>generates a file <code>.CpG_report.merged_CpG_evidence.cov</code></p> <pre><code>NC_035785.1 217 219 100.000000  17  0\nNC_035785.1 523 525 87.500000   7   1\nNC_035785.1 556 558 50.000000   5   5\nNC_035785.1 727 729 100.000000  16  0\nNC_035785.1 1330    1332    0.000000    0   2\nNC_035785.1 1403    1405    0.000000    0   2\nNC_035785.1 1494    1496    66.666667   2   1\nNC_035785.1 1747    1749    100.000000  8   0\nNC_035785.1 2024    2026    100.000000  24  0\nNC_035785.1 2054    2056    93.333333   14  1\n</code></pre> <p>(V) Running bismark2report</p> <p>USAGE: bismark2report [options]</p> <pre><code>${bismark_dir}/bismark2report\n</code></pre> <p>(VI) Running bismark2summary</p> <p>USAGE: bismark2summary [options]</p> <p>Produces report like this</p> <pre><code>${bismark_dir}/bismark2summary\n</code></pre> <p>Produces report like this</p>"},{"location":"bio_DNA-methylation/#bs-snpr","title":"BS-Snpr","text":"<p>See https://github.com/hellbelly/BS-Snper</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li>https://nbviewer.org/github/RobertsLab/project-gigas-oa-meth/blob/master/code/07-BS-SNPer.ipynb - Pacific oyster exposed to OA. Author: Yaamini Venkataraman </li> </ul>"},{"location":"bio_DNA-methylation/#epidiversesnp-nextflow-pipeline","title":"<code>EpiDiverse/snp</code> (Nextflow pipeline)","text":"<p>See https://github.com/EpiDiverse/snp</p>"},{"location":"bio_DNA-methylation/#instructions-for-running-on-mox","title":"Instructions for running on Mox","text":"<p>Add the following below your SBATCH script header. Replace <code>bams_dir</code> and <code>genome_fasta</code> locations with your own.</p> <p>NOTE: A FastA index file needs to be present in the same directory as your genome FastA file.</p> <pre><code># These variables need to be set by user\n\n## Directory with BAM(s)\nbams_dir=\"/gscratch/scrubbed/samwhite/data/C_virginica/BSseq/120321-cvBS\"\n\n## Location of EpiDiverse/snp pipeline directory\nepi_snp=\"/gscratch/srlab/programs/epidiverse-pipelines/snp\"\n\n## FastA file is required to end with .fa\n## Requires FastA index file to be present in same directory as FastA\ngenome_fasta=\"/gscratch/srlab/sam/data/C_virginica/genomes/GCF_002022765.2_C_virginica-3.0_genomic.fa\"\n\n## Location of Nextflow\nnextflow=\"/gscratch/srlab/programs/nextflow-21.10.6-all\"\n\n## Specify desired/needed version of Nextflow\nnextflow_version=\"20.07.1\"\n\n\n###################################################################################\n\n\n# Exit script if a command fails\nset -e\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n# Activate NF-core conda environment\nconda activate epidiverse-snp_env\n\n# Count BAMs\n# Needed to pass info to Epidiverse/spn\n# to avoid artificial file count limitation.\nbam_count=0\n\nfor bam in ${bams_dir}*.bam\ndo\n  # Increments counter by 1 for each BAM\n  ((bam_count++))\ndone\n\n## Run EpiDiverse/snp\nNXF_VER=${nextflow_version} \\\n${nextflow} run \\\n${epi_snp} \\\n--input ${bams_dir} \\\n--reference ${genome_fasta} \\\n--variants \\\n--clusters \\\n--take ${bam_count}\n</code></pre>"},{"location":"bio_DNA-methylation/#epidiversewgbs-nextflow-pipeline","title":"<code>EpiDiverse/wgbs</code> (Nextflow pipeline)","text":"<p>See https://github.com/EpiDiverse/wgbs.</p>"},{"location":"bio_DNA-methylation/#instructions-for-running-on-raven","title":"Instructions for running on Raven","text":""},{"location":"bio_DNA-methylation/#instructions-for-running-on-mox_1","title":"Instructions for running on Mox","text":"<p>NOTE: All code below should be added to your SLURM script.</p> <ol> <li>Add the following lines to the beginning (below the header) of your SLURM script:</li> </ol> <pre><code># Load Anaconda\n# Unknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the EpiDiverse/wbgs Anaconda environment\nconda activate epidiverse-wgbs_env\n</code></pre> <ol> <li> <p>Run the Nextflow pipeline. Read the comments in code below for important usage notes.</p> <p>NOTE: Replace items enclosed in <code>&lt;&gt;</code> (including the <code>&lt;&gt;</code> with your own path(s))</p> </li> </ol> <pre><code># Run Nextflow EpiDiverse/wgbs pipeline\n# Expects paired end, gzipped FastQ files named *.fastq.gz. Add --SE parameter to use single end instead.\n# Genome FastA must have a corresponding FastA index file.\n# Can perform trimming if desired. Add --trim parameter.\n# Can run FastQC after trimming. Add --fastqc parameter.\nNXF_VER=20.07.1 \\\n/gscratch/srlab/programs/nextflow \\\n/gscratch/srlab/programs/epidiverse-pipelines/wgbs \\\n--input &lt;path to directory with *.fastq.gz files&gt; \\\n--reference &lt;path to genome FastA&gt; \\\n--INDEX\n</code></pre>"},{"location":"bio_DNA-methylation/#methylkit","title":"Methylkit","text":"<p>See also the official documentation - MethylKit Vignette</p>"},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_2","title":"Use cases from our lab","text":"<ul> <li> <p>https://github.com/sr320/paper-oly-mbdbs-gen/blob/master/code/01-methylkit.Rmd - used to processes BS-MBDSeq Data from Olympia oysters, run on personal computer (not Mox). Author: Laura Spencer </p> </li> <li> <p>https://github.com/hputnam/Meth_Compare/blob/master/code/MethCompare_methylKit_analysis.R coral methylation comparison of methods. </p> </li> <li> <p>https://github.com/epigeneticstoocean/paper-gonad-meth/blob/master/code/04-methylkit.Rmd eastern oyster OA work </p> </li> </ul>"},{"location":"bio_DNA-methylation/#diagram_1","title":"Diagram","text":"<p> Flowchart of possible operations by methylKit. A summary of the most importantmethylKit features is shown in a flow chart. It depicts the main features of methylKitand the sequential relationship between them. The functions that could be used for thosefeatures are also printed in the boxes. - Figure and caption from Akalin et al. 2012</p>"},{"location":"bio_DNA-methylation/#characterizing-gene-level-methylation","title":"Characterizing Gene Level Methylation","text":""},{"location":"bio_DNA-methylation/#use-cases-from-our-lab_3","title":"Use cases from our lab","text":"<p>https://sr320.github.io/gene-meth/</p>"},{"location":"bio_Transcriptome-assembly/","title":"Transcriptome Assembly","text":"<p>Introductory guide to transcriptome assembly using <code>Trinity</code> and short-read sequencing data.</p>"},{"location":"bio_Transcriptome-assembly/#qc","title":"QC","text":"<p>A normal starting point would be having raw sequence data provided by a core facility. When downloading said data you need to make sure you check the integrity of the files after transfer by confirming checksum hashes (usually <code>MD5</code> checksums) match those provided by the sequencing facility. </p> <p>You should run <code>FastQC</code> to assess sequencing quality. This might vary based on the details of your project but generally you can ID outliers and those samples with poor read quality. Presence of adapters can also be visualized.</p>"},{"location":"bio_Transcriptome-assembly/#trimming","title":"Trimming","text":"<p>Quality and adapter trimming is required prior to assembly. <code>fastp</code> is recommended due to its speed and FastQC-like report(s). Additionally, the output from <code>fastp</code> can also be analyzed by <code>MultiQC</code> (requires a \"plug-in\"). Trimmed files should be passed through <code>FastQC</code> and assessed. Although rare, some projects may require a second round of trimming.</p> <p>Alternatively, <code>Trinity</code> has trimming capabilities built in, using Trimmomatic. Although convenient, it limits the ability to assess post-trimming sequencing data prior to assembly.</p>"},{"location":"bio_Transcriptome-assembly/#assembly","title":"Assembly","text":"<p><code>Trinity</code> is the de facto standard. It is well-documented, well-supported, and actively updated. Additionally, the developer is very responsive, considerate, and helpful to all GitHub Issues.</p> <p><code>Trinity</code> is powerful and has complex, but useful options availalbe. Take time to consider how you will use your assembly for later analysis. <code>Trinity</code> has many options available for downstream analysis (e.g. gene expression) that can be simplified with careful planning prior to assembly.</p> <p>Due to the intensive processing required for assembly (high CPU and RAM usage), it is highly recommended to run all assemblies on an execute node on Mox. As such, all code examples are written with the assumption that the commands are being run on Mox.</p>"},{"location":"bio_Transcriptome-assembly/#sample-list-file","title":"Sample list file","text":"<p>It is recommended to create a sample list file for <code>Trinity</code> to use. One of the biggest benefits is that this sample file list can be used for other downstream operations in the <code>Trinity</code> pipeline. Additionally, it's an easy way to document which sequencing files were used for assembly. Here's the example from <code>Trinity</code>. Sample file list is tab-delimited like this:</p> <pre><code>cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq\ncond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq\ncond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq\ncond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq\n</code></pre>"},{"location":"bio_Transcriptome-assembly/#stranded-sequencing-reads","title":"Stranded sequencing reads","text":"<p><code>Trinity</code> has the option (<code>--SS_lib_type</code>) to specify whether or not the sequences you're assembly are \"stranded\". This is dependent upon the library construction. With that said, most paired-end RNA-seq project libraries are constructed using Illumina's stranded kit. As such, the user should specify this in the following fashion as on option in the <code>Trinity</code> command (example specifies typical stranded libraries): <code>--SS_lib_type RF</code></p> <p>If you do not know whether your libraries are stranded or not (for example, if you downloaded RNA-seq data from NCBI and the metadata doesn't indicate library construction methodology), <code>Trinity</code> has a built-in tool to help assess your sequencing reads, after assembly:</p> <p>Examine-Strand-Specificity</p>"},{"location":"bio_Transcriptome-assembly/#de-novo-assembly","title":"De novo assembly","text":"<p>A de novo assembly is an assembly that is done without the use of a reference genome. Here's an example command, using trimmed paired-end reads. This set of commands will assembly the reads into contigs, generate assembly statistics, a gene map file (maps isoforms to \"gene\" names), and a sequence length file (useful for downstream gene expression).</p> <pre><code># Perform assembly\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--SS_lib_type RF \\\n--max_memory 100G \\\n--CPU ${threads} \\\n--samples_file ${samples}\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".seq_lens\n</code></pre> <ul> <li><code>--max_memory 100G</code> should not be changed, per communications with the developer.</li> </ul>"},{"location":"bio_Transcriptome-assembly/#use-cases-from-our-lab","title":"Use cases from our lab","text":"<ul> <li>Transcriptome-Assembly-C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox</li> </ul>"},{"location":"bio_Transcriptome-assembly/#genome-guided-assembly","title":"Genome-guided assembly","text":"<p>A genome-guided assembly is an assembly which utilizes a reference genome. This requires a sorted BAM as input, which means you have to have previously aligned your RNA-seq reads to a reference genome. See our Handbook entry on using Hisat2 for read alignment. Here's an example command, using trimmed paired-end reads. This set of commands will assembly the reads into contigs, generate assembly statistics, a gene map file (maps isoforms to \"gene\" names), and a sequence length file (useful for downstream gene expression).</p> <pre><code># Perform assembly\n${programs_array[trinity]} \\\n--genome_guided_bam ${sorted_bam} \\\n--genome_guided_max_intron ${max_intron} \\\n--seqType fq \\\n--SS_lib_type RF \\\n--max_memory 100GB \\\n--CPU ${threads} \\\n--samples_file ${samples}\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n&gt; \"${fasta_name}\".seq_lens\n</code></pre> <ul> <li> <p><code>--genome_guided_max_intron ${max_intron}</code>: The value used in the <code>Trinity</code> examples is 10000.</p> </li> <li> <p><code>--max_memory 100G</code> should not be changed, per communications with the developer.</p> </li> </ul>"},{"location":"bio_Transcriptome-assembly/#use-cases-from-our-lab_1","title":"Use cases from our lab","text":"<ul> <li>Transcriptome-Assembly-Genome-guided-C.virginica-Adult-Gonad-OA-RNAseq-Using-Trinity-on-Mox</li> </ul>"},{"location":"bio_Transcriptome-assembly/#output-files","title":"Output files","text":"<p>Both types of assemblies listed above will generate your assembly as a FastA file:</p> <ul> <li><code>Trinity.fasta</code>: This is the default name.</li> </ul> <p>If you ran the commands above you will also get the following files:</p> <ul> <li> <p><code>assembly_stats.txt</code>: Statistics on your assembly. Will look something like this:</p> <pre><code>################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  887315\nTotal trinity transcripts:  1849486\nPercent GC: 36.26\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\nContig N10: 7967\nContig N20: 5284\nContig N30: 3814\nContig N40: 2801\nContig N50: 2062\n\nMedian contig length: 562\nAverage contig: 1117.46\nTotal assembled bases: 2066718534\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\nContig N10: 6904\nContig N20: 4398\nContig N30: 3003\nContig N40: 2120\nContig N50: 1501\n\nMedian contig length: 434\nAverage contig: 860.79\nTotal assembled bases: 763788564\n</code></pre> </li> <li> <p><code>Trinity.fasta.gene_trans_map</code>:</p> <pre><code>TRINITY_GG_1_c20044_g1  TRINITY_GG_1_c20044_g1_i2\nTRINITY_GG_1_c20044_g1  TRINITY_GG_1_c20044_g1_i4\nTRINITY_GG_1_c27757_g4  TRINITY_GG_1_c27757_g4_i1\nTRINITY_GG_1_c4646_g1   TRINITY_GG_1_c4646_g1_i1\nTRINITY_GG_1_c31636_g3  TRINITY_GG_1_c31636_g3_i1\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i2\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i7\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i5\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i6\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i4\nTRINITY_GG_1_c5375_g1   TRINITY_GG_1_c5375_g1_i1\n</code></pre> </li> <li> <p><code>Trinity.fasta.seq_lens</code>:</p> <pre><code>#fasta_entry    length\nTRINITY_GG_1_c20044_g1_i2   1058\nTRINITY_GG_1_c20044_g1_i4   1057\nTRINITY_GG_1_c27757_g4_i1   265\nTRINITY_GG_1_c4646_g1_i1    347\nTRINITY_GG_1_c31636_g3_i1   215\nTRINITY_GG_1_c5375_g1_i2    324\nTRINITY_GG_1_c5375_g1_i7    511\nTRINITY_GG_1_c5375_g1_i5    349\nTRINITY_GG_1_c5375_g1_i6    340\n</code></pre> </li> </ul>"},{"location":"bio_Transcriptome-assembly/#gene-expression","title":"Gene expression","text":""},{"location":"bio_Transcriptome-assembly/#annotation","title":"Annotation","text":""},{"location":"code_Snippets/","title":"Code Snippets","text":"<p>A few useful code chunks.</p>"},{"location":"code_Snippets/#shell-basics","title":"Shell Basics","text":"<p>Most commands are for bash (shell) scripts.</p> <p>Also, assumes usage of bash &gt;=4.0.</p>"},{"location":"code_Snippets/#r-markdown","title":"R Markdown","text":""},{"location":"code_Snippets/#use-bash-variables-across-chunks","title":"Use Bash variables across chunks","text":"<p>Variables are saved to a \u201cdot file\u201d and that file needs to be sourced in each Bash chunk to have access to the Bash variables across Bash chunks.</p> <p>The Bash variables set in the example below are:</p> <ul> <li> <p><code>${threads}</code></p> </li> <li> <p><code>${my_fasta}</code></p> </li> <li> <p><code>${samtools}</code></p> </li> </ul> <pre><code>{bash save-bash-variables-to-rvars-file}\n# Send text to export Bash variables to .rvars file\n{\necho \"# CPU threads\"\necho 'export threads=8'\necho \"\"\necho \"# Programs\"\necho 'export my_fasta=\"~/data/temporary.fasta\"'\necho 'export samtools=\"~/programs/samtools-1.12/samtools\"'\necho \"\"\n} &gt; .rvars\n</code></pre> <p>In subsequent Bash chunks, load the variables into memory to use them:</p> <pre><code>{bash load-bash-variables}\n# Load contents of .rvars into memory so varaibles are accessible\nsource .rvars\n\n# Create FastA index file\n\"${samtools} faidx \"${my_fasta}\"\n</code></pre>"},{"location":"code_Snippets/#fastq-files","title":"FastQ files","text":""},{"location":"code_Snippets/#create-separate-arrays-for-r1-and-r2-reads","title":"Create separate arrays for R1 and R2 reads","text":"<ul> <li> <p>With a for loop   <pre><code># Declare arrays\nR1_array=()\nR2_array=()\n\n# Populate arrays\nfor fastq in *R1.fq\ndo\n  R1_array+=(${fastq})\ndone\n\nfor fastq in *R2.fq\ndo\n  R2_array+=(${fastq})\ndone\n</code></pre></p> </li> <li> <p>Using \"globbing\"   <pre><code># Declare arrays\nR1_array=()\nR2_array=()\n\n# Populate arrays\nR1_array=(*R1.fq)\nR2_array=(*R2.fq)\n</code></pre></p> </li> <li> <p>Create comma-separated lists of FastQ reads</p> <p>(E.g. This is useful when running <code>bowtie2</code> or <code>Trinity</code>)</p> <pre><code>R1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n</code></pre> </li> </ul>"},{"location":"code_Snippets/#creating-single-array-with-paired-reads","title":"Creating single array with paired reads","text":"<pre><code>## Assumes there is only a single set of paired reads per sample\n\n# Declare array\nfastq_array=()\n\n# Populate array\n# Corresponding reads will be placed next to each other in array\n# (e.g. sample01_R1.fq sample01_R2.fq sample02_R1.fq samples02_R2.fq)\nfastq_array=(*.fq)\n</code></pre> <ul> <li> <p>Loop through single array of paired reads</p> <pre><code>## Assumes there is only a single set of paired reads per sample\n\n# Declare array\nfastq_array=()\n\n# Populate array\nfastq_array=(*.fq)\n\n# Loop through read pairs\n# Increment by 2 to process next pair of FastQ files\nfor (( i=0; i&lt;${#fastq_array[@]} ; i+=2 ))\n  do\n  echo \"Read 1: ${fastq_array[i]}\"\n  echo \"Read 2: ${fastq_array[i+1]}\"\ndone\n</code></pre> </li> <li> <p>Create comma-separated lists of paired FastQ reads</p> <p>(E.g This is useful when running <code>bowtie2</code> or <code>Trinity</code>)</p> <pre><code># Create comma-separated lists of FastQ reads\n# Loop through read pairs\n# Increment by 2 to process next pair of FastQ files\nfor (( i=0; i&lt;${#fastq_array[@]} ; i+=2 ))\ndo\n  # Check array length for even number (i.e. paire end FastQs)\n  if [[ $(( \"${#fastq_array[@]}\" % 2 )) -ne 0 ]]; then\n    echo \"FastQ array contains uneven number of files.\"\n    exit\n  fi\n\n  # Handle \"fence post\" problem\n  # associated with comma placement\n  if [[ ${i} -eq 0 ]]; then\n    R1_list=\"${fastq_array[${i}]},\"\n    R2_list=\"${fastq_array[${i}+1]},\"\n\n  elif [[ ${i} -eq $(( ${#fastq_array[@]} - 1 )) ]]; then\n    R1_list=\"${R1_list}${fastq_array[${i}]}\"\n    R2_list=\"${R2_list}${fastq_array[${i}+1]}\"\n\n  else\n    R1_list=\"${R1_list}${fastq_array[${i}]},\"\n    R2_list=\"${R2_list}${fastq_array[${i}+1]},\"\n  fi\ndone\n</code></pre> </li> </ul>"},{"location":"code_Snippets/#file-transfers","title":"File Transfers","text":""},{"location":"code_Snippets/#backing-up-mox-files","title":"Backing up Mox files","text":"<pre><code>/volume2/web/seashell/bu-mox$ \nrsync -avz --exclude '*_to_*' --exclude 'CHG_*.txt' --exclude 'CHH_*.txt' --exclude 'CpG_*txt' \\\n--progress sr320@mox.hyak.uw.edu:/gscratch/scrubbed/sr320/ scrubbed/\n\n\n\n/volume2/web/seashell/bu-mox$ \nrsync -avz --progress sr320@mox.hyak.uw.edu:/gscratch/srlab/sr320/ .\n</code></pre>"},{"location":"code_Snippets/#backing-up-raven-files","title":"Backing up Raven files","text":"<pre><code>/home/shared/8TB_HDD_01/sr320/github$ \nrsync -avz . \\\nsr320@gannet.fish.washington.edu:/volume2/web/seashell/bu-github/\n</code></pre>"},{"location":"code_Snippets/#wget-a-lot-of-files-from-url","title":"wget a lot of files from url","text":"<pre><code>wget -r \\\n--no-directories --no-parent \\\n-P . \\\n-A \"*_001_val_1.fq.gz\" https://gannet.fish.washington.edu/metacarcinus/Salmo_Calig/analyses/20190806_TrimGalore/\n</code></pre>"},{"location":"code_Snippets/#git-clone-website","title":"git clone website","text":"<p>when in public_html</p> <pre><code>mkdir temp\ncd temp\ngit clone https://github.com/sr320/lab-website.git\ncd ..\ncp -r temp/lab-website/docs/* .\nrm -f -r temp\necho \"now done\"\n</code></pre>"},{"location":"code_Snippets/#transfer-sequencing-files-to-owl","title":"Transfer sequencing files to Owl","text":""},{"location":"code_Snippets/#standard-rsync-procedure","title":"Standard <code>rsync</code> procedure:","text":"<pre><code>rsync --archive --progress --verbose *.fastq.gz &lt;owl_username&gt;@owl.fish.washington.edu:/volume1/web/nightingales/&lt;species_directory&gt;\n</code></pre> <ul> <li> <p>Replace <code>&lt;owl_username_&gt;</code> with whatever username you use to login to owl (even replace the <code>&lt;</code> and the <code>&gt;</code>).</p> </li> <li> <p>Replace <code>&lt;species_directory&gt;</code> with whatever species you're working with  (even replace the <code>&lt;</code> and the <code>&gt;</code>). Example directory name format: <code>P_generosa</code>.</p> </li> <li> <p>If it doesn't work, Sam may need to change your user settings on Owl, so please post an issue in https://github.com/RobertsLab/resources/issues/</p> </li> </ul>"},{"location":"code_Snippets/#using-rsync-list-of-files","title":"Using <code>rsync</code> list of files:","text":"<pre><code>rsync -avP --files-from=:/volume1/web/nightingales/P_generosa/rsync_list.txt owl:/volume1/web/ .\n</code></pre> <pre><code>head rsync_list.txt\n\nnightingales/P_generosa/Geoduck-ctenidia-RNA-1_S3_L001_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-2_S11_L002_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-3_S19_L003_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-4_S27_L004_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-5_S35_L005_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-6_S43_L006_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-7_S51_L007_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-ctenidia-RNA-8_S59_L008_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-gonad-RNA-1_S1_L001_R2_001.fastq.gz\nnightingales/P_generosa/Geoduck-gonad-RNA-2_S9_L002_R2_001.fastq.gz\n</code></pre>"},{"location":"code_Snippets/#confirm-md5-checksums","title":"Confirm MD5 checksums","text":""},{"location":"code_Snippets/#multiple-md5-checksum-files-linux","title":"Multiple MD5 checksum files (Linux)","text":"<pre><code>for checksum_file in *.md5\ndo\n  md5sum --check ${checksum_file}\ndone\n</code></pre>"},{"location":"code_Snippets/#multiple-md5-checksum-files-mac-os","title":"Multiple MD5 checksum files (Mac OS)","text":"<pre><code>for checksum_file in *.md5\ndo\n  # Gets filename without any suffixes\n  filename=$(basename -s .md5 ${checksum_file})\n  # Generates MD5 checksum and compares to provided checksum in MD5 file\n  diff &lt;(md5 \"${filename}.fastq.gz\" | awk '{print $4}') &lt;(awk '  {print $1}' ${checksum_file})\ndone\n</code></pre>"},{"location":"code_Snippets/#download-file-from-google-drive","title":"Download file from Google Drive","text":"<p>Install <code>gdown</code>.</p> <p>Ideally, a checksum for the file hosted on Google Drive exists and be can be subsequently verified after downloading.</p> <pre><code>gdown -O PGA_assembly.fasta https://drive.google.com/uc?id=1Yanmb5yBXn-D4b_fzkR2GSxP\n</code></pre>"},{"location":"code_Snippets/#transfer-files-tofrom-mox-using-globus-connect-personal","title":"Transfer files to/from Mox using Globus Connect Personal","text":"<ol> <li> <p>Log into Mox.</p> </li> <li> <p>Activate anaconda (this might fail, let me know if it does and don't bother going to the next step): <code>conda activate</code></p> </li> <li> <p>Setup Globus collection: <code>/gscratch/srlab/programs/globusconnectpersonal-3.1.4/globusconnectpersonal -setup --no-gui</code></p> </li> <li> <p>Follow the instructions (copy/paste URL into browser, get code from webpage, enter code in Mox terminal, provide name for collection).</p> </li> <li> <p>Add desired Mox directory to config file and set permissions. Here's an example:</p> </li> </ol> <pre><code>$cat ~/.globusonline/lta/config-paths\n\n~/,0,1\n/gscratch/scrubbed/samwhite/,0,1\n</code></pre> <p>The config file does two things:</p> <ul> <li><code>~/,0,1</code>: Makes your home directory readable/writeable by Globus.</li> <li> <p><code>/gscratch/scrubbed/samwhite/,0,1</code>: Makes my directory on <code>/gscratch/scrubbed/</code> readable/writeable by Globus.</p> </li> <li> <p>Start Globus Connect Personal: <code>/gscratch/srlab/programs/globusconnectpersonal-3.1.4/globusconnectpersonal -start</code>. Nothing will happen after you hit enter. The cursor will simply flash - this is good.</p> </li> <li> <p>Login to your Globus Connect Personal account via a web browser.</p> </li> <li> <p>Click on Collections and you should now see your collection (name provided in Step 4), and it should have a green stack of papers(?) next to it; the green indicates that the connection is activate.</p> </li> <li> <p>Click on the collection name.</p> </li> <li> <p>Click on \"Open in File Manager\" (on the right side of the screen).</p> </li> <li> <p>Navigate to the directory you setup in Step 5. NOTE: You'll have to navigate up a directory out of your home directory in order to get to the <code>/gscratch</code> partition.</p> </li> <li> <p>Transfer data from other Globus Endpoint to Mox!</p> </li> </ul>"},{"location":"code_Snippets/#fasta","title":"FastA","text":""},{"location":"code_Snippets/#filter-fasta-file-by-minimum-sequence-length","title":"Filter FastA File by Minimum Sequence Length","text":"<p>Just change the number \"200\" in the code below to your desired minimum sequence length.</p> <pre><code>$ awk '!/^&gt;/ { next } { getline seq } length(seq) &gt;= 200 { print $0 \"\\n\" seq }' InputFastaFile.fasta\n</code></pre> <p>Code explanation:</p> <p><code>!/^&gt;/ { next }</code>:</p> <ul> <li>If a line (i.e. record) begins with a \u201c&gt;\u201d, go to the next line (record). The \"!\" tells awk to skip the regular expression that immediatley follows. The \"^\" tells awk that the regular expression it's looking for should only match if it's at the beginning of a line. Finally, the regular expression we're looking for in this example is the \"&gt;\", which denotes the sequence descriptor portion of FASTA files.</li> </ul> <p><code>{ getline seq }</code>:</p> <ul> <li>\u201cgetline\u201d reads the next record and assigns the entire record to a variable called \u201cseq\u201d</li> </ul> <p><code>length(seq) &gt;=200</code>:</p> <ul> <li>If the length of the \u201cseq\u201d record is greater than, or equal to, 200 then\u2026</li> </ul> <p><code>{print $0 \"\\n\" seq&gt;}</code>:</p> <ul> <li>Print all records (<code>$0</code>) of the variable \u201cseq\u201d in the file that matched our conditions, each on a new line (\u201c\\n\u201d)</li> </ul>"},{"location":"code_Snippets/#fasta-to-tab-delimited","title":"fasta to tab-delimited","text":"<pre><code>!perl -e '$count=0; $len=0; while(&lt;&gt;) {s/\\r?\\n//; s/\\t/ /g; if (s/^&gt;//) { if ($. != 1) {print \"\\n\"} s/ |$/\\t/; $count++; $_ .= \"\\t\";} else {s/ //g; $len += length($_)} print $_;} print \"\\n\"; warn \"\\nConverted $count FASTA records in $. lines to tabular format\\nTotal sequence length: $len\\n\\n\";' \\\n../data/GCF_000297895.1_oyster_v9_cds_from_genomic.fna &gt; ../analyses/GCF_000297895.1_oyster_v9_cds_from_genomic.tab\n</code></pre>"},{"location":"code_Snippets/#fastqc","title":"<code>FastQC</code>","text":""},{"location":"code_Snippets/#pass-space-delimited-list-of-fastq-files-to-fastqc","title":"Pass space-delimited list of FastQ files to FastQC","text":"<pre><code># Set CPU threads to use\nthreads=20\n\n# Populate array with FastQ files\nfastq_array=(*.fq.gz)\n\n# Pass array contents to new variable\nfastqc_list=$(echo \"${fastq_array[*]}\")\n\n# Run FastQC\n# NOTE: Do NOT quote ${fastqc_list}\nfastqc \\\n--threads ${threads} \\\n--outdir ${output_dir} \\\n${fastqc_list}\n</code></pre>"},{"location":"code_Snippets/#blast","title":"<code>BLAST</code>","text":"<pre><code>Applications/bioinfo/ncbi-blast-2.11.0+/bin/blastx \\\n-query ../data/GCF_000297895.1_oyster_v9_cds_from_genomic.fna \\\n-db ../blastdb/Caenorhabditis_elegans.WBcel235.pep  \\\n-out ../analyses/Cg-WBcel235_blastx.tab \\\n-evalue 1E-05 \\\n-num_threads 4 \\\n-max_target_seqs 1 \\\n-max_hsps 1 \\\n-outfmt \"6 qaccver saccver evalue\"\n</code></pre>"},{"location":"code_Snippets/#tips-tricks","title":"Tips &amp; Tricks","text":""},{"location":"code_Snippets/#remove-spaces-from-filenames-in-a-directory","title":"Remove spaces from filenames in a directory","text":"<pre><code>for file in *; do mv \"$file\" ${file// /}; done\n</code></pre> <p>Explanation:</p> <ul> <li> <p><code>for file in *;</code></p> </li> <li> <p>A for loop that looks at all files in the current directory. The word <code>file</code> is a variable that takes on the value of each file name in the directory (one file name per loop). The <code>;</code> is needed for bash for loop formatting.</p> </li> <li> <p><code>do mv \"$file\" ${file// /};</code></p> </li> <li> <p>Tells bash to use the move command (<code>mv</code>) and use the current contents of the variable <code>$file</code> as the initial filename. The <code>${file// /}</code> is a substitution command that tells bash to use the contents of the <code>file</code> variable and replace all spaces (<code>//</code> ; note - there should be a space after the last slash here) with nothing (<code>/</code> - you can add text after this slash to replace with information of your choice). The <code>;</code> is needed for bash for loop formatting.</p> </li> <li> <p><code>done</code></p> </li> <li>Ends the for loop</li> </ul>"},{"location":"mox_Adding-a-User/","title":"New User","text":"<p>The first step for being added to the Roberts Lab account is to submit an issue requesting access. Once you have been added into the UW-IT system (you will notified by a response in the GitHub issue), you can follow the steps below.</p> <p>Taken from here</p> <p>For the user:</p> <ol> <li>Go to https://uwnetid.washington.edu/manage/</li> <li>Click the \"Computing Services\" link on the left</li> <li>Click the \"Hyak Server\" and \"Lolo Server\" check boxes in the \"Inactive Services\" section.</li> <li>Click the \"Subscribe &gt;\" button at the bottom of the page.</li> <li>Read the notice and click the \"Finish\" button.</li> </ol> <p>For two factor authentication, you can either sign up for Duo here and use your smart phone or request a security token here. Duo is much easier.</p> <p>For the designated Technical contact (i.e. Steven or Sam):</p> <ol> <li>Proceed to the UW-IT Groups Service.</li> <li>Click the \"Find my groups\" link in the \"Find groups\" section.</li> <li>In the search results section, there should be a link u_hyak_srlab. Click it</li> <li>It will bring up a description of your group. Click the \"Membership\" link.</li> <li>Type the UW NetID(s) into the \"Add members\" text field and click the \"Do it\" button. Newly added user(s) should now appear in the \"Membership\" section. An error window will appear if the user(s) cannot be added.</li> <li>Notify the users that they have been added.</li> </ol>"},{"location":"mox_Data-Storage-and-System-Organization/","title":"Data Storage and System Organization","text":""},{"location":"mox_Data-Storage-and-System-Organization/#hyak-mox-storage-locations-capacities","title":"Hyak (mox) Storage Locations &amp; Capacities","text":""},{"location":"mox_Data-Storage-and-System-Organization/#1-user-specific-storage","title":"1. User-specific storage","text":"<ul> <li>Storage allocation: 10GB (or 250,000 files)</li> <li>Located on your login node (e.g. <code>/usr/lusers/UWnetID</code>)</li> <li>To see space and file utilization: <code>mmlsquota gscratch:home --block-size G</code></li> <li>For personal data, scripts, and other small files, or files you don't want potentially changed by others.</li> </ul>"},{"location":"mox_Data-Storage-and-System-Organization/#2-group-specific-storage","title":"2. Group-specific storage","text":"<ul> <li>Storage allocation: 5500GB (or 2,475,000 files)</li> <li>Located: <code>/gscratch/srlab/</code></li> <li>Shared by all srlab members</li> <li>To see space and file utilization: <code>mmlsquota -j srlab gscratch --block-size G</code></li> </ul>"},{"location":"mox_Data-Storage-and-System-Organization/#3-temporary-storage","title":"3. Temporary storage","text":"<ul> <li>Storage allocation: 200TB (or 200,000,000 files).</li> <li>Located: <code>/gscratch/scrubbed/</code></li> <li>Shared by all Hyak (mox) users.</li> <li>Files are automatically deleted 30 days after creation.</li> <li>To see space and file utilization: <code>mmlsquota -j scrubbed gscratch --block-size G</code></li> </ul>"},{"location":"mox_Data-Storage-and-System-Organization/#suggested-user-organization","title":"Suggested User Organization","text":"<p>You should be aware of storage limits above, but here is a suggestion of how to organize your files.</p> <p>In our group-specific storage (<code>/gscratch/srlab/your_uw_id</code>) create clear subdirectories that any files that might be needed over the course of months or years and are not large in size.</p> <p>Generally you will need to  use the temporary storage. Roughly 500GB of input or output would qualify for using this space. Of course this will always depend on our free space in group-specific storage. Just be aware of the 30 day limit. </p> <p>And example of how Steven operates is that for every job he creates a directory in slurm (eg 020322-oly-snp) and includes job shell script in this directory and write out to said directory. Once complete you would rsync to your personal directory on one of birds (eg gannet).</p>"},{"location":"mox_File-Transfers/","title":"File Transfers","text":""},{"location":"mox_File-Transfers/#rsync","title":"<code>rsync</code>","text":""},{"location":"mox_File-Transfers/#transferring-data-tofrom-mox-hyak-with-rsync","title":"Transferring data to/from Mox (Hyak) with <code>rsync</code>","text":"<p><code>rsync</code> is a file transfer program. It copies specified files/folders from one location to another. Additionally, it verifies data integrity after the files have been transferred. This feature is critical, due to the large file sizes we frequently work with.</p>"},{"location":"mox_File-Transfers/#copy-files-to-mox","title":"Copy files to Mox:","text":"<ul> <li><code>rsync --archive --progress --verbose /path/to/file username@mox_IP:/path/to/mox/directory</code></li> </ul>"},{"location":"mox_File-Transfers/#copy-entire-folder-to-mox-it-is-important-to-make-sure-there-is-no-at-the-end-of-the-remote-path","title":"Copy entire folder to Mox (it is important to make sure there is no <code>/</code> at the end of the remote path):","text":"<p>Navigate to the directory immediately above the one which you are interested in copying and then run the following command):</p> <ul> <li><code>rsync --archive --progress --verbose --relative ./directory username@mox_IP:/path/to/mox/directory</code></li> </ul>"},{"location":"mox_File-Transfers/#copy-files-from-mox","title":"Copy files from Mox:","text":"<ul> <li><code>rsync --archive --progress --verbose username@mox_IP:/path/to/mox/file /path/to/local/directory</code></li> </ul>"},{"location":"mox_File-Transfers/#sftp","title":"<code>sftp</code>","text":"<ul> <li><code>sftp -oPort=#### user42@my.server.edu</code>  once in commands include <code>ls</code>, <code>cd</code>, <code>get -r *</code> etc. Note port only needs be set not default (21).</li> </ul>"},{"location":"mox_Installing-Programs/","title":"Installing software","text":""},{"location":"mox_Installing-Programs/#guidance-for-installing-programs","title":"Guidance for installing programs.","text":"<p>All program installations should be performed with a Build node.</p> <ol> <li> <p>Transfer your program files on to Hyak. Make note of any dependencies your program may need including Python (which can be loaded via a module) or another program.</p> </li> <li> <p>If your program installation has dependency installation as part of the install script, you will need to use a build node for installation and compiling, otherwise an interactive node will be adequate.</p> </li> <li> <p>Due to space limitations, and our desire to share with the rest of the lab, all programs should be installed here:</p> </li> </ol> <p><code>/gscratch/srlab/programs</code>.</p> <ol> <li> <p>Unzip the program files.</p> </li> <li> <p>Begin installation. Most software packages include a <code>README</code> text file that explains the installation procedure. There is a lot of trial and error in this step, and you'll get very good at reading and Googling error messages, StackExchange will be your friend. An example of the process involved can be found here</p> </li> </ol>"},{"location":"mox_Installing-Programs/#general-tips","title":"General Tips","text":"<ul> <li>Add <code>cmake</code> to your system <code>$PATH</code> by adding the following to your <code>~/.bashrc</code> file:</li> </ul> <pre><code># Append cmake to beginning of PATH (primarily for Trinity 2.8 install)\nexport PATH=\"/gscratch/srlab/programs/cmake-3.12.1/bin:$PATH\"\n</code></pre>"},{"location":"mox_Installing-Programs/#ana-conda-packages","title":"(Ana) conda packages:","text":"<ol> <li> <p>Activate the default (base) conda environment:</p> <p><code>/gscratch/srlab/programs/anaconda3/condabin/conda activate</code></p> </li> <li> <p>Install your desired package (replace <code>&lt;package&gt;</code> with your package name):</p> <p><code>conda install &lt;package&gt;</code></p> </li> <li> <p>Deactivate the conda environment:</p> <p><code>conda deactivate</code></p> </li> <li> <p>The program should now be available in this directory:</p> <p><code>/gscratch/srlab/programs/anaconda3/bin/&lt;program_name&gt;</code></p> </li> </ol>"},{"location":"mox_Installing-Programs/#installing-r-packages","title":"Installing R Packages","text":"<p>This is a guide to change the default R library install location to avoid running into space limits in the default home directory. After following the instructions below, all package installations should be performed on a build node.</p> <ol> <li> <p>Make a designated directory for your R packages, e.g.:</p> <p><code>mkdir --parents /gscratch/srlab/${USER}/R_libs</code></p> </li> <li> <p>Create an <code>.Renviron</code> file in your home directory, defining the <code>R_USER_LIB</code> location established in Step 1:</p> <pre><code>echo \"# Set local library installation path\nR_LIBS_USER=/gscratch/srlab/${USER}/R_libs\" &gt; ~/.Renviron\n</code></pre> </li> <li> <p>Confirm success:</p> <pre><code># Start R\n/gscratch/srlab/programs/R-3.6.2/bin/R\n</code></pre> <pre><code># Check library paths\n.libPaths()\n</code></pre> </li> <li> <p>The output should look something like this:</p> <pre><code>[1] \"/gscratch/srlab/sam/R_libs\"          \n[2] \"/gscratch/srlab/programs/R-3.6.2/library\"\n</code></pre> </li> </ol>"},{"location":"mox_Jupyter-Notebooks/","title":"Jupyter Notebooks","text":"<p>These directions are taken from the Mox Hyak wiki found here.</p>"},{"location":"mox_Jupyter-Notebooks/#use-jupyter-notebook","title":"Use Jupyter Notebook","text":"<ol> <li> <p>Login to Hyak (MOX).</p> </li> <li> <p>Start an interactive node session via <code>srun -p srlab -A srlab --time=hh:mm:ss --pty /bin/bash</code></p> <ul> <li>Replace the <code>--time=hh:mm:ss</code> with desired runtime. E.g. <code>--time=02:00:00</code> will set a runtime of 2hrs, 0mins, and 0secs.</li> </ul> </li> <li> <p>Activate Anaconda 3: <code>conda activate</code></p> </li> <li> <p>Navigate to your desired working directory (e.g. <code>cd /gscratch/srlab/</code> or <code>/gscratch/scrubbed/</code>).</p> </li> <li> <p>Start Jupyter Lab <code>jupyter-lab --no-browser --port 9000 --ip 0.0.0.0</code>.</p> <ul> <li>Make note of the NODE_NUMBER assigned to you (it will frequently be different each time you run this process) - highlighted in the screencap below:</li> </ul> <p></p> </li> <li> <p>In another terminal window on your local desktop, type <code>ssh &lt;UW_NetID&gt;@mox.hyak.uw.edu -L 9000:&lt;NODE_NUMBER&gt;.hyak.local:9000</code></p> <ul> <li> <p>Replace <code>&lt;UW_NetID&gt;</code> (including the <code>&lt;&gt;</code>) with your UW NetID.</p> </li> <li> <p>Replace <code>&lt;NODE_NUMBER&gt;</code> (including the <code>&lt;&gt;</code>) with the node assigned to you in Step 3.</p> </li> <li> <p>NOTE: If you receive the following error message (note the part highlighted in white), then close all of your terminals connected to Mox and start again; this time specifying a different port number in Step 5 (port number can be anything greater than 9000 and less than 65000):</p> </li> </ul> <p></p> </li> <li> <p>In your local web browser, paste the lengthy URL provided in Step 3.</p> </li> </ol>"},{"location":"mox_Logging-In/","title":"Logging in","text":"<ol> <li>Open your favorite terminal</li> <li>Type <code>ssh &lt;YourUWNetID&gt;@mox.hyak.uw.edu</code> (replace <code>&lt;YourUWNetID&gt;</code> with your own UW Net ID)</li> <li>Input your UWNetID password</li> <li>If you're signed up for 2-factor authentication via Duo, open your smart phone and approve the connection.</li> <li>You're logged in to a Login node for Hyak!</li> </ol> <p>Example:</p> <pre><code>D-69-91-141-150:~ Sean$ ssh seanb80@mox.hyak.uw.edu\nPassword:\nEnter passcode or select one of the following options:\n\n 1. Duo Push to iOS (XXX-XXX-1239)\n 2. Phone call to iOS (XXX-XXX-1239)\n\nDuo passcode or option [1-2]: 1\nLast login: Thu Jun  8 14:59:10 2017 from d-173-250-161-130.dhcp4.washington.edu\n\n     ** NOTICE **\n     Users need to do all their interactive work, including compiling and\n     building software, on the compute nodes (n####) and NOT on the\n     head/login node (hyak.washington.edu). The login nodes are for\n     interacting with the scheduler and transferring data to and from the\n     system.\n\n     Please visit the Hyak User Wiki for more details\n     http://wiki.hyak.uw.edu\n\n\n[seanb80@mox2 ~]$\n</code></pre>"},{"location":"mox_Node-Types/","title":"Node Types","text":"<p>There are 4 main types of Hyak nodes:</p> <ul> <li> <p>Login</p> </li> <li> <p>Build</p> </li> <li> <p>Interactive</p> </li> <li> <p>Execute</p> </li> </ul> <p>Each has a different function and different levels of connectivity.</p> <p>We're guaranteed one node allocation at any given time, some nodes count towards this allocation, some do not.</p>"},{"location":"mox_Node-Types/#login-node","title":"Login Node","text":"<ul> <li>Shell prompt looks like <code>[UWNetID@mox2 ~]$</code></li> <li>The first node you encounter upon logging in.</li> <li>Access to this node type is user-specific (i.e. only you have access to your login node).</li> <li>For file transfers and manipulation.</li> <li>This node has internet connectivity.     </li> <li>Not for running programs, program compiling, or other time/compute power intensive tasks.  </li> </ul>"},{"location":"mox_Node-Types/#build-node","title":"Build Node","text":"<ul> <li> <p>Enter Build node from Login node (specify time needed):</p> <ul> <li><code>srun -p build --time=h:mm:ss --mem=100G --pty /bin/bash</code></li> </ul> </li> <li> <p>Shell prompt looks like <code>[UWNetID@nXXXX ~]$</code>. (<code>XXXX</code> will actually be a number)</p> </li> <li>For downloading and compiling software from external sources</li> <li>This node has internet connectivity</li> <li>Not for compute power intensive tasks.</li> <li>Access to this node type is granted to all users of the Hyak (mox) system across the entire university.</li> <li>A limited number of build nodes are available across all Hyak (mox) users, so there may be a wait to access a build node at times.</li> <li>When finished, exit a build node by typing <code>exit</code> and then press the <code>Enter</code> key.</li> </ul>"},{"location":"mox_Node-Types/#interactive-node","title":"Interactive Node","text":"<ul> <li>Shell prompt looks like <code>[UNetID@nXXXX ~]$</code>. (<code>XXXX</code> will actually be a number)</li> <li> <p>Enter Interactive node from Login node (specify time needed):</p> <ul> <li><code>srun -p srlab -A srlab --time=h:mm:ss --mem=100G --pty /bin/bash</code></li> </ul> </li> <li> <p>For testing, short run/low power tasks, and experimentation</p> </li> <li>Access to this node type is limited to the Roberts Lab group, but is limited to a single group member at one time.</li> <li>Cannot use Execute node while Interactive node is in use.</li> <li>This node does not have internet connectivity.</li> <li>Not for compute power or time intensive tasks. Has file size/number limits.</li> <li>When finished, exit an interactive node by typing <code>exit</code> and then press the <code>Enter</code> key.</li> </ul>"},{"location":"mox_Node-Types/#execute-node","title":"Execute Node","text":"<ul> <li>Runs computing jobs submitted via an <code>sbatch</code> script.</li> <li>For execution of large tasks. The \"heavy lifting\" node.</li> <li>No shell prompt</li> <li>This node does not have internet connectivity</li> <li>Access to this node type is limited to the Roberts Lab group, but is limited to a single group member at one time.</li> <li>Cannot use Interactive node while Execute node is in use.</li> <li>Creates <code>slurm-job#.out</code> files in working directory specified in <code>sbatch</code> execution script. This contains all standard out output from the program. This can be monitored via <code>cat</code> or <code>tail</code> from a Login node.</li> <li><code>top</code> and other task manager functions can only be accessed after <code>ssh</code>ing in to the node.</li> </ul>"},{"location":"mox_RStudio-Server/","title":"RStudio Server","text":""},{"location":"mox_RStudio-Server/#quick-start-guide","title":"Quick Start Guide","text":"<p>Example SLURM Script to launch RStudio Server:</p> <ul> <li> <p>User needs to set the following before starting script:</p> <ul> <li><code>--mail-user=</code></li> <li><code>--chdir=</code></li> <li> <p><code>R_LIBS_USER</code> in <code>~/.Renviron</code>. Example:</p> <pre><code>cat ~/.Renviron \n# Set local library installation path\nR_LIBS_USER=/gscratch/srlab/${USER}/R_libs_singularity\n</code></pre> </li> </ul> </li> <li> <p>After submitting script, view the SLURM output file located in <code>--chdir=</code> for information on:</p> <ol> <li> <p>How to create tunnel to Mox node.</p> </li> <li> <p>What address to direct your web browser to.</p> </li> <li> <p>Username/password to enter into RStudio Server interface.</p> </li> <li> <p>How to terminate RStudio Server and the SLURM job.</p> </li> </ol> </li> <li> <p>Example script uses the following Singularity container image: <code>rstudio-4.0.2.sjw-v1.0</code>.</p> </li> </ul> <pre><code>#!/bin/bash\n## Job Name\n#SBATCH --job-name=rstudio_server_test\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-08:00:00\n## Memory per node\n#SBATCH --mem=100G\n#SBATCH --signal=USR2\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=\n## Specify the working directory for this job\n#SBATCH --chdir=\n\n\n################################################################\n# Set user-defined variables inside this box.\n\n# Set container path\ncontainer_path=\"/gscratch/srlab/programs/singularity_containers\"\n\n# Set container name\ncontainer=\"rstudio-4.0.2.sjw-v1.0.sif\"\n################################################################\n\n## MAKE NO CHANGES BELOW THIS LINE\n\nmodule load singularity\n\n\n\nexport PASSWORD=$(openssl rand -base64 15)\n# get unused socket per https://unix.stackexchange.com/a/132524\n# tiny race condition between the python &amp; singularity commands\nreadonly PORT=$(python -c 'import socket; s=socket.socket(); s.bind((\"\", 0)); print(s.getsockname()[1]); s.close()')\ncat 1&gt;&amp;2 &lt;&lt;END\n1. SSH tunnel from your workstation using the following command:\n\n   ssh -N -L 8787:${HOSTNAME}:${PORT} ${USER}@mox.hyak.uw.edu\n\n   and point your web browser to http://localhost:8787\n\n2. log in to RStudio Server using the following credentials:\n\n   user: ${USER}\n   password: ${PASSWORD}\n\nWhen done using RStudio Server, terminate the job by:\n\n1. Exit the RStudio Session (\"power\" button in the top right corner of the RStudio window)\n2. Issue the following command on the login node:\n\n      scancel -f ${SLURM_JOB_ID}\nEND\n\n\n##NOTE##\n# This is a local drive location I can write, you should be able\n# to just set to a subfolder of your HPC home/scratch directory\nexport TMPDIR=\"/gscratch/scrubbed/${USER}/rstudio-tmp\"\n\nmkdir -p \"$TMPDIR/tmp/rstudio-server\"\nuuidgen &gt; \"$TMPDIR/tmp/rstudio-server/secure-cookie-key\"\nchmod 0600 \"$TMPDIR/tmp/rstudio-server/secure-cookie-key\"\n\nmkdir -p \"$TMPDIR/var/lib\"\nmkdir -p \"$TMPDIR/var/run\"\n\n# User-installed R packages go into their home directory\nif [ ! -e ${HOME}/.Renviron ]\nthen\n  printf '\\nNOTE: creating ~/.Renviron file\\n\\n'\n  echo 'R_LIBS_USER=~/R/%p-library/%v' &gt;&gt; ${HOME}/.Renviron\nfi\n\n# This example bind mounts the /gscratch/scrubbed/${USER} directory on the host into the Singularity container.\n# By default the only host file systems mounted within the container are $HOME, /tmp, /proc, /sys, and /dev.\nsingularity exec \\\n--bind=\"$TMPDIR/var/lib:/var/lib/rstudio-server\" \\\n--bind=\"$TMPDIR/var/run:/var/run/rstudio-server\" \\\n--bind=\"$TMPDIR/tmp:/tmp\" \\\n--bind=/gscratch/scrubbed/${USER} \\\n${container_path}/${container} \\\nrserver --www-port ${PORT} --auth-none=0 --auth-pam-helper-path=pam-helper\n</code></pre>"},{"location":"mox_RStudio-Server/#createcustomize-your-own-singularity-rstudio-server-container","title":"Create/customize your own Singularity Rstudio Server container","text":"<p>NOTE: These instructions are written to be performed on Mox (Hyak).</p> <ol> <li> <p>Create a Singularity definition file:</p> <ul> <li> <p>Example filename: <code>rstudio-4.0.2.sjw-v1.0.def</code></p> </li> <li> <p>Here's an example with a good set of basic installations for R 4.0.2:</p> </li> </ul> <pre><code>Bootstrap: docker\nFrom: rocker/rstudio:4.0.2\n%files\n    # Load file with R package installation commands in to container at /tmp\n    # Expects file called \"r_packages_installs.R\" to be in current directory.\n    r_packages_installs.R /tmp/\n\n%post\n    # Install additinoal system packages in container\n    # Most are needed for R/RStudio dependencies\n    apt -y update\n    apt -y install libxml2 libz-dev libbz2-dev liblzma-dev libxtst6 libxt6\n\n    # Run R package installation script file\n    Rscript /tmp/r_packages_installs.R\n</code></pre> </li> <li> <p>Create file <code>r_packages_installs.R</code> containing R package installation instructions.</p> <ul> <li> <p>NOTE: The container already has a base set of R packages (e.g. <code>ggplot2</code> installed).</p> </li> <li> <p>Here's an example with a set of commonly used packages:</p> </li> </ul> <pre><code># Update base packages\nupdate.packages(ask = FALSE)\n\n# Install BioConductor package manager\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\ninstall.packages(\"BiocManager\")\nBiocManager::install(version = \"3.14\")\n\n# Install tidyverse\ninstall.packages(\"tidyverse\")\n\n# Install matrixStats 0.61.0 (needed for DESeq2)\ninstall.packages(\"https://cran.rstudio.com/src/contrib/matrixStats_0.61.0.tar.gz\", repos=NULL, type=\"source\")\n\n# Install remotes package (allows for package installs from GitHub)\nBiocManager::install(\"remotes\")\n\n# Install GSEABase (a dependency for numerous gene ontology/enrichment analysis)\nBiocManager::install(\"Bioconductor/GSEABase\")\n\n# Install qvalue package\nBiocManager::install(\"qvalue\")\n\n# Install GO.db (annotation maps for Gene Ontology data)\nBiocManager::install(\"GO.db\")\n\n# Install MatrixGenerics (needed for DESeq2)\nBiocManager::install(\"MatrixGenerics\")\n\n# Install Methylkit\nBiocManager::install(\"methylKit\")\n\n# Install GOseq\nBiocManager::install(\"goseq\")\n\n# Install WGCNA\nBiocManager::install(\"WGCNA\")\n\n# Install DESeq2\nBiocManager::install(\"DESeq2\")\n</code></pre> </li> <li> <p>Log into a build node.</p> </li> <li> <p>Load the Singularity module:</p> <p><code>module load singularity</code></p> </li> <li> <p>Build the container:</p> <ul> <li>NOTE: Container name will be <code>rstudio-4.0.2.sjw-v1.0.sif</code></li> </ul> <p><code>singularity build --fakeroot rstudio-4.0.2.sjw-v1.0.sif rstudio-4.0.2.sjw-v1.0.def</code></p> </li> <li> <p>Use the SLURM script above.</p> <ul> <li>NOTE: Be sure to update the script line to reflect your container name:</li> </ul> <pre><code># Set container name\ncontainer=\"rstudio-4.0.2.sjw-v1.0.sif\"\n</code></pre> </li> </ol>"},{"location":"mox_Running-a-Job/","title":"Running a job","text":"<p>NOTE - Please use temporary storage / <code>scrubbed</code> for running jobs (ie writing new files to). As the name suggests you will need move files to a \"bird\" for archival storage. If you are needing a  set of large raw files for analysis - also place these in the <code>scrubbed</code> directory.</p> <p><code>sbatch</code> is the main execution command for the job scheduler (slurm). It spools up an execute node for long term or compute intensive tasks such as assemblies, blasts, or other things of that nature.</p> <p><code>sbatch</code> can be run from a login node with the command  ` <pre><code>sbatch shell.script\n</code></pre></p> <p><code>sbatch</code> requires a shell script to function, with two main parts, the header and the execute portion.</p>"},{"location":"mox_Running-a-Job/#intro","title":"Intro","text":""},{"location":"mox_Running-a-Job/#the-header","title":"The Header","text":"<pre>\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=myjob\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Nodes\n#SBATCH --nodes=n\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=dd-hh:mm:ss\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=$USER\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/srlab/path/to/your/desired/directory\n</code>\n</pre> <p>Bolded sections must be changed prior to execution.</p> <ul> <li> <p><code>--job-name=</code><code>myjob</code> is just an identifier for the system. It's what shows up in <code>scontrol</code> and <code>squeue</code> calls.</p> </li> <li> <p><code>--nodes=</code><code>n</code> Replace <code>n</code> with the number of nodes (maximum 2).</p> </li> <li> <p><code>--time=</code><code>dd-hh:mm:ss</code> is the \"wall\" time, or how long we are reserving the node for our use. This argument requires some consideration and knowledge about the program you're running prior to execution. Selecting too little wall time will cause the scheduler to kill your process mid-run when time runs out. Selecting too much time limits other's ability to use Hyak functions, but the scheduler releases a node upon program completion usually, so this is a secondary consideration.</p> </li> <li> <p><code>--mem=</code><code>500G</code> specifies how much memory (RAM) to allocate to the process. We have two nodes with two different amounts of RAM: 512GB and 128GB. The amount entered will determine which node is assigned to your job. E.g. if two jobs are submitted that request &gt;128GB RAM, then the jobs will be run sequentially, in the order they were submitted, because there is only one node that has &gt;128GB of RAM.</p> </li> <li> <p><code>--chdir=</code><code>/gscratch/srlab/path/to/your/desired/directory</code> indicates the working directory where output will be written, and how things will be referenced inside of the home node. Ideally this will be on the <code>/gscratch/srlab/</code> drive, but there's no requirement for this. See the Data Storage &amp; System Organization section of the wiki for more info.</p> </li> </ul>"},{"location":"mox_Running-a-Job/#the-execute-portion","title":"The Execute portion","text":"<p>This section contains the commands you want executed. You can treat it like the command line in that it executes commands sequentially as input. These can include program calls, module loading, making directories, etc. See the Full Example script below.</p>"},{"location":"mox_Running-a-Job/#full-example-script","title":"Full Example script","text":"<p>The script below (named <code>Plat_Illu_Run2.sh</code>) specifies a job called \"Oly_Platanus_Illu\" and requests a single node,  720hrs of computing time, using 500G of RAM.</p> <p>NOTE: Since only a single node is requested, another job could be submitted and run simultaneously on our other node, but the job would have to request &lt;=128GB of RAM (the max on the available node).</p> <p>The actual jobs that follow the <code>sbatch</code> header loads the Anaconda module (which is used to load a Python environment), makes a new directory in <code>/scr/srlab/seanb80/plat_illu_tmp</code>, runs the <code>platanus</code> program on a set of files, and then runs the <code>redundans</code> programm on a set of files.</p> <p>To run the script below, one would enter the following in a login node:</p> <p><code>sbatch Plat_Illu_Run2.sh</code></p> <pre><code>#!/bin/bash\n## Job Name\n#SBATCH --job-name=Oly_Platanus_Illu\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (720 hours)\n#SBATCH --time=720:00:00\n## Memory per node\n#SBATCH --mem=500G\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/srlab/data/Oly_Plat_Illu2/\n\nmodule load anaconda2_4.3.1\n\nmkdir -p /scr/srlab/seanb80/plat_illu_tmp\n\n/gscratch/srlab/programs/platanus_1.2.4/platanus assemble \\\n-f /gscratch/srlab/data/OlyData/Illumina/trimmed/*.fq.fq \\\n-t 28 \\\n-k 20 \\\n-u 0.2 \\\n-o Oly_Out_ \\\n-m 500\n\n/gscratch/srlab/programs/redundans/redundans.py \\\n-t 28 \\\n-v \\\n-l /gscratch/srlab/data/OlyData/PacBio/170210_PCB-CC_MS_EEE_20kb_P6v2_D01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170228_PCB-CC_AL_20kb_P6v2_C01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170228_PCB-CC_AL_20kb_P6v2_D01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170228_PCB-CC_AL_20kb_P6v2_E01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170307_PCB-CC_AL_20kb_P6v2_C01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170307_PCB-CC_AL_20kb_P6v2_C02_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170314_PCB-CC_20kb_P6v2_A01_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170314_PCB-CC_20kb_P6v2_A02_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170314_PCB-CC_20kb_P6v2_A03_1_filtered_subreads.fastq /gscratch/srlab/data/OlyData/PacBio/170314_PCB-CC_20kb_P6v2_A04_1_filtered_subreads.fastq \\\n-f /gscratch/srlab/data/Oly_Plat_Illu/Oly_Out__contig.fa \\\n-o /gscratch/srlab/data/Oly_Redundans_Run2\n</code></pre>"},{"location":"mox_Running-a-Job/#sbatch-script-templateexample","title":"SBATCH Script Template/Example","text":"<pre><code>#!/bin/bash\n## Job Name\n#SBATCH --job-name=DESCRIPTIVE_JOB_NAME\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=YOUR_UW_NET_ID@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/path/to/your/desired/directory\n\n# Requires Bash &gt;=4.0, as script uses associative arrays.\n\n###################################################################################\n# These variables need to be set by user\n\n## Number of CPU threads to use for programs (if applicable)\nthreads=28\n\n## Program paths\nbowtie2_dir=\"/gscratch/srlab/programs/bowtie2-2.4.2-linux-x86_64\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n## Programs associative array\n## Using array is useful for logging program options (see end of script)\ndeclare -A programs_array\n\nprograms_array=(\n[bowtie2]=\"${bowtie2_dir}/bowtie2\" \\\n[bowtie2_build]=\"${bowtie2_dir}/bowtie2-build\" \\\n[samtools_index]=\"${samtools} index\" \\\n[samtools_sort]=\"${samtools} sort\" \\\n[samtools_view]=\"${samtools} view\"\n)\n\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n\n## PUT COMMANDS IN THIS SECTION\n\n## CALL PROGRAMS FROM ARRAY\n${programs_array[bowtie2_build]} \\\n--threads ${threads} \\\n${transcriptomes_array[$transcriptome]} \\\n${transcriptome_name}\n\n\n###################################################################################\n\n## Capture program options\n## Expects program options to be accessible via an \"-h\" argument,\n## but has exceptions for some other commonly used programs (e.g. samtools, multiqc)\necho \"Logging program options...\"\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &amp;&gt;&gt; program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\necho \"\"\necho \"Finished logging program options.\"\necho \"\"\n\necho \"\"\necho \"Logging system PATH.\"\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} &gt;&gt; system_path.log\n\necho \"Finished logging system PATH\"\n</code></pre>"},{"location":"mox_Software/","title":"Software","text":""},{"location":"mox_Software/#program-locations","title":"Program locations","text":"<p>The majority of programs can be found in:</p> <p><code>$/gscratch/srlab/programs/</code></p> <p>(Ana) conda programs are a bit more difficult to track down, but try looking in these two locations:</p> <p><code>/gscratch/srlab/programs/anaconda3/bin/</code></p>"},{"location":"mox_Software/#modules","title":"Modules","text":"<p>Modules are a relatively simple way to add programs to your system <code>$PATH</code></p> <p>A module is a text file. Here's an example from <code>cat /gscratch/srlab/programs/modules/maker-3.01.03.module</code>:</p> <pre><code>#%Module1.0\nproc ModulesHelp { } {\n        puts stderr \"\\tAdds MAKER dependencies to environment.\"\n}\n\nmodule-whatis \"Adds MAKER dependencies to environment.\"\n\nsetenv          ZOE             /gscratch/srlab/programs/snap-2013-11-29/Zoe\nsetenv          AUGUSTUS_CONFIG_PATH             /gscratch/srlab/programs/Augustus-3.3.2/config\nprepend-path    PATH            /gscratch/srlab/programs/exonerate-2.2.0-x86_64/bin\nprepend-path    PATH            /gscratch/srlab/programs/ncbi-blast-2.10.1+/bin\nprepend-path    PATH            /gscratch/srlab/programs/snap-2013-11-29\nprepend-path    PATH            /gscratch/srlab/programs/RepeatMasker-4.1.0\n</code></pre> <p>There are two lines that describe what the module does (e.g. <code>Adds MAKER dependencies to environment.</code>)</p> <p>Those are followed by setting some environmental variables and adding other programs to the system <code>$PATH</code> needed by the MAKER program.</p>"},{"location":"mox_Software/#loading-modules","title":"Loading modules","text":"<p>There are many pre-made modules available for anyone to use at any time. List them like so:</p> <p><code>module avail</code></p> <p>Modules preceded by <code>contrib/</code> are modules created by other Mox users outside of the Roberts Lab.</p> <p>The remaining modules are those created by Mox UW-IT staff and primarily utility applications.</p> <p>To run (i.e. load) a module (replace <code>&lt;module_name&gt;</code> with the module name or full path to module file):</p> <p><code>module load &lt;module_name&gt;</code></p> <p>You can add our custom modules directory to your <code>~/.bashrc</code> file. This will allow you to load a module by calling just the the name of the module file without the need to call the full module paht. See the modules directory for more info on what custom modules are available (<code>/gscratch/srlab/programs/modules</code>).</p> <pre><code>printf \"\\n%s\\n%s\\n%s\" \"# Prepend custom modules to system ${MODULEPATH}\" \"MODULEPATH=/gscratch/srlab/programs/modules:${MODULEPATH}\" \"export MODULEPATH\" \\\n&gt;&gt; ~/.bashrc\n</code></pre> <p>To make the above command active, type <code>bash</code> at the command prompt (you only need to do this one time; your changes will be loaded each time you login).</p>"},{"location":"mox_Software/#available-programs","title":"Available Programs","text":"<p>Below is the current list of programs available on Mox. It's very dynamic, so please check the contents of <code>$/gscratch/srlab/programs</code> periodically. If you need some other/new programs, please refer to the program installation instructions or feel free to ask Sam.</p> <pre><code>$/gscratch/srlab/programs\n2bRAD_GATK            DRAP                   macau                    perl              smrtanalysis_2.3.0.140936.run\nanaconda3             exonerate-2.2.0-x86_64             maker-2.31.10                picard_2.18.4         snap-2013-11-29\nargparse-1.4.0            express-1.5.1-linux_x86_64         maker-3.01.03                picard-2.9.1          SOAPdenovo2\nAugustus-3.3.2            FastaIndex                 MaSuRCA-3.2.3                pigz-2.4              SOAPec_bin_v2.03\nbamtools-2.5.1            fastp-0.20.0               mawk-1.3.4-20190203              pilon             SPAdes-3.13.0-Linux\nbbmap_38.34           FastQC-0.11.5              mdust                    pitchfork             SparseAssembler\nbcftools-1.9              fastqc_v0.11.8                 megahit_v1.1.4_LINUX_CPUONLY_x86_64-bin  platanus_1.2.4            sqlite\nbcl2fastq-v2.20           fastqc_v0.11.9                 MEGAN6                   pstl              sratoolkit.2.10.6-centos_linux64\nbedtools-2.27.1           freebayes-v.1.3.0-1            MEGAN-6.18.3                 pyfaidx-0.5.5.2           SSPACE-LongRead_v1-1\nbin               gapcloser-1.12                 MEGAN_Community_unix_6_17_0.sh       pyScaf                SSPACE-STANDARD-3.0_linux-x86_64\nBismark-0.19.0            GARM_v0.7.5                MEGAN_Community_unix_6_18_3.sh       quast-4.5             stacks-2.41\nBismark-0.21.0            GATK                   MetaGeneMark_linux_64_3.38           R-3.6.2               STAR-2.7.6a\nBismark-0.21.0_dev        gcc                    Metassembler                 racon             stringtie-1.3.6.Linux_x86_64\nBismark-0.22.3            get-pip.py                 miniconda3                   rainbow_2.0.4         stringtie-2.1.4.Linux_x86_64\nblast-2.2.17              gffread-0.11.4.Linux_x86_64        minimap2-2.17_x64-linux              reago-1.1-release-2015.12.18  supernova-2.0.0\nblat-v36x2            git-sym                    modules                      redundans             tbb\nblat-v36x5            graphviz-2.40.1                mummer                   RepeatMasker-4.1.0        tguenther-bayenv2_public-2b2b7f20bb62\nbowtie2-2.1.0             gt-1.5.10-Linux_x86_64-64bit-complete  MUMmer3.23                   resources             tmhmm-2.0c\nbowtie2-2.3.4.1-linux-x86_64  hisat2-2.1.0               mummer-4.0.0beta2                rmblast-2.10.0            transdecoder\nbowtie2-2.3.5.1-linux-x86_64  hisat2-2.2.0               NanoPlot-1.29.1                  RNAMMER-1.2           TransDecoder-v5.3.0\nbowtie2-2.4.1-linux-x86_64    hmmer-2.3                  ncbi-blast-2.10.1+               RSEM-1.3.3            TransDecoder-v5.5.0\nbsmap-2.89            hmmer-3.1b2                ncbi-blast-2.6.0+                salmon-0.11.2-linux_x86_64    tree-1.8.0\nbusco-v3              hmmer-3.2.1                ncbi-blast-2.8.1+                salmon-1.1.0_linux_x86_64     trf409.linux64\nbwa-0.7.15            hmmer-3.3                  ncbi-blast-2.8.1+_orginal            salmon-1.2.1_linux_x86_64     TrimGalore-0.4.5\nbwa-0.7.17            htslib-1.9                 networkx-1.11                samtools-1.10         TrimGalore-0.6.6\ncanu                  infernal-1.1.1                 networkx2                    samtools-1.4          Trimmomatic-0.33\ncd-hit-v4.8.1-2019-0228       interproscan-5.31-70.0             nseg                     samtools-1.9          Trimmomatic-0.36\ncelera                jellyfish-1.1.11               ont-guppy_3.4.4                  scripts               trinityrnaseq-v2.9.0\ncmake-3.12.1              jellyfish-2.2.10               ont-guppy_4.0.15_linux64             sedef             Trinity-v2.8.3\ndDocent-2.7.8             jellyfish-2.3.0                parallel-20180822                seqtk-1.3             Trinotate-v3.1.1\ndecorator-4.0.11          jsoncpp-1.8.4              parallel-20190922                setuptools-36.0.1         Trinotate-v3.2.0\ndetonate-1.11             kmergenie-1.7048               pblat-2.1                    Sibelia-3.0.7-Source      vcflib\ndiamond-0.9.26            krakenuniq-0.5.8               PBSuite                      signalp-4.1           vcftools-0.1.16\ndiamond-0.9.29            last-852                   pear-0.9.11-linux-x86_64             signalp-5.0b          wtdbg-2.1_x64-linux\ndiamond-2.0.4             likelybin-0.1.0                pecan                    simuPOP-1.1.10.9\n</code></pre>"},{"location":"mox_Viewing-and-Interacting-with-Jobs/","title":"Viewing and interacting with jobs","text":""},{"location":"mox_Viewing-and-Interacting-with-Jobs/#viewing-jobs","title":"Viewing Jobs:","text":"<p>There are two main commands to view job statuses. <code>squeue</code> and <code>scontrol</code>. <code>squeue</code> shows information about all jobs currently running on Hyak, while <code>scontrol</code> shows information on a specific job, and requires additional arguments</p> <p><code>squeue</code> - </p> <p>Typing <code>squeue</code> in any node type of Hyak shows the following output</p> <pre><code>[seanb80@mox1 CanuTest]$ squeue\n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n             24074     build   my_job    dsale PD       0:00      1 (QOSMaxCpuPerUserLimit)\n             24355     build   my_job    dsale PD       0:00      1 (Priority)\n             32589      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32590      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32591      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32592      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32594      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32595      chem dft_dime  inguyen PD       0:00      2 (Resources)\n             32628      chem Modello_     gd24 PD       0:00      1 (Resources)\n             32770    ilahie  R5local   vanouk PD       0:00     18 (Resources)\n             32765       stf R5global   vanouk PD       0:00     11 (Resources)\n             32776  ferrante     bash      af0  R      14:38      1 n2013\n             32103      choe NPc_f2_5    ychoe  R 4-10:43:42      1 n2179\n             32482      choe NPex_dn2    ychoe  R   22:14:20      1 n2012\n             32481      choe  NPex_dn    ychoe  R   22:14:51      1 n2195\n             32192      chem EXC-DMC-    lrm13  R 2-18:29:37      1 n2014\n             32588      chem dft_dime  inguyen  R    3:34:51      2 n[2024-2025]\n             32619      chem dft_snap   yliu92  R   17:08:07      1 n2201\n             32618      chem dft_snap   yliu92  R   17:21:38      1 n2005\n             32769    ilahie   R5orig   vanouk  R      57:21     18 n[2156-2173]\n             32494      chem prova2_E     gd24  R   17:56:09      1 n2180\n             32504      chem prova2_E     gd24  R   17:56:09      1 n2184\n             ...\n</code></pre> <p>This shows the JobID (important for <code>scontrol</code>), the group who owns the JobID, the job name, time remaining, number of nodes used, and node IDs (important for <code>ssh</code>ing in to view process information). The output can be piped in to grep to identify individual groups via <code>squeue | grep \"srlab\"</code> for ease of finding relevant information.</p> <pre><code>[seanb80@n2149 CanuTest]$ squeue | grep \"srlab\"\n             32779     srlab     bash  seanb80  R       0:09      1 n2149\n</code></pre> <p><code>scontrol</code> - </p> <p><code>scontrol</code> shows more in depth information regarding a specific job and node. </p> <p>Job information: <code>scontrol show job JobID</code> returns state, run time, time limit, and node architecture information. The output below shows that our job has been running for 00:14:55, (RunTime), has a total TimeLimit of 00:30:00 and is running on a 28 core node (NumCPUs) with 28gb of memory (mem). </p> <pre><code>[seanb80@n2149 CanuTest]$ scontrol show job 32779\nJobId=32779 JobName=bash\n   UserId=seanb80(557445) GroupId=hyak-srlab(415510) MCS_label=N/A\n   Priority=100 Nice=0 Account=srlab QOS=normal\n   JobState=RUNNING Reason=None Dependency=(null)\n   Requeue=1 Restarts=0 BatchFlag=0 Reboot=0 ExitCode=0:0\n   RunTime=00:14:55 TimeLimit=00:30:00 TimeMin=N/A\n   SubmitTime=2017-06-21T07:32:33 EligibleTime=2017-06-21T07:32:33\n   StartTime=2017-06-21T07:32:33 EndTime=2017-06-21T08:02:33 Deadline=N/A\n   PreemptTime=None SuspendTime=None SecsPreSuspend=0\n   Partition=srlab AllocNode:Sid=mox1:15953\n   ReqNodeList=(null) ExcNodeList=(null)\n   NodeList=n2149\n   BatchHost=n2149\n   NumNodes=1 NumCPUs=28 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:*\n   TRES=cpu=28,mem=28G,node=1\n   Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=*\n   MinCPUsNode=1 MinMemoryCPU=1G MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   Gres=(null) Reservation=(null)\n   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)\n   Command=/bin/bash\n   WorkDir=/gscratch/srlab/data/CanuTest\n   Power=\n</code></pre>"},{"location":"mox_Viewing-and-Interacting-with-Jobs/#view-cpu-and-memory-loads-on-node","title":"View CPU and Memory Loads on Node","text":"<p>There are two ways to see activity. Using <code>sstat</code> the Slurm Workload Manager or <code>top</code>. </p> <p>For either I suggest starting to find details of your job: <pre><code>[sr320@mox2 ~]$ squeue | grep srlab\n            130588     srlab supernov    sr320  R 2-08:29:31      1 n2211\n</code></pre></p> <p>Then using the job ID </p> <p><pre><code>[sr320@mox2 ~]$ sstat -j 130588.batch \n       JobID  MaxVMSize  MaxVMSizeNode  MaxVMSizeTask  AveVMSize     MaxRSS MaxRSSNode MaxRSSTask     AveRSS MaxPages MaxPagesNode   MaxPagesTask   AvePages     MinCPU MinCPUNode MinCPUTask     AveCPU   NTasks AveCPUFreq ReqCPUFreqMin ReqCPUFreqMax ReqCPUFreqGov ConsumedEnergy  MaxDiskRead MaxDiskReadNode MaxDiskReadTask  AveDiskRead MaxDiskWrite MaxDiskWriteNode MaxDiskWriteTask AveDiskWrite \n------------ ---------- -------------- -------------- ---------- ---------- ---------- ---------- ---------- -------- ------------ -------------- ---------- ---------- ---------- ---------- ---------- -------- ---------- ------------- ------------- ------------- -------------- ------------ --------------- --------------- ------------ ------------ ---------------- ---------------- ------------ \n130588.batch 378173576K          n2211              0 255186652K 297379616K      n2211          0 188699776K        0        n2211              0          0 6-21:36:24      n2211          0 1-12:27:15        1     27.00M       Unknown       Unknown       Unknown              0 75974159.15M           n2211               0 75974159.15M  3421658.12M            n2211                0  3421658.12M \n[sr320@mox2 ~]$ \n</code></pre> Yes it is ugly and for the most part not valuable.</p> <p>You could trim down, </p> <pre><code>[sr320@mox2 ~]$ sstat --format=AveCPU,AveCPUFreq,ReqCPUFreq,MaxVMSize,AveVMSize,MinCPU,NTasks,MaxRSSNode -j 130588.batch \n    AveCPU AveCPUFreq ReqCPUFreq  MaxVMSize  AveVMSize     MinCPU   NTasks MaxRSSNode \n---------- ---------- ---------- ---------- ---------- ---------- -------- ---------- \n1-13:07:49     14.99M    Unknown 378173576K 255188704K 6-21:36:24        1      n2211 \n</code></pre> <p>Now for what works! </p> <p>Using the node ID from above.</p> <p><pre><code>ssh -t n2211 top\n</code></pre> </p> <p>But you can simplify</p> <pre><code>ssh -t n2211 top -u sr320 | grep 8742\n</code></pre> <p>Just remember to Control 'C' when you are done as this program is running on the node. </p>"},{"location":"mox_Viewing-and-Interacting-with-Jobs/#memory-only","title":"Memory only","text":"<p><code>free</code> <pre><code>[sr320@mox1 jobs]$ ssh -t n2221 free -g\n              total        used        free      shared  buff/cache   available\nMem:            251           6         241           2           3         241\nSwap:            11           0          11\n</code></pre></p>"},{"location":"mox_Viewing-and-Interacting-with-Jobs/#cancelling-jobs","title":"Cancelling jobs:","text":"<p>Canceling jobs is done via the <code>scancel JobID</code> command. It cancels any job you have ownership of with a 12 second graceful shutdown period, so be sure you're canceling the right job when you execute it.</p> <pre><code>[seanb80@n2149 CanuTest]$ scancel 32779\nsrun: Force Terminated job 32779\n[seanb80@n2149 CanuTest]$ srun: Job step aborted: Waiting up to 12 seconds for job step to finish.\nsrun: error: n2149: task 0: Killed\n[seanb80@mox1 CanuTest]$ \n</code></pre>"},{"location":"music/","title":"Spotify Playlists","text":""},{"location":"test/","title":"this is a pages","text":"<p>not in the Index</p> <p>maybe some</p> <pre><code>kadjfkadjfkajdfkjadf\nadfakjfdakdjfkadjfkajdfkajdfkjakldfj\n'ajfdka'\n</code></pre>"},{"location":"archive/Docker-Guide/","title":"Docker Guide","text":""},{"location":"archive/Docker-Guide/#roberts-lab-docker-help-file","title":"Roberts Lab Docker Help File","text":""},{"location":"archive/Docker-Guide/#this-file-is-intended-to-provide-a-brief-introduction-on-using-docker-and-the-dockerfile-dockerfilebio-for-the-roberts-lab","title":"This file is intended to provide a brief introduction on using Docker and the Dockerfile, Dockerfile.bio, for the Roberts Lab. <p>For Mac/Windows users, it is written as though you are using/launching Docker via Docker QuickStart Terminal, which is only available as part of Docker Toolbox!</p> <p>There are five sections of instructions, each with increasing usage complexity:</p> <ul> <li>Build an Image<ul> <li>Required to begin working with Docker.</li> </ul> </li> <li>Starting a Container<ul> <li>Instructions on running a container from an image.</li> <li>Lacks the ability to interact with files on your computer.</li> </ul> </li> <li>Using Jupyter Notebooks<ul> <li>Instructions on how to run a container and use Jupyter Notebooks in your computer's browser.</li> <li>Lacks the ability to interact with files on your computer.</li> </ul> </li> <li>Interact with Files on Your Computer<ul> <li>Instructions on how to run a container that can interact with files on your computer.</li> <li>This will be the most useful container and will likely be the default setup you use from here on out.</li> </ul> </li> <li>Semi-important Supplemental Info<ul> <li>Instructions on how to limit and reduce Docker image disk space usage by re-using existing images/containers and/or deleting old/unused images/containers.</li> </ul> </li> </ul>","text":""},{"location":"archive/Docker-Guide/#build-the-docker-image","title":"Build the Docker Image","text":"<ul> <li>Only needs to be done once.</li> <li>Items in all caps (e.g. NAME) can be replaced with text of your choosing and does not need to be uppercase.</li> <li> <p>~8GB in size</p> </li> <li> <p>Download and install Docker for your operating system (Docker Toolbox if using Windows/Mac!!).</p> </li> <li>Download the Roberts Lab bioinformatics Dockerfile: Dockerfile.bio. Ideally, clone this repo. Otherwise, the Dockerfile should be saved in its own, dedicated directory (i.e. no other files in directory).</li> <li>Open a terminal.</li> <li>Change to the directory where you saved the Dockerfile.</li> <li>Build the Docker image:<ol> <li>On Mac: <ol> <li><code>eval \"$(docker-machine env default)\"</code></li> <li><code>docker build --tag=\"NAME/bioinformatics:v11\" --file=\"Dockerfile.bio\" .</code></li> </ol> </li> </ol> </li> <li>Non-Mac:<code>docker build --tag=\"NAME/bioinformatics:v11\" --file=\"Dockerfile.bio\" .</code></li> </ul> <p>Explanation:  - <code>docker build</code> constructs the Docker image from the instructions in the Dockerfile. The Dockerfile tells Docker which programs should be downloaded, installed, and where/how to install them in the Docker image.  - <code>--tag=\"&lt;name&gt;\"</code> Allows you to give the image you build an easy to remember name. It can be anything you like.  - <code>--file=\"&lt;dockerfile_name&gt;\" .</code> Tells Docker the name of the Dockerfile and to look for it in the current directory (the <code>.</code>).</p>"},{"location":"archive/Docker-Guide/#start-a-docker-container-basic","title":"Start a Docker Container (Basic)","text":"<p>These instructions will run the Docker container from the image built above with no \"frills.\" See the Intermediate instructions to begin using Jupyter Notebooks in the Docker container.</p> <ul> <li>Requires that a Docker image has already been built</li> <li>Mac users: If opening a new Terminal window, enter the following before proceeding:</li> </ul> <p><code>eval \"$(docker-machine env default)\"</code></p> <ol> <li>Identify existing image(s):</li> </ol> <p><code>docker ps -a</code></p> <ol> <li>Start a Docker container (replace IMAGE_NAME with desired image name from Step 1): </li> </ol> <p><code>docker run -it IMAGE_NAME /bin/bash</code></p> <p>You will now be inside the docker container. The container is basically a specialized computer that has very few programs besides the bioinformatics programs specified in the Dockerfile. Feel free to move around and try things out.</p> <ol> <li>Exit the container: Type \"exit\".</li> </ol> <p>Explanation:</p> <ul> <li><code>docker ps -a</code> Lists all images on the system in order they were created, newest to oldest</li> <li><code>docker run</code> Starts a Docker container. Requires an image name.</li> <li><code>-it</code> Starts a Docker container with an interactive terminal (i.e. a terminal window to type in).</li> <li><code>IMAGE_NAME</code> The name of the image that should be used to start the Docker container.</li> <li><code>/bin/bash</code> The command that the container should run when it starts. In this case, we tell the container to start bash. Bash is the command line stuff you use when using Terminal.</li> </ul>"},{"location":"archive/Docker-Guide/#run-jupyter-notebook-in-docker-container-intermediate","title":"Run Jupyter Notebook in Docker Container (Intermediate)","text":"<ol> <li>Start a Docker container with specific port mappings:</li> </ol> <p><code>docker run -p 8888:8888 -it IMAGE_NAME /bin/bash</code></p> <ol> <li>Start Jupyter Notebook (enter this inside the container):</li> </ol> <p><code>jupyter notebook</code></p> <ol> <li>In a separate Terminal window, outside of your container, check the IP address of the Docker machine:</li> </ol> <p><code>docker-machine ip</code></p> <ol> <li>Run Jupyter Notebook in your browser:<ol> <li>Enter URL (in a different window or tab than what you're using for R Studio):<ol> <li>Mac users (use the IP address from Step 4 above): e.g. <code>192.168.99.100:8888</code></li> <li>Others: <code>localhost:8888</code></li> </ol> </li> </ol> </li> </ol> <p>Explanation:  - <code>-p 8888:8888</code> Tells Docker to create container that binds your computer's port 8888 to container port 8888. Allows you to use Jupyter Notebook in your browser.  - The port bindings for your computer can be changed (the first number in the 8888:8888 part of the command). It's recommended to stick to port numbers greater than 9000 if they need to be changed. The port bindings for the container (the second number in the 88888:8888 part of the command) should not be changed, since Jupyter Notebooks are currently configured to connect to those ports of the container. </p>"},{"location":"archive/Docker-Guide/#access-files-outside-of-a-docker-container-advanced","title":"Access Files Outside of a Docker Container (Advanced)","text":"<ul> <li>WARNING! The current setup of the Roberts Lab Dockerfile.bio runs the Docker container as the \"root\" user. Any changes made to volumes on your computer that are mounted in the Docker container will be executed without asking for a password! If you mount the wrong directories of your computer, you may do serious harm (like, render it inoperable) to your computer when making changes to the directory mounted inside the Docker container!</li> </ul> <p>IMPORTANT! </p> <ul> <li>Mac users can only mount directories contained in the <code>/Users</code> directory! </li> <li>Windows users can only mount directories contained in the <code>/c/Users/</code> directory!</li> <li>Requires that a Docker image has already been built</li> <li>Mac users: If opening a new Terminal window, enter the following before proceeding:</li> </ul> <p><code>eval \"$(docker-machine env default)\"</code></p> <ol> <li>Start a Docker container with specific port mappings and volume mount points:</li> </ol> <p><code>docker run -p 8888:8888 -v /path/to/computer/folder:/path/to/container/folder -it IMAGE_NAME /bin/bash</code></p> <p>Explanation:</p> <ul> <li><code>docker run -p 8888:8888 -it IMAGE_NAME /bin/bash</code> See the Basic &amp; Intermediate guides.</li> <li><code>-v</code> This flag tells Docker to mount a volume from your computer in the Docker container.</li> <li><code>/path/to/computer/folder:</code> The location of the folder on your computer that you would like to be able to access from your Docker container. If the folder doesn't exist on your computer, Docker will create it.</li> <li><code>/path/to/container/folder</code> The location of the folder inside the Docker container where you will be able to access the folder on your computer specified in the first portion of the command.</li> </ul> <p>Example: </p> <p><code>-v /Users/Sam/Downloads:/home/srlab/junk</code></p> <p>The above command allows me to acces the files in my Downloads folder on my computer. Once I'm in the Docker container, I would change to the \"junk\" directory to interact with the files in my Downloads folder on my computer.</p> <p>Note: You can mount multiple volumes by adding multiple <code>-v</code> flags followed by the desired local and container mount points.</p>"},{"location":"archive/Docker-Guide/#supplemental-info","title":"Supplemental Info","text":""},{"location":"archive/Docker-Guide/#reuse-an-existing-container","title":"Reuse an existing container <ul> <li>Most users should follow this once they've built and run their first image/container.</li> <li>Requires that a Docker image has already been built</li> <li>Requires that a Docker container has been created</li> <li>Mac users: If opening a new Terminal window, enter the following before proceeding:</li> </ul> <p><code>eval \"$(docker-machine env default)\"</code></p> <p>Every time the <code>docker run</code> command is used, a new container is created (even if you use the same exact <code>docker run</code> command). This can lead to clutter and confusion. To reuse an existing container do the following:</p> <ol> <li><code>docker ps -a</code> Lists all existing containers</li> <li>If the container STATUS is listed as \"Exited\" use one of the following options:<ol> <li><code>docker start CONTAINER_ID</code> Replace \"CONTAINER_ID\" with the ID of the desired container.</li> <li><code>docker start NAMES</code> Replace \"NAMES\" with the name of the desired container.</li> </ol> </li> <li>If the container STATUS is listed as \"Up\", use one of the following options:<ol> <li><code>docker attach CONTAINER_ID</code> Replace \"CONTAINER_ID\" with the ID of the desired container.</li> <li><code>docker attach NAMES</code> Replace \"NAMES\" with the name of the desired container.</li> </ol> </li> <li>Press CTRL-c to enter the container.</li> <li>When finished, leave the container using one of the following options:<ol> <li>Press CTRL-p, then press CTRL-q. This will detach the container and leave it running. This will allow you to skip Step 2 when reusing the container.</li> <li><code>exit</code> This will stop the container. You will have to start at Step 2 in order to reuse the container.</li> </ol> </li> </ol>","text":""},{"location":"archive/Mox-Hyak-Supercomputer-Guide/","title":"Mox Hyak Supercomputer Guide","text":"<p>This has its own dedicated repo/wiki: Mox user guide</p>"},{"location":"archive/READM/","title":"READM","text":"<p>resources/docs/archive</p>"},{"location":"archive/READM/#archived-markdown-files-no-longer-in-use-by-mkdocs-to-create-readthedocs-roberts-lab-handbook","title":"Archived markdown files no longer in use by MkDocs to create readthedocs Roberts Lab Handbook.","text":""}]}